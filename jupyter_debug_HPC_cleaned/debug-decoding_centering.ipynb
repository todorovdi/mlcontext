{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9577e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%debug\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from os.path import join as pjoin\n",
    "\n",
    "import os,sys; sys.path.append(os.path.expandvars('$CODE_MEMORY_ERRORS'))\n",
    "from IPython import get_ipython; ipython = get_ipython()\n",
    "#%run -i ../exec_HPC.py 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc00ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CODE_MEMORY_ERRORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ba099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "runstrings = open( pjoin(os.path.expandvars('$CODE_MEMORY_ERRORS'),'_runstrings.txt'),'r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f42746",
   "metadata": {},
   "outputs": [],
   "source": [
    "len( set(runstrings) ), len(runstrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec0ff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "istr = 17\n",
    "rs = runstrings[istr]\n",
    "if rs.startswith('ipython'):\n",
    "    pstr = ' '.join( rs.split(' ')[5:] )[:-1]\n",
    "    runf = rs.split(' ')[2]\n",
    "    rsmod = runf + ' ' + pstr \n",
    "    print( rsmod )\n",
    "else:\n",
    "    pstr = ' '.join( rs.split(' ')[1:] )[:-1]\n",
    "    runf = ''\n",
    "    #runf = rs.split(' ')[2]00\n",
    "print(pstr)\n",
    "\n",
    "pstr0 = pstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb064e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin,tmax = -14.88,-14.42\n",
    "wstr = '--slide_window_shift 0.232 --slide_windows_type auto'\n",
    "wstr2 = f'--slide_windows_type explicit --tmin {tmin} --tmax {tmax} '\n",
    " #--env_to_run stable,random\n",
    "    # --env_to_run stable\n",
    "pstr = pstr0.replace(wstr,wstr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896d791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b4c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc; gc.collect()\n",
    "#ipython.magic()\n",
    "#%debug\n",
    "#mstr0 = '%run -i ' + rsmod\n",
    "#ipython.magic(mstr0)\n",
    "ipython.run_line_magic('run',' -i ' + runf + ' ' + pstr + \\\n",
    "                      ' --use_preloaded_flt_raw 1')\n",
    "    # --exit_after enforce_consist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08af024",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfev), len(behav_df_cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270fa82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all( np.diff( epochs_curenv.events[:,0] ) > 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91b05bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_to_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d509933e",
   "metadata": {},
   "source": [
    "# side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbdc34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28568b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 =  ('-i ' + runf + ' ' + pstr + \n",
    "    ' --use_preloaded_flt_raw 1 --nskip_trial 3 '\n",
    "    ' --nb_fold 2 --n_splits_B2B 3 --save_result 0'\n",
    "    ' --custom_suffix __test__ '\n",
    "    ' --n_jobs 1'\n",
    "    ' --do_classic_dec 1 --exit_after classic_1st')\n",
    "#    ' --do_classic_dec 0 --exit_after b2b_1st')\n",
    "\n",
    "#' --exit_after classic_1st')\n",
    "#--exit_after rescale\n",
    "s2 = s1\n",
    "s2 = s2.replace('--scale_Y_robust 0','--scale_Y_robust 1')\n",
    "print(s1)  # no robus y\n",
    "print(s2)  # robust y\n",
    "\n",
    "rs = []\n",
    "#ipython.magic(mstr0)\n",
    "for s in [s1,s2]:\n",
    "    ipython.run_line_magic('run',s)\n",
    "    rs += [res]\n",
    "    #rs += [addvar_]\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e1adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_classic = rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cec2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rs_b2b = rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4259399",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = subdf[addvars]._values                                           \n",
    "if par['discard_hit_twice']:                                                                                                                      \n",
    "    non_hit = subdf['non_hit_not_adj']     \n",
    "non_hit_mask = non_hit                                                                                                                        \n",
    "\n",
    "vals_non_hit = vals[non_hit]  # already non_hit                                                                                               \n",
    "y = vals_non_hit                                                                                                                                                                                                                                                              \n",
    "mask_not_inf = ~np.any( np.isinf(y), axis=1)                                                                                                      \n",
    "mask_not_nan = ~np.any( np.isnan(y), axis=1)                                                                                                      \n",
    "#print('infs ', (~mask_not_inf).sum(), len(mask_not_inf) )                                                                                        \n",
    "\n",
    "mask_good = getMaskNotNanInf(y, axis=1)       \n",
    "vals1 = y[mask_good]\n",
    "print(y.shape, vals1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22266024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93816dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afe2495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184b9555",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39373dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "for wc,res in zip( [False, True], rs_b2b ):\n",
    "#     vals = res['vals']\n",
    "#     y_t = RobustScaler(with_centering = wc).fit_transform(vals)\n",
    "#     npos = (y_t > 0).sum()\n",
    "#     print(vals.shape, npos)\n",
    "    \n",
    "    y_t = RobustScaler(with_centering = wc).fit_transform(vals1)\n",
    "    npos =  (vals1 > 0).sum()\n",
    "    npos_t = (y_t > 0).sum()\n",
    "    \n",
    "    print(wc, vals1.shape, vals1.size, y_t.shape, npos, \n",
    "          npos_t)\n",
    "\n",
    "# def scale axis = 0\n",
    "npos_t0 = (scale(vals1) > 0).sum()\n",
    "npos_t00 = (scale(vals1, axis=0) > 0).sum()\n",
    "npos_t01 = (scale(vals1, axis=1) > 0).sum()\n",
    "npos_t0wm0 = (scale(vals1, with_mean=0) > 0).sum()\n",
    "print(npos, npos_t0, npos_t00, npos_t01, npos_t0wm0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a73a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std( (y_t),0 ), np.mean( (y_t),0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8288ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std( scale(vals1),0 ), np.mean( scale(vals1),0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c4ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = np.arange(10)[:,None]\n",
    "scale(yy),yy.shape #.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0facea",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(*np.where(np.sign(vals1) != np.sign(scale(vals1)))) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2814a58",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# TODO: check first var in classic is same as first in b2b\n",
    "# compare scaleing outputa\n",
    "# is b2b scale inv or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cbdbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_non_hit_recalc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f927413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8137d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rscs = []\n",
    "rys = []\n",
    "for res in rs_b2b:\n",
    "    rscs += [res['scores']]\n",
    "    vals = res['vals']\n",
    "    rys += [vals]\n",
    "    print('sc = ',res['scores'] )\n",
    "    print('     ', vals[:3])\n",
    "    \n",
    "    nna = np.isnan(vals).sum()\n",
    "    print(nna)\n",
    "    \n",
    "    npos = (vals >= 0).sum(0)\n",
    "    print(vals.shape, npos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b3be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "neq = np.sign(rs_b2b[0]['vals']) != np.sign(rs_b2b[1]['vals'])\n",
    "rs_b2b[0]['vals'][neq], rs_b2b[1]['vals'][neq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f213a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbdefde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rs_classic = rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7570c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in rs_classic:\n",
    "    #print(res['scores'], res['vals'][:3])\n",
    "    \n",
    "    vals = res['vals']\n",
    "    rys += [vals]\n",
    "    print('sc = ',res['scores'] )\n",
    "    print('     vals[:4] = ', vals[:4])\n",
    "    \n",
    "    nna = np.isnan(vals).sum()\n",
    "    print(nna)\n",
    "    \n",
    "    npos = (vals >= 0).sum()\n",
    "    print(vals.shape, npos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a01cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in rs_classic:\n",
    "    print(res['scores'], res['vals'][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c766c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rys[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b057d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in rs:\n",
    "    #print( res[:10] )\n",
    "    print(np.mean(res))\n",
    "    print(np.median(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d86205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d82d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.abs(scale(rys[0]) - scale(rys[1])).max() )\n",
    "print( np.abs(rys[0] - scale(rys[1])).max() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7160c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(rscs[0] - scale(rscs[1])).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21f5a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(scale(rscs[0]) - scale(rscs[1])).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d7fc28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb17b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcur.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd24a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "spoc = SPoC(n_components=SPoC_n_components, log=True, reg='oas',                                                                                  \n",
    "            rank='full', n_jobs=min(n_jobs_SPoC, Xcur.shape[0] ),                                                                                 \n",
    "            fit_log_level=mne_fit_log_level)                                                                                                      \n",
    "# Regression for classic decoding                                                                                                                 \n",
    "if regression_type == 'Ridge':                                                                                                                    \n",
    "    alphas = np.logspace(-5, 5, 12)                                                                                                               \n",
    "    G = make_pipeline(spoc, RidgeCV(alphas=alphas, fit_intercept=False))                                                                          \n",
    "elif regression_type == 'xgboost':                                                                                                                \n",
    "    from xgboost import XGBRegressor                                                                                                              \n",
    "    xgb = XGBRegressor(**add_clf_creopts)                                                                                                         \n",
    "    # Regressions for the B2B                                                                                                                     \n",
    "    G = make_pipeline(spoc, xgb)                                                                                                                  \n",
    "    # Regressions for the B2B                                                                                                                     \n",
    "\n",
    "    #param_grid = {                                                                                                                               \n",
    "    #    'pca__n_components': [5, 10, 15, 20, 25, 30],                                                                                            \n",
    "    #    'model__max_depth': [2, 3, 5, 7, 10],                                                                                                    \n",
    "    #    'model__n_estimators': [10, 100, 500],                                                                                                   \n",
    "    #}                                                                                                                                            \n",
    "    #grid = GridSearchCV(pipeline, param_grid,                                                                                                    \n",
    "    #  cv=5, n_jobs=-1, scoring='roc_auc')                                                                                                        \n",
    "else:                                                                                                                                             \n",
    "    raise ValueError('wrong regression value')                                                                                                    \n",
    "\n",
    "\n",
    "H = LinearRegression(fit_intercept=False, n_jobs= n_jobs_SPoC)                                                                                    \n",
    "#G = direct pipeline (spoc + regerssor)                                                                                                           \n",
    "#H = back pipeline                                                                                                                                \n",
    "b2b = B2B_SPoC(G=G, H=H, n_splits=n_splits_B2B,                                                                                                   \n",
    "    parallel_type=B2B_SPoC_parallel_type,n_jobs=n_jobs)                                                                                           \n",
    "\n",
    "sk = 4; nv=2\n",
    "d = {}\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "b2b.fit(Xcur[::sk],y[::sk][:,:nv])  \n",
    "r = np.diag(b2b.E_)\n",
    "print(r)\n",
    "d['noscale'] = r\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "b2b.fit(Xcur[::sk],y[::sk][:,:nv] * 10)  \n",
    "r = np.diag(b2b.E_)\n",
    "print(r)\n",
    "d['manual_y'] = r\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "b2b.fit(Xcur[::sk] * 3.3,y[::sk][:,:nv] * 10)  \n",
    "r = np.diag(b2b.E_)\n",
    "print(r)\n",
    "d['manual_Xy'] = r\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "b2b.fit(Xcur[::sk],y[::sk][:,:nv] * 10 - 5)  \n",
    "r = np.diag(b2b.E_)\n",
    "print(r)\n",
    "d['manual&shift_y'] = r\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "# shift only one dim\n",
    "b2b.fit(Xcur[::sk],y[::sk][:,:nv] * 10 - np.arange(2)[None,:]*5)  \n",
    "r = np.diag(b2b.E_)\n",
    "print(r)\n",
    "d['manual&shift1_y'] = r\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "b2b.fit(Xcur[::sk],scale( y[::sk], with_mean = False ) [:,:nv])  \n",
    "r = np.diag(b2b.E_)\n",
    "print(r)\n",
    "d['scale_wm0_y'] = r\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "b2b.fit(Xcur[::sk],scale( y[::sk], with_mean = True ) [:,:nv])  \n",
    "r = np.diag(b2b.E_)\n",
    "print(r)\n",
    "d['scale_wm1_y'] = r\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "y_t = RobustScaler(with_centering=False).fit_transform(y[::sk])[:,:nv]\n",
    "b2b.fit(Xcur[::sk],y_t)  \n",
    "r = np.diag(b2b.E_)\n",
    "d['scale_wc0_y'] = r\n",
    "print(r)\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "y_t = RobustScaler(with_centering=True).fit_transform(y[::sk])[:,:nv]\n",
    "b2b.fit(Xcur[::sk],y_t)  \n",
    "r = np.diag(b2b.E_)\n",
    "d['scale_wc1_y'] = r\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb62524",
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaleIfNeeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3b30e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_wm0_y good\n",
    "wc0 good\n",
    "#with mean (or with centering) == False => same as non_scaled\n",
    "#   or scaled w/o shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41e93ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,r in d.items():\n",
    "    print(f'{n:15}, {r[0]:6.3}, {r[1]:6.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febb4d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "nspl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3026dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RidgeCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5986d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classic_simple(y):\n",
    "    y = y[:,0]\n",
    "    print(y.shape)\n",
    "    Xcur_ = Xcur[::sk]\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    spoc_est = SPoC(n_components=SPoC_n_components, log=True, reg='oas',                                                                              \n",
    "    rank='full', n_jobs=n_jobs_per_dim_classical_dec,                                                                 \n",
    "    fit_log_level=mne_fit_log_level)         \n",
    "    cv = KFold(nb_fold, shuffle=True)  \n",
    "    alphas = np.logspace(-5, 5, 12)                                                                                                               \n",
    "    est = make_pipeline(spoc_est, RidgeCV()) \n",
    "    nsplit = 0\n",
    "    y_preds = np.zeros(len(y))\n",
    "    for train, test in cv.split(Xcur_, y):     \n",
    "        print(y.shape)\n",
    "        print(f'Starting split N={nsplit}')                                                                                                           \n",
    "        with mne.use_log_level(mne_fit_log_level):                                                                                                    \n",
    "            est.fit(Xcur_[train], y[train])                                                                                                            \n",
    "        y_preds[test] = est.predict(Xcur_[test])                                                                                                       \n",
    "        score = spearmanr(y_preds[test], y[test]) \n",
    "        return score[0]\n",
    "    \n",
    "y_t = RobustScaler(with_centering=True).fit_transform(y[::sk])[:,:nv]\n",
    "r = classic_simple(y_t)  \n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45885ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = {}\n",
    "r = classic_simple(y[::sk][:,:nv])  \n",
    "print(r)\n",
    "dc['noscale'] = r\n",
    "\n",
    "r = classic_simple(y[::sk][:,:nv] * 10)  \n",
    "print(r)\n",
    "dc['manual_y'] = r\n",
    "\n",
    "#b2b.fit(Xcur[::sk] * 3.3,y[::sk][:,:nv] * 10)  \n",
    "#print(r)\n",
    "#dc['manual_Xy'] = r\n",
    "\n",
    "r = classic_simple(y[::sk][:,:nv] * 10 - 5)  \n",
    "print(r)\n",
    "dc['manual&shift_y'] = r\n",
    "\n",
    "\n",
    "# shift only one dim\n",
    "r = classic_simple(y[::sk][:,:nv] * 10 - np.arange(2)[None,:]*5)  \n",
    "print(r)\n",
    "dc['manual&shift1_y'] = r\n",
    "\n",
    "r = classic_simple(scale( y[::sk], with_mean = False ) [:,:nv])  \n",
    "print(r)\n",
    "dc['scale_wm0_y'] = r\n",
    "\n",
    "r = classic_simple(scale( y[::sk], with_mean = True ) [:,:nv])  \n",
    "print(r)\n",
    "dc['scale_wm1_y'] = r\n",
    "\n",
    "\n",
    "y_t = RobustScaler(with_centering=False).fit_transform(y[::sk])[:,:nv]\n",
    "r = classic_simple(y_t)  \n",
    "dc['scale_wc0_y'] = r\n",
    "print(r)\n",
    "\n",
    "\n",
    "y_t = RobustScaler(with_centering=True).fit_transform(y[::sk])[:,:nv]\n",
    "r = classic_simple(y_t)  \n",
    "dc['scale_wc1_y'] = r\n",
    "print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b4b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,r in dc.items():\n",
    "    print(f'{n:15}, {r:6.3}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merr_Romain_proj",
   "language": "python",
   "name": "merr_romain_proj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
