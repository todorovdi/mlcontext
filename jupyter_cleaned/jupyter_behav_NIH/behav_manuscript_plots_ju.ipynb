{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf23da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55550333-465e-4026-8a32-1da00b2bd76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; \n",
    "os.path.expandvars('$CODE_MEMORY_ERRORS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fcb534-b379-46e7-b60c-38b1c4f45c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9952a90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "ipy = get_ipython()\n",
    "from os.path import join as pjoin\n",
    "import os,sys; sys.path.append(os.path.expandvars('$CODE_MEMORY_ERRORS'))\n",
    "import error_sensitivity\n",
    "import pandas as pd\n",
    "import seaborn as sns; print(sns.__version__)\n",
    "from datetime import datetime\n",
    "import pingouin as pg\n",
    "data_dir_general = os.path.expandvars('$DATA_QUENTIN')\n",
    "data_dir_input = os.path.expandvars('$DATA_MEMORY_ERRORS_STAB_AND_STOCH')\n",
    "scripts_dir = pjoin( os.path.expandvars('$CODE_MEMORY_ERRORS'))\n",
    "\n",
    "print(data_dir_input, scripts_dir)\n",
    "\n",
    "subjects = [f for f in os.listdir(data_dir_input) if f.startswith('sub') ]\n",
    "subjects = list(sorted(subjects))\n",
    "print(subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fa0a3a",
   "metadata": {},
   "source": [
    "### prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290b5aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from config2 import path_data\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from behav_proc import *\n",
    "\n",
    "import numpy as np\n",
    "#from collections import OrderedDict as odict\n",
    "from config2 import envcode2env\n",
    "from pingouin import ttest\n",
    "\n",
    "from base2 import radius_cursor\n",
    "radius_cursor\n",
    "ps_2nice = dict( zip(['pre','pert','washout','rnd'], \n",
    "        ['No perturbation','Perturbation','Washout','Random']) )\n",
    "\n",
    "\n",
    "target_angs = (np.array([157.5, 112.5, 67.5, 22.5]) + 90) * (np.pi / 180)\n",
    "target_angs / np.pi * 180\n",
    "\n",
    "import behav_proc\n",
    "from behav_proc import addBehavCols2, truncateNIHDfFromES, calcESthr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab37059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "// needed to access notebook path later\n",
    "var nb = IPython.notebook;\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var command = \"NOTEBOOK_FULL_PATH = '\" + nb.base_url + nb.notebook_path + \"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31801f4c",
   "metadata": {
    "run_control": {
     "marked": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def getAddInfo():\n",
    "    import datetime\n",
    "    # Get the current date and time in the format YYYY-MM-DD HH:MM:SS\n",
    "    now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    # Get the name of the current jupyter notebook\n",
    "    #notebook_name = os.path.basename(os.environ.get(\"NOTEBOOK_PATH\", \"\"))\n",
    "    notebook_name = NOTEBOOK_FULL_PATH\n",
    "    #print(notebook_name)\n",
    "    add_ttle = f\"{now}\\n{notebook_name}\"\n",
    "    return add_ttle\n",
    "\n",
    "def addTitleInfo(axs):\n",
    "    add_ttle = getAddInfo()\n",
    "    # Add a linebreak and the date, time, and notebook name to the ylabel of each axis\n",
    "    if axs is not None:\n",
    "        if isinstance(axs, (list, np.ndarray)): # If axs is a list or an array of axes\n",
    "            for ax in axs:\n",
    "                title = ax.get_title()\n",
    "                new_title = f\"{title}\\n{add_ttle}\"\n",
    "                ax.set_title(new_title)\n",
    "        else: # If axs is a single axis\n",
    "            title = axs.get_title()\n",
    "            new_title = f\"{title}\\n{add_ttle}\"\n",
    "            axs.set_title(new_title)\n",
    "    else:\n",
    "        title = plt.gcf()._suptitle.get_text()\n",
    "        new_title = f\"{title}\\n{add_ttle}\"\n",
    "        plt.suptitle(new_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af1617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"NOTEBOOK_FULL_PATH:\\n\", NOTEBOOK_FULL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2a17cc-c6cb-4310-9c44-0adebe94a7c8",
   "metadata": {
    "run_control": {
     "marked": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fnf = pjoin(path_data,'df_all_multi_tsz_.pkl.zip')\n",
    "#fnf = '/home/demitau/ownCloud/Current/merr_data/df_all_multi_tsz.pkl.zip'\n",
    "print(fnf)\n",
    "print( str(datetime.fromtimestamp(os.stat(fnf).st_mtime)))\n",
    "df_all_multi_tsz = pd.read_pickle(fnf)\n",
    "#dfc_multi_tsz = pd.   read_pickle(pjoin(path_data,'df_all_multi_tsz_trunc_q=0.05.pkl.zip'))\n",
    "print(df_all_multi_tsz['trial_group_col_calc'].unique())\n",
    "print(df_all_multi_tsz['retention_factor_s'].unique())\n",
    "# df = df_all_multi_tsz.query('trial_shift_size == 1 and trial_group_col_calc == \"trialwe\" '\n",
    "#                             ' and retention_factor_s == \"1.000\"').copy()\n",
    "df_all_multi_tsz_orig = df_all_multi_tsz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0841864",
   "metadata": {
    "run_control": {
     "marked": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df_all_multi_tsz.query('trial_shift_size == 1 and trial_group_col_calc == \"trialwe\" '\n",
    "                           ' and retention_factor_s == \"0.924\"').copy().sort_values(['subject','trials'])\n",
    "df_witgt = df_all_multi_tsz.query('trial_shift_size == 1 and trial_group_col_calc == \"trialwtgt_we\" '\n",
    "                           ' and retention_factor_s == \"0.924\"').copy().sort_values(['subject','trials'])\n",
    "df_orig = df\n",
    "\n",
    "#%debug\n",
    "df_witgt,dfall_witgt,ES_thr_witgt,_,_ = addBehavCols2(df_witgt.copy());\n",
    "df,dfall,ES_thr,envv,pert = addBehavCols2(df);\n",
    "\n",
    "df_wthr = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24ad81b",
   "metadata": {
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# to get retention from fits\n",
    "loadBC = 0\n",
    "if loadBC:\n",
    "    bestCalcs = pd.read_pickle(pjoin(path_data,'herz_param_calced6.pkl.zip')\n",
    "        ,compression='zip')\n",
    "\n",
    "    for ute in [True,False]:\n",
    "        bc = bestCalcs.query('use_true_errors == @ute').\\\n",
    "            groupby(['runname'])['fun'].mean().to_frame()\n",
    "        i = bc['fun'].idxmin()\n",
    "\n",
    "        rn = bc.loc[i].name\n",
    "\n",
    "        alphas = bestCalcs.query(f'runname == \"{rn}\"')['alpha']\n",
    "        print(f'{rn}\\n  {alphas.mean():.2f} {alphas.std():.2f}' )\n",
    "\n",
    "        #plt.hist(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e590d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[['target_locs','org_feedback']].describe()\n",
    "print( df_all_multi_tsz['trial_group_col_calc'].unique() )\n",
    "\n",
    "checkErrBounds(df,['error','prev_error','error_deg'])\n",
    "\n",
    "assert dfall.query('env == \"stable\"').trialwpertstage_wb.max() < 60\n",
    "#qs0_fig3 = ' and trialwpertstage_wb > 0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834ca26b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(df['error_deg'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ecf3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac64037",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_wthr['err_sens'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d26230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for generalization analysis\n",
    "import behav_proc\n",
    "stds = behav_proc._calcStds(df)\n",
    "stds = stds.to_frame().reset_index().rename(columns={'error_deg':'error_deg_initstd'}) \n",
    "\n",
    "print( df_all_multi_tsz.trial_group_col_calc.unique() )\n",
    "\n",
    "df_all_multi_tsz_whtr = df_all_multi_tsz.merge(stds, on='subject')\n",
    "df_all_multi_tsz_whtr_ = df_all_multi_tsz_whtr.\\\n",
    "    query('trial_group_col_calc in [\"trialwe\", \"trialwtgt_we\"]').copy()\n",
    "\n",
    "df_all_multi_tsz_whtr_['env'] = df_all_multi_tsz_whtr_['environment'].apply(lambda x: envcode2env[x])\n",
    "\n",
    "# def f(x):    \n",
    "#     if x > np.pi:\n",
    "#         x -= 2*np.pi\n",
    "#     elif x < -np.pi:\n",
    "#         x += 2*np.pi\n",
    "#     return x\n",
    "#df_all_multi_tsz_whtr_['error'] = df_all_multi_tsz_whtr_['error'].apply(f)\n",
    "df_all_multi_tsz_whtr_['error_deg'] = df_all_multi_tsz_whtr_['error'] / np.pi * 180 \n",
    "df_all_multi_tsz_whtr_['error_initstd'] = df_all_multi_tsz_whtr_.error_deg_initstd /  180 * np.pi \n",
    "\n",
    "print('trial_group_col_calc uniue = ', df_all_multi_tsz['trial_group_col_calc'].unique() )\n",
    "\n",
    "\n",
    "checkErrBounds(df,['error','prev_error','error_deg'])\n",
    "checkErrBounds(df_all_multi_tsz_whtr_,['error','prev_error','error_deg'])\n",
    "\n",
    "shiftszs = df_all_multi_tsz_whtr_['trial_shift_size'].unique()\n",
    "print(shiftszs)\n",
    "\n",
    "_cols = [col for col in df_all_multi_tsz.columns if col.find('like') >= 0]\n",
    "print(_cols)\n",
    "\n",
    "#df_all_multi_tsz.query('trials <= 4 and subject == @subjects[0] and  trial_group_col_calc == \"trialwe\"')\\\n",
    "#    [['trials','trial_shift_size','error','prev_error']]\n",
    "\n",
    "# truncate multi-ver ES\n",
    "# remove trials with error > std_mult * std of error\n",
    "dfall_notclean = df_all_multi_tsz_whtr_.query('err_sens.abs() <= @ES_thr')\n",
    "\n",
    "from behav_proc import truncateDf\n",
    "dfall_mshsz = truncateDf(dfall_notclean, 'err_sens', q=0.0, infnan_handling='discard', \n",
    "       cols_uniqify = ['subject','environment','trial_shift_size',\n",
    "                       'trial_group_col_calc','retention_factor_s'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cfadc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set(font_scale=1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893a755f",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## No savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e330001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from behav_proc import checkSavingsNIH\n",
    "checkSavingsNIH(dfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bea3b01",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corrs_per_subj_me_,corrs_per_subj  = corrMean(dfall, \n",
    "                stagecol = 'pert_stage', coln='err_sens', method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2c47b5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show stat signif\n",
    "stage_pairs = [(1,6),(3,8)]\n",
    "ttrs2 = []\n",
    "for s1,s2 in stage_pairs: \n",
    "    lst = [s1,s2]\n",
    "    ttrs_sig, ttr = comparePairs(corrs_per_subj.reset_index().query('pert_stage.isin(@lst)'), 'r', 'pert_stage',\n",
    "                                 paired=True)\n",
    "    ttr['stage_pair'] = f'{s1}-{s2}'\n",
    "    ttrs2 += [ttr]\n",
    "ttrs2 = pd.concat(ttrs2)\n",
    "display( ttrs2.query('pval <= 1e-2') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1226e354",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stage_pairs_nice = {\"1-6\":'first and last', \"3-8\":'second and third'}\n",
    "\n",
    "display(ttrs2)\n",
    "print('\\n\\nNo savings:')\n",
    "for irow,row in ttrs2.query('alternative == \"two-sided\"').iterrows():\n",
    "    sp = row['stage_pair']\n",
    "    pv=row['pval']\n",
    "    T=row['T']\n",
    "\n",
    "    #print(sp,pv)\n",
    "    print('ES during {} perturbations are not significantly different, t={:.2f}, p-value = {:.2e}.'.\\\n",
    "              format(stage_pairs_nice[sp],T,pv) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8b6c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show stat signif\n",
    "stage_pairs = [(1,3),(6,8)]\n",
    "print(stage_pairs)\n",
    "ttrs2 = []\n",
    "for s1,s2 in stage_pairs: \n",
    "    lst = [s1,s2]\n",
    "    ttrs_sig, ttr = comparePairs(corrs_per_subj.reset_index().query('pert_stage.isin(@lst)'), 'r', 'pert_stage',\n",
    "                                 paired=True)\n",
    "    ttr['stage_pair'] = f'{s1}-{s2}'\n",
    "    ttrs2 += [ttr]\n",
    "ttrs2 = pd.concat(ttrs2).query('alternative != \"two-sided\"')\n",
    "display( ttrs2.query('pval <= 1e-2')[['pval','ttstr']] )#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ced7a3",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Fig 2 CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c702f45f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a920c278",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#me.subject.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85040d58",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from figure import renameTickLabels, palette_stabrand\n",
    "\n",
    "thr = \"mestd*0\"\n",
    "me = dfall.groupby(['thr','subject','env'], observed=True).\\\n",
    "    mean(numeric_only=1).reset_index()\n",
    "me_env = me\n",
    "#me.groupby(['env','thr']).size()\n",
    "sns.set(font_scale=1.3)\n",
    "fg = sns.catplot(data = me.query('thr == @thr'), \n",
    "                 kind='violin', y='err_sens', \n",
    "    x='env', col='thr', order=['stable','random'],\n",
    "                palette = palette_stabrand)\n",
    "#addTitleInfo(fg.axes.flatten()[0])\n",
    "for ax in fg.axes.flatten():\n",
    "    ax.axhline(y=0, c='r', ls=':'); #ax.set_ylim(-5,5)\n",
    "    \n",
    "from figure.mystatann import plotSigAll\n",
    "ylast, ttrssig_env = plotSigAll(ax, 0.83, 0.05, ticklen=0.02,\n",
    "       df=me, coln='err_sens', colpair = 'env')\n",
    "    \n",
    "ax.annotate('C', xy=(0, 1), xytext=(-60, 60), \n",
    "      fontsize=19, fontweight='bold', va='top', ha='left',\n",
    "      xycoords='axes fraction', textcoords='offset points')\n",
    "fg.set_ylabels('Error sensitivity')\n",
    "ax.set_xlabel('Environment')\n",
    "\n",
    "fign = 'Fig2C'\n",
    "plt.savefig(pjoin(path_fig,fign + '.svg'))\n",
    "plt.savefig(pjoin(path_fig,fign + '.pdf'))\n",
    "plt.show()\n",
    "    \n",
    "###################\n",
    "# non-pooled stages and env comparison\n",
    "me = dfall.groupby(['thr','subject','ps2_'], observed=True).\\\n",
    "    mean(numeric_only=1).reset_index()\n",
    "me_ps = me\n",
    "#me.groupby(['ps_','thr']).size()\n",
    "sns.set(font_scale=1.3)\n",
    "fg = sns.catplot(data = me.query('thr == @thr'), kind='violin', y='err_sens', \n",
    "    x='ps2_', col='thr', order=['pre','pert','washout','rnd'],\n",
    "                hue = 'ps2_')\n",
    "for ax in fg.axes.flatten():\n",
    "    ax.axhline(y=0, c='r', ls=':'); #ax.set_ylim(-5,5)\n",
    "#addTitleInfo(fg.axes.flatten()[0])\n",
    "#plt.gcf().add_subplot_labels(['C'])\n",
    "\n",
    "ylast, ttrssig_ps = plotSigAll(ax, 2.05, 0.14, ticklen=0.05,\n",
    "       df=me, coln='err_sens', colpair = 'ps2_', fontsize = 10)\n",
    "\n",
    "ax.annotate('D', xy=(0, 1), xytext=(-60, 60), \n",
    "      fontsize=19, fontweight='bold', va='top', ha='left',\n",
    "      xycoords='axes fraction', textcoords='offset points')\n",
    "\n",
    "ax.set_xlabel('Experiment stage')\n",
    "#ax.set_xticklabels(['No perturbation','Perturbation','Washout','Random'], \n",
    "#                   rotation=30)\n",
    "ps_2nice = dict( zip(['pre','pert','washout','rnd'], \n",
    "        ['No perturbation','Perturbation','Washout','Random']) )\n",
    "renameTickLabels(ax, ps_2nice, rotation=30)\n",
    "\n",
    "fg.set_ylabels('Error sensitivity')\n",
    "fign = 'Fig2D'\n",
    "plt.savefig(pjoin(path_fig,fign + '.svg'))\n",
    "plt.savefig(pjoin(path_fig,fign + '.pdf'))\n",
    "\n",
    "#fg.set_titles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381f2b31",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f37bfe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# to put in results\n",
    "ttrs = []\n",
    "for env in me_env.env.unique():\n",
    "    r = compare0(me_env.query('env == @env'),'err_sens',cols_addstat=['err_sens'])\n",
    "    r['env'] = env\n",
    "    ttrs += [r]\n",
    "ttrs_pos = pd.concat(ttrs).query('pval <= 0.05').set_index('env')\n",
    "assert len(ttrs_pos) == 2\n",
    "display(ttrs_pos)\n",
    "\n",
    "s0 = 'Averages of ES within participant. \\n'\n",
    "for env in me_env.env.unique():\n",
    "    row = ttrs_pos.loc[env]\n",
    "    s = (f\"{env} ES mean = {row['err_sens_mean']:.2f} (std = {row['err_sens_std']:.2f}),\"\n",
    "        f\" ES > 0 p-value = {row['pval']:.2e}. \\n\" )\n",
    "    s = s[0].upper() + s[1:]\n",
    "    s0 += s\n",
    "\n",
    "display(ttrssig_env)\n",
    "row = ttrssig_env.iloc[0]\n",
    "\n",
    "s = f\"Stable > random T={row['T']:.2f}, p-value={row['pval']:.2e}\"\n",
    "print(s0)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546a5c12",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#comparePairs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c0c3f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# to put in results\n",
    "#cocoln = 'ps2_'\n",
    "ttrs = []\n",
    "for ps in me_ps.ps2_.unique():\n",
    "    r = compare0(me_ps.query('ps2_ == @ps'),'err_sens',cols_addstat=['err_sens'])\n",
    "    r['ps2_'] = ps\n",
    "    ttrs += [r]\n",
    "ttrs_pos = pd.concat(ttrs).query('pval <= 0.05')\n",
    "assert len(ttrs_pos) == 4\n",
    "display(ttrs_pos)\n",
    "ttrs_pos = ttrs_pos.set_index('ps2_')\n",
    "\n",
    "s0 = 'Averages of ES within participant: \\n'\n",
    "for ps in me_ps.ps2_.unique():\n",
    "    row = ttrs_pos.loc[ps]\n",
    "    s = (f\"{ps} ES mean = {row['err_sens_mean']:.2f} (std = {row['err_sens_std']:.2f}),\"\n",
    "        f\" ES > 0 p-value = {row['pval']:.2e}. \\n\" )\n",
    "    s = s[0].upper() + s[1:]\n",
    "    s0 += s\n",
    "\n",
    "#display(ttrssig_ps)\n",
    "#row = ttrssig_ps.iloc[0]\n",
    "\n",
    "ttrssig_ps,_ = comparePairs(me_ps, 'err_sens', 'ps2_', alt=['greater'], \n",
    "                            paired=True, updiag=False)\n",
    "display(ttrssig_ps[ttrssig_ps.columns[-5:]])\n",
    "s1 = ''\n",
    "for i,row in ttrssig_ps.iterrows():\n",
    "    ttstr = row['ttstr']\n",
    "    s = ttstr.replace(row['val2'], ps_2nice[row['val2']] ).replace(row['val1'],\n",
    "                                                                   ps_2nice[row['val1']] )    \n",
    "    s += f\" T={row['T']:.2f}, p-value={row['pval']:.2e}; \\n\"\n",
    "    s1 += s\n",
    "#s = f\"Stable > random p-value={row['pval']:.2e}\"\n",
    "print(s0)\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685f4687",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#me_ps.query('ps2_.isin(@psvals)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f248c4bd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "me_ps.ps2_.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b201e4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show that dif between pert and rand is not there\n",
    "psvals = [\"pert\",\"rnd\"]\n",
    "ttrssig,ttrssig_all = comparePairs(me_ps.query('ps2_.isin(@psvals)'),\n",
    "                         'err_sens', 'ps2_', alt=['two-sided'], \n",
    "                        paired=True, updiag=True, pooled=0)\n",
    "display(ttrssig_all)\n",
    "assert len(ttrssig_all) == 1\n",
    "row = ttrssig_all.iloc[0]\n",
    "if row['pval'] > 0.05:    \n",
    "    s = 'The difference between ES in '\n",
    "    s += '{} and {} conditions is not significant ('.format( \n",
    "        ps_2nice[row['val2']], ps_2nice[row['val1'] ] )\n",
    "    s += f\" T={row['T']:.2f}, p-value={row['pval']:.2e}).\"\n",
    "    #s1 += s\n",
    "    print(s)\n",
    "else:\n",
    "    print('Actually there is significance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f551d72",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Fig 2 AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4c356b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tr = np.arange(len(pert))\n",
    "c = 1 / np.pi  * 180\n",
    "thrs = [\"mestd*0\"]\n",
    "qs = 'thr in @thrs'\n",
    "for lablet,varn,pertc in [('A', 'error_pscadj', 1.), \n",
    "                   ('B', 'err_sens', 0.06)]:\n",
    "    #varn = 'org_feedback'\n",
    "    #for varn in     \n",
    "    #for truncs, df in zip(['truncate q=5%','truncate no'],[dfc, dfc0]):\n",
    "    #for truncs, dfall in zip(['truncate q=5%'],[df_]):\n",
    "    varn_eff = varn\n",
    "    if varn.startswith('org_feedback'):\n",
    "        dfall['vtp'] = np.array(dfall[varn]) * c# - 180\n",
    "        varn_eff = 'vtp'\n",
    "    elif varn.startswith('error'):\n",
    "        dfall['vtp'] = np.array(dfall[varn]) * c \n",
    "        varn_eff = 'vtp'\n",
    "    #elif varn.startswith('err_sens'):\n",
    "    #    pert_shift = \n",
    "        #df['vtp'] = np.array(df[varn]) \n",
    "        #varn_eff = 'vtp'\n",
    "\n",
    "    plt.figure(figsize=(12,4))\n",
    "    fg = sns.relplot(data=dfall.query(qs),\n",
    "        kind='line', x=\"trials\", y=varn_eff, \n",
    "        col='thr', estimator='mean', errorbar='sd', height = 4, aspect=2.5)\n",
    "\n",
    "    for ax in fg.axes.flatten():\n",
    "        ax.plot(tr, pert * pertc, c='violet', ls= '--')\n",
    "        ax.plot(tr, envv * 30 * pertc, c='black', lw=0, marker='.' ,alpha=0.2)\n",
    "        #ax.set_title(f'{varn}  {truncs}')\n",
    "        ax.set_ylabel(varn )\n",
    "    if varn.startswith('error_'):\n",
    "        fg.set_ylabels('Angular error [deg]')\n",
    "        fg.set_titles('Error dynamics')\n",
    "    else:\n",
    "        fg.set_ylabels('Error sensitivity')\n",
    "        fg.set_titles('Error sensitivity dynamics')\n",
    "    fg.set_xlabels('Trial number')\n",
    "    \n",
    "    fign = 'Fig2'+lablet\n",
    "    plt.savefig(pjoin(path_fig,fign + '.svg'))\n",
    "    plt.savefig(pjoin(path_fig,fign + '.pdf'))\n",
    "\n",
    "    \n",
    "     \n",
    "    #addTitleInfo(fg.axes.flatten()[0])\n",
    "    ax.annotate(lablet, xy=(0, 1), xytext=(-60, 20), \n",
    "      fontsize=19, fontweight='bold', va='top', ha='left',\n",
    "      xycoords='axes fraction', textcoords='offset points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8447c1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b061da24",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#   debug large ES\n",
    "# dfall.query('err_sens.abs() > 10')\\\n",
    "#     [['subject','trials','error','err_sens','prev_error']]\n",
    "\n",
    "# t1,t2 = 20,49\n",
    "# qs = 'trials <= @t2 and trials >= @t1'\n",
    "# fg = sns.relplot(data=dfall.query(qs),\n",
    "#     kind='line', x=\"trialwe\", y='err_sens', \n",
    "#     estimator='mean', errorbar='sd', height = 4, aspect=2.5)\n",
    "# fg.refline(x=24)\n",
    "\n",
    "# df_all_multi_tsz['trial_group_col_calc'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae7587c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### within target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c20392",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from figure.plots import relplot_multi\n",
    "df2 = df_all_multi_tsz.\\\n",
    "    query('trial_shift_size == 1 and '\n",
    "          'trial_group_col_calc.isin([\"trialwtgt_we\",\"trialwe\"]) '\n",
    "            ' and retention_factor_s == \"1.000\"').copy()\n",
    "\n",
    "dfni = df2.loc[~np.isinf(df2['err_sens'])]\n",
    "dfni_g = dfni.query('err_sens.abs() <= @ES_thr')\n",
    "nremoved_pooled = len(dfni) - len(dfni_g)\n",
    "\n",
    "sz = dfni.groupby(['subject'],observed=True).size()\n",
    "sz_g = dfni_g.groupby(['subject'],observed=True).size()\n",
    "mpct = ((sz - sz_g) / sz).mean() * 100\n",
    "print(f'Mean percentage of removed trials = {mpct:.2f}%, '\n",
    "      f'pooled = {nremoved_pooled / len(dfni) * 100:.2f}%')\n",
    "\n",
    "dfall2 = truncateDf(dfni_g, 'err_sens', q=0.0, infnan_handling='discard', \n",
    "                   cols_uniqify = ['subject','env','trial_group_col_calc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6caa37",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fg,df= relplot_multi(data=dfall2,\n",
    "              ys=[['error_pscadj'],\n",
    "                 ['err_sens']], x='trials',\n",
    "                height=4,aspect=2, kind='line',\n",
    "                     col = 'trial_group_col_calc',\n",
    "                    estimator='mean', errorbar='sd')\n",
    "fg.refline(y=0)\n",
    "#r[0].refline(x=526)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a1949a",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Corr with abs error (and prev) for Fig 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7475589",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# correlation between ES and abs err within env\n",
    "dfs = []\n",
    "for varn in ['error','error_abs','prev_error','prev_error_abs']:\n",
    "    def f(df_):\n",
    "        #df_.query('err_sens < inf')\n",
    "        r = pg.corr( df_[varn], df_['err_sens'],  method='spearman')\n",
    "        return r\n",
    "    corrs_abserr_per_subj = dfall.groupby(['thr','subject','env'],\n",
    "                                         observed=True).apply(f)\n",
    "    #display(corrs_abserr_per_subj)\n",
    "\n",
    "    corrs_abserr = dfall.groupby(['thr','env'], observed=True).apply(f)\n",
    "    #display(corrs_abserr)\n",
    "\n",
    "    def f(df_):    \n",
    "        a = df_.query('env == \"stable\"')['r']\n",
    "        b = df_.query('env == \"random\"')['r']\n",
    "        #print(len(a),len(b),a.abs().min(),b.abs().min())\n",
    "        rs = []\n",
    "        for alt in ['two-sided','greater','less']:\n",
    "            #print(a.values, b.values)\n",
    "            rs.append( pg.ttest( a, b, alternative = alt) )\n",
    "        return pd.concat(rs)\n",
    "\n",
    "    #%debug\n",
    "    import warnings\n",
    "    #warnings.filterwarnings(\"error\")\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    #with warnings.catch_warnings(record=True) as w:\n",
    "    ttest_of_corr_abserr = corrs_abserr_per_subj.\\\n",
    "        groupby(['thr']).apply(f)\n",
    "    ttest_of_corr_abserr['varn'] = varn\n",
    "    dfs += [ttest_of_corr_abserr]\n",
    "\n",
    "dfr = pd.concat(dfs)\n",
    "dfr = dfr.rename(columns={'p-val':'pval'})\n",
    "\n",
    "corrs_abserr = corrs_abserr.rename(columns={'p-val':'pval'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5441d2c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#dfall.prev_error_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6e5704",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(getAddInfo())\n",
    "thrs = [ \"mestd*0\"]\n",
    "qs = 'thr in @thrs'\n",
    "corrs_ = corrs_abserr.query(qs)\n",
    "display( corrs_[corrs_['pval'] < 5e-2] )\n",
    "with pd.option_context('display.max_rows', 500):\n",
    "    dfr_ = dfr.query('varn == \"prev_error_abs\" and pval < 0.05')\n",
    "    display(dfr_.query(qs))\n",
    "    #display(dfr_.query('thr == \"mestd*1.0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806d7fdb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pg.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1880caff",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# signed error\n",
    "def f(df_):\n",
    "    r = pg.corr( df_['error'], df_['err_sens'],  method='spearman')\n",
    "    return r\n",
    "corrs_err_per_subj = dfall.groupby(['thr','subject','env']).apply(f)\n",
    "\n",
    "# preverror\n",
    "def f(df_):\n",
    "    r = pg.corr( df_['prev_error_abs'], df_['err_sens'],  method='spearman')\n",
    "    return r\n",
    "corrs_prevabserr_per_subj = dfall.groupby(['thr','subject','env']).apply(f)\n",
    "\n",
    "def f(df_):    \n",
    "    a = df_.query('env == \"stable\"')['r']\n",
    "    b = df_.query('env == \"random\"')['r']\n",
    "    rs = []\n",
    "    for alt in ['two-sided','greater','less']:\n",
    "        rs.append( pg.ttest( a, b, alternative = alt) )\n",
    "    return pd.concat(rs)\n",
    "ttest_of_corr_prevabserr = corrs_prevabserr_per_subj.groupby(['thr']).apply(f)\n",
    "display(ttest_of_corr_prevabserr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f1080f",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Fig 3 (Within pert stage time resolved plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f42292",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def f(df_):\n",
    "    #df_.query('err_sens < inf')\n",
    "    r = np.cov( df_['err_sens'].values, df_['prev_error_abs'].values  )\n",
    "    return r[0,1] / r[1,1]\n",
    "covs_prevabserr_per_subj = dfall.groupby(['thr','subject','env']).apply(f)\n",
    "covs_prevabserr_per_subj = covs_prevabserr_per_subj.to_frame().reset_index().rename(columns={0:'covabsprev'})\n",
    "\n",
    "display(covs_prevabserr_per_subj)\n",
    "dfall_aug = dfall.merge(covs_prevabserr_per_subj, on = ['thr','subject','env'])\n",
    "\n",
    "dfall_aug = dfall_aug.assign(err_sens_prevabserrcorr = \\\n",
    "            dfall_aug['err_sens'] - dfall_aug['prev_error_abs'] * dfall_aug['covabsprev'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514d9aa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfall = dfall.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcda0de",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfc = dfall_aug.query('thr == \"mestd*0\"')\n",
    "print(len(dfc))\n",
    "dfc['trialwpertstage_wb'] = dfc['trialwpertstage_wb'].\\\n",
    "    where(dfc['environment'] == 0, dfc['trialwb'])\n",
    "dfc['trialwpertstage_wb'] = dfc['trialwpertstage_wb'].astype(int)\n",
    "\n",
    "assert not dfc.duplicated(['subject','trials']).any()\n",
    "# nan-ify after pause\n",
    "dfc.loc[dfc['trialwb'] == 0, 'err_sens'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888395b4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a03de37",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Fig 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe29e44",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# calc slopes\n",
    "method = 'pearson'\n",
    "corrs_per_subj_me_,_  = corrMean(dfall, stagecol = 'ps2_',\n",
    "                                             method=method)\n",
    "pcorrs_per_subj_me_,_ = corrMean(dfall, covar = 'prev_error_abs', \n",
    "                               stagecol = 'ps2_',\n",
    "                                              method=method)\n",
    "\n",
    "pswb2r = corrs_per_subj_me_.loc[('mestd*0',slice(None))].\\\n",
    "    to_dict()\n",
    "print(pswb2r)\n",
    "def f(row):\n",
    "    #ps = row['pert_stage_wb']\n",
    "    ps = row['ps2_']\n",
    "    r = pswb2r['r'][ps]\n",
    "    std_x = pswb2r['std_x'][ps]\n",
    "    mean_x = pswb2r['mean_x'][ps]\n",
    "    std_y = pswb2r['std_y'][ps]\n",
    "    mean_y = pswb2r['mean_y'][ps]\n",
    "    xs = row['trialwpertstage_wb']\n",
    "    return mean_y + r * (xs - mean_x) / std_x * std_y \n",
    "dfc['pred'] = dfc.apply(f, axis=1)\n",
    "#corrs_per_subj_me_ES['r'] * dfc['error_abs']\n",
    "\n",
    "pswb2r = pcorrs_per_subj_me_.loc[('mestd*0',slice(None))].\\\n",
    "    to_dict()\n",
    "print(pswb2r)\n",
    "def f(row):\n",
    "    #ps = row['pert_stage_wb']\n",
    "    ps = row['ps2_']\n",
    "    if ps == -1:\n",
    "        return None\n",
    "    r = pswb2r['r'][ps]\n",
    "    std_x = pswb2r['std_x'][ps]\n",
    "    mean_x = pswb2r['mean_x'][ps]\n",
    "    std_y = pswb2r['std_y'][ps]\n",
    "    mean_y = pswb2r['mean_y'][ps]\n",
    "    #mean_z =  pswb2r['mean_z'][ps]\n",
    "    xs = row['trialwpertstage_wb']\n",
    "    return mean_y + r * (xs - mean_x) / std_x * std_y# + mean_z\n",
    "dfc['ppred'] = dfc.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaba1b5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pcorrs_per_subj.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c77f68",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hue_order = dfc['pert_stage_wb'].unique()\n",
    "col_order = ['pre', 'pert', 'washout', 'rnd']\n",
    "hues = [[0],[1,3],[2,4],[5]]\n",
    "\n",
    "# TODO: add fit\n",
    "# TODO: start of pert\n",
    "# TODO: sd instead of se\n",
    "palette=['blue', 'orange', 'green', 'olive','cyan','brown']\n",
    "df_ = dfc.query('trial_shift_size == 1')\n",
    "fg = sns.relplot(data=df_, kind='line',\n",
    "            x='trialwpertstage_wb', col='ps2_',\n",
    "           y='err_sens', hue='pert_stage_wb',\n",
    "                 ci = 'sd', palette = palette,\n",
    "           facet_kws={'sharex':False},\n",
    "                 hue_order=hue_order,\n",
    "            col_order = col_order, legend=None)\n",
    "# for ax in fg.axes.flatten():\n",
    "#     ax.axhline(0,ls=':',c='red', alpha=0.7)\n",
    "    \n",
    "for i, ax in enumerate(fg.axes.flat):\n",
    "    col_ = fg.col_names[i]\n",
    "    ax.set_title(ps_2nice[ax.get_title()[7:]] )\n",
    "    if col_ == 'rnd':\n",
    "        continue\n",
    "    sp = np.array(palette)[hues[i]]\n",
    "    sp = list(sp)\n",
    "    sns.lineplot(data=df_[df_['ps2_'] == col_], \n",
    "        x='trialwpertstage_wb', y='pred', \n",
    "        hue='pert_stage_wb', ax=ax, legend=None,\n",
    "                palette = sp, dashes=[4,2])\n",
    "    \n",
    "    \n",
    "#addTitleInfo(fg.axes.flat[0])\n",
    "    \n",
    "print(fg.hue_kws, fg.hue_names)\n",
    "fg.refline(y=0, color='red')\n",
    "#fg.map(plt.hist, 'tip').refline(0.15)\n",
    "    \n",
    "#fg.set_titles('{col_name}')\n",
    "fg.set_xlabels('Trial number')\n",
    "fg.set_ylabels('Error sensitivy')\n",
    "    \n",
    "lablet = 'A'\n",
    "ax = fg.axes.flat[0]\n",
    "ax.annotate(lablet, xy=(0, 1), xytext=(-60, 40), \n",
    "  fontsize=19, fontweight='bold', va='top', ha='left',\n",
    "  xycoords='axes fraction', textcoords='offset points')\n",
    "fnfig = pjoin(path_fig, f'Fig3_{lablet}_dynESpert_stage.pdf')\n",
    "plt.savefig(fnfig)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "###############################\n",
    "\n",
    "#vn = 'err_sens_abserrcorr'\n",
    "vn = 'err_sens_prevabserrcorr'\n",
    "palette=['blue', 'orange', 'green', 'olive','cyan','brown']\n",
    "df_ = dfc.query('trial_shift_size == 1')\n",
    "fg = sns.relplot(data=df_, kind='line',\n",
    "            x='trialwpertstage_wb', col='ps2_',\n",
    "           y=vn, hue='pert_stage_wb',\n",
    "                 ci = 'sd', palette = palette,\n",
    "           facet_kws={'sharex':False},\n",
    "                 hue_order=hue_order,\n",
    "            col_order = col_order, legend=None)\n",
    "# for ax in fg.axes.flatten():\n",
    "#     ax.axhline(0,ls=':',c='red', alpha=0.7)\n",
    "    \n",
    "for i, ax in enumerate(fg.axes.flat):\n",
    "    col_ = fg.col_names[i]\n",
    "    ax.set_title(ps_2nice[ax.get_title()[7:]] )\n",
    "    if col_ == 'rnd':\n",
    "        continue\n",
    "    sp = np.array(palette)[hues[i]]\n",
    "    sp = list(sp)\n",
    "    sns.lineplot(data=df_[df_['ps2_'] == col_], \n",
    "        x='trialwpertstage_wb', y='ppred', \n",
    "        hue='pert_stage_wb', ax=ax, legend=None,\n",
    "                palette = sp, dashes=[4,2])        \n",
    "    \n",
    "#addTitleInfo(fg.axes.flat[0])\n",
    "    \n",
    "print(fg.hue_kws, fg.hue_names)\n",
    "fg.refline(y=0, color='red')\n",
    "\n",
    "#fg.set_titles('{col_name}')\n",
    "fg.set_xlabels('Trial number')\n",
    "fg.set_ylabels('Error sensitivy conditioned\\non previous absolute error')\n",
    "\n",
    "\n",
    "lablet = 'B'\n",
    "ax = fg.axes.flat[0]\n",
    "ax.annotate(lablet, xy=(0, 1), xytext=(-60, 40), \n",
    "  fontsize=19, fontweight='bold', va='top', ha='left',\n",
    "  xycoords='axes fraction', textcoords='offset points')\n",
    "fnfig = pjoin(path_fig, f'Fig3_{lablet}_dynESpert_stage.pdf')\n",
    "plt.savefig(fnfig)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64b5cd3",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#vn = 'err_sens_abserrcorr'\n",
    "vn = 'err_sens_prevabserrcorr'\n",
    "palette=['blue', 'orange', 'green', 'olive','cyan','brown']\n",
    "df_ = dfc.query('trial_shift_size == 1')\n",
    "fg = sns.relplot(data=df_, kind='line',\n",
    "            x='trialwpertstage_wb', col='ps2_',\n",
    "           y=vn, hue='pert_stage_wb',\n",
    "                 ci = 'sd', palette = palette,\n",
    "           facet_kws={'sharex':False},\n",
    "                 hue_order=hue_order,\n",
    "            col_order = col_order, legend=None)\n",
    "# for ax in fg.axes.flatten():\n",
    "#     ax.axhline(0,ls=':',c='red', alpha=0.7)\n",
    "addTitleInfo(fg.axes.flat[0])\n",
    "    \n",
    "for i, ax in enumerate(fg.axes.flat):\n",
    "    col_ = fg.col_names[i]\n",
    "    if col_ == 'rnd':\n",
    "        continue\n",
    "    sp = np.array(palette)[hues[i]]\n",
    "    sp = list(sp)\n",
    "#     sns.lineplot(data=df_[df_['ps_'] == col_], \n",
    "#         x='trialwpertstage_wb', y='ppred', \n",
    "#         hue='pert_stage_wb', ax=ax, legend=None,\n",
    "#                 palette = sp, dashes=[4,2])\n",
    "print(fg.hue_kws, fg.hue_names)\n",
    "fg.refline(y=0, color='red')\n",
    "\n",
    "fg.set_titles('{col_name}')\n",
    "fg.set_xlabels('Trial number')\n",
    "fg.set_ylabels('Error sensitivy conditioned\\non absolut error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f4bc75",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c083de2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Fig-3 related stats print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a201ecbc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "method = 'spearman'\n",
    "_,corrs_per_subj  = corrMean(dfall, stagecol = 'ps2_', method=method)\n",
    "_,pcorrs_per_subj = corrMean(dfall, covar = 'prev_error_abs', \n",
    "        stagecol = 'ps2_', method=method)\n",
    "\n",
    "# stats for Fig 3 caption\n",
    "from behav_proc import compare0\n",
    "def f(df):\n",
    "    if len(df) == 0:\n",
    "        return None\n",
    "    ttrs = compare0(df, 'r', cols_addstat=['r'])\n",
    "    return ttrs\n",
    "\n",
    "print(getAddInfo())\n",
    "\n",
    "print('ps_-sep corr')\n",
    "ttrs = corrs_per_subj.\\\n",
    "    groupby(['ps2_']).apply(f)\n",
    "corrs_sig = ttrs.query('pval <= 0.05').reset_index()\n",
    "cols = ['ps2_','dof','T','pval','alt','ttstr','r_mean', 'r_std']\n",
    "display(corrs_sig[cols])\n",
    "\n",
    "print('ps_-sep partial corr')\n",
    "ttrs = pcorrs_per_subj.\\\n",
    "    groupby(['ps2_']).apply(f)\n",
    "pcorrs_sig = ttrs.query('pval <= 0.05').reset_index()\n",
    "display(pcorrs_sig[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbca421",
   "metadata": {
    "hidden": true,
    "tags": [
     "final_output"
    ]
   },
   "outputs": [],
   "source": [
    "corrmeth = corrs_per_subj['method'].unique()[0]\n",
    "for n,sig in zip([f'{corrmeth} correlations between trial number and ES within subject',\n",
    "                  ('Partial correlations between trial number and '\n",
    "                  'ES within subject, conditioned on absolute error size')],\n",
    "                 [corrs_sig, pcorrs_sig]):    \n",
    "    s = n + ': '\n",
    "    for irow,row in sig.iterrows():\n",
    "        psn = ps_2nice[row['ps2_']]\n",
    "        s += f\"{psn} mean r = {row['r_mean']:.3f} (std={row['r_std']:.3f}) \" +\\\n",
    "            f\"r{row['ttstr'][-4:]} p-val {row['pval']:.2e}; \"\n",
    "    print(s[:-2] + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e085ab31",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ps_2nice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874445a9",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Variability (compare with Tan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6bd6f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d004743",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "histlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4447e46",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#dfc = dfall_aug.query('thr == \"mestd*1.0\"')\n",
    "#dfc = dfall.query('thr == \"mestd*1.0\"')\n",
    "# here we need all trials, w/o holes\n",
    "#dfc = df_wthr.copy()\n",
    "dfc = df.copy()\n",
    "\n",
    "assert not dfc.duplicated(['subject','trials']).any()\n",
    "\n",
    "## corr ES and variance (and other statistics), fixed histlen across subjects\n",
    "\n",
    "from behav_proc import addWindowStatCols\n",
    "dfcs,dfcs_fixhistlen,dfcs_fixhistlen_untrunc,histlens  = addWindowStatCols(dfc, ES_thr)\n",
    "\n",
    "# this function just sets to NaNs large values\n",
    "# me_pct_excl is info on what was excluded: mean_excl - mean percentage of excluded, std_excl - std percentage of excluded\n",
    "dfcs_fixhistlen, me_pct_excl = behav_proc.truncLargeStats(dfcs_fixhistlen_untrunc, histlens, std_mult = 5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c530e1d9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfcs_fixhistlen_untrunc.to_pickle(pjoin(path_data,'dfcs_fixhistlen_untrunc.pkl') )\n",
    "dfcs_fixhistlen.to_pickle(pjoin(path_data,'dfcs_fixhistlen.pkl') )\n",
    "me_pct_excl.to_pickle(pjoin(path_data,'me_pct_excl.pkl') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e716808",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(dfcs_fixhistlen_untrunc), len(dfcs_fixhistlen), len(dfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02a9d14",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfcs_fixhistlen.groupby('subject').size().max(), dfcs_fixhistlen_untrunc.groupby('subject').size().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b41b0e4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfcs_fixhistlen_untrunc['error_pscadj_mav3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5fe7b9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mebad = me_pct_excl.query('not varn.str.startswith(\"error_pscadj_abs\") and mean_excl >= 3')\n",
    "display( mebad )\n",
    "\n",
    "display(me_pct_excl['mean_excl'].describe([0.95]))\n",
    "\n",
    "display(me_pct_excl.query('not varn.str.startswith(\"error_pscadj_abs\")')['mean_excl'].describe([0.95]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f69b989",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# np.std?\n",
    "\n",
    "# err = np.array([0.2195 , 0.2547]); \n",
    "# np.mean(err), np.std(err, ddof=1)\n",
    "\n",
    "# dfcs0.query('subject_ind == 1 and trialwb <= 4').sort_values('trials')\\\n",
    "#     [['trials','trialwb','error_pscadj_abs','error_pscadj_abs_mav3','error_pscadj_abs_std3',\n",
    "#       'error_pscadj_abs_Tan3','error_pscadj_abs_mav3','error_pscadj_abs_mavsq3',\n",
    "#      'error_pscadj_abs_var3']]\n",
    "\n",
    "# dfcs_fixhistlen.query('subject_ind == 1 and trialwb <= 4').sort_values('trials')\\\n",
    "#     [['trials','trialwb','error_pscadj_abs','error_pscadj_abs_mav3','error_pscadj_abs_std3',\n",
    "#       'error_pscadj_abs_Tan3','error_pscadj_abs_mav3','error_pscadj_abs_mavsq3',\n",
    "#      'error_pscadj_abs_var3']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130b4f43",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### supp plots1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef1b0c2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "varnames_toshow0 = []\n",
    "#for varn0 in ['error_pscadj_abs']:#'error_change']:\n",
    "for varn0 in ['error_pscadj']:#'error_change']:\n",
    "    for std_mavsz_ in range(2,30)[1::10]:\n",
    "        varnames_toshow0_ = []\n",
    "        for varn in  ['{varn0}_std{std_mavsz_}',\n",
    "                      '{varn0}_invstd{std_mavsz_}',                     \n",
    "                     '{varn0}_mavsq{std_mavsz_}',\n",
    "                      '{varn0}_mav_d_std{std_mavsz_}',\n",
    "                      '{varn0}_mav_d_var{std_mavsz_}',\n",
    "                     '{varn0}_Tan{std_mavsz_}']:        \n",
    "            varnames_toshow0_ += [varn.format(varn0=varn0,std_mavsz_=std_mavsz_)]\n",
    "        varnames_toshow0 += [varnames_toshow0_[:3],varnames_toshow0_[3:]]\n",
    "        \n",
    "        \n",
    "varnames_toshow0 = [['error_pscadj_std2','error_pscadj_std3',\n",
    "                     'error_pscadj_std27'],\n",
    "                     ['error_pscadj_invstd9','error_pscadj_invstd21',                     \n",
    "                   'error_pscadj_invstd15', 'error_pscadj_Tan5']]\n",
    "\n",
    "varnames_toshow = varnames_toshow0[0]\n",
    "varnames_toshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beba6238",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2b8d9b",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# density plots (in place defintion)\n",
    "def density_plot(x,y, **kwargs):\n",
    "    #ax = sns.kdeplot(data=dfcs_fixhistlen,\n",
    "    #           x='err_sens',y=vn, fill=False, hue=coln_col)\n",
    "    df__ = pd.DataFrame( np.array(list(zip(x,y))))\n",
    "    ax = sns.kdeplot(data=df__,\n",
    "            x=x,y=y, fill=True, **kwargs)\n",
    "    ax.axhline(0,ls=':', c='r')\n",
    "    ax.axvline(0,ls=':', c='r')\n",
    "    \n",
    "    \n",
    "for coln_col in ['env','ps_']:\n",
    "    for varnames_toshow in varnames_toshow0: #[varnames_toshow0[:6],varnames_toshow0[6:]]:\n",
    "        #dfcs_fixhistlen_untrunc\n",
    "        for vn in varnames_toshow:\n",
    "            g = sns.FacetGrid(col=coln_col, data=dfcs_fixhistlen)\n",
    "            g.map(density_plot, \"err_sens\", vn, label='')                                                        \n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0172de6a",
   "metadata": {
    "code_folding": [
     4
    ],
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# density plots\n",
    "ind = 0\n",
    "for coln_col in ['env','ps_']:\n",
    "    for varnames_toshow in varnames_toshow0:\n",
    "        fg,df = relplot_multi(sep_ys_by = 'row', kind='density',             \n",
    "                      data=dfcs_fixhistlen, x='err_sens',\n",
    "                      ys=[varnames_toshow], col=coln_col, palette='Set1',\n",
    "                     height = 5, facet_kws={'sharex':True, 'sharey':'row'})#, alpha=0.3)\n",
    "\n",
    "        for ax in fg.axes.flatten():\n",
    "            ttl = ax.get_title().replace('__varname = ','').replace('env = ','')\n",
    "            #ax.set_ylabel()\n",
    "            ax.set_title(ttl)\n",
    "        fg.refline(x=0)\n",
    "        fg.refline(y=0)\n",
    "        fg.fig.suptitle('Different statistics vs err sens')\n",
    "        plt.tight_layout()     \n",
    "        plt.savefig( pjoin(path_fig, f'ES2statDens_{varn0}_{coln_col}_{ind}.pdf') )\n",
    "        plt.close()\n",
    "        ind += 1\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84671b16",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# scatter plots, pooled\n",
    "from figure.plots import relplot_multi\n",
    "ind = 0\n",
    "for coln_col in ['env','ps_']:\n",
    "    for varnames_toshow in varnames_toshow0: #[varnames_toshow0[:6],varnames_toshow0[6:]]:\n",
    "        fg,df = relplot_multi(sep_ys_by = 'row',             \n",
    "              data=dfcs_fixhistlen, x='err_sens',\n",
    "              ys=varnames_toshow, col=coln_col, palette='Set1',\n",
    "             height = 5, alpha=0.3)\n",
    "        for ax in fg.axes.flatten():\n",
    "            ttl = ax.get_title().replace('__varname = ','').replace('env = ','')\n",
    "            ax.set_title(ttl)\n",
    "        fg.refline(x=0)\n",
    "        fg.refline(y=0)\n",
    "        fg.fig.suptitle('Different statistics vs err sens')\n",
    "        plt.tight_layout()     \n",
    "        plt.savefig( pjoin(path_fig, f'ES2stat_{varn0}_{coln_col}_{ind}.pdf') )\n",
    "        plt.close()\n",
    "        ind += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba57e9e3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mean over subjects\n",
    "ind = 0\n",
    "for coln_col in ['env','ps_']:\n",
    "    for varnames_toshow in varnames_toshow0: #[varnames_toshow0[:6],varnames_toshow0[6:]]:        \n",
    "        me = dfcs_fixhistlen.\\\n",
    "            groupby(['subject','env'], observed=True)\\\n",
    "            [['err_sens']+varnames_toshow].mean().reset_index()\n",
    "        \n",
    "        fg,df = relplot_multi(sep_ys_by = 'row', data=me, x='err_sens',\n",
    "                              ys=varnames_toshow, col=coln_col,\n",
    "                              height = 5, alpha=0.8, palette='Set1')\n",
    "        \n",
    "        for ax in fg.axes.flatten():\n",
    "            ttl = ax.get_title().replace('__varname = ','').replace('env = ','')\n",
    "            ax.set_title(ttl)\n",
    "        fg.refline(x=0)\n",
    "        fg.refline(y=0)\n",
    "        fg.fig.suptitle('Different statistics vs err sens')\n",
    "        plt.tight_layout()     \n",
    "        plt.savefig( pjoin(path_fig, f'ES2stat_mean_{varn0}_{coln_col}_{ind}.pdf') )\n",
    "        plt.close()\n",
    "        ind += 1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0650b16",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfcs_fixhistlen.duplicated(['subject','trials']).any()\n",
    "dfcs_fixhistlen.groupby(['subject']).trials.diff().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ca2f5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dynamics across time plots\n",
    "ind = 0\n",
    "for varnames_toshow in varnames_toshow0: #[varnames_toshow0[:6],varnames_toshow0[6:]]:\n",
    "    import gc;gc.collect()\n",
    "    fg,df__ = relplot_multi(sep_ys_by = 'row', data=dfcs_fixhistlen, x='trials',\n",
    "                          ys=varnames_toshow + ['err_sens'], hue='pert_stage', height = 5, kind='line',\n",
    "                         palette='Paired')\n",
    "    for ax in fg.axes.flatten():\n",
    "        ttl = ax.get_title().replace('__varname = ','').replace('env = ','')\n",
    "        ax.set_title(ttl)\n",
    "    fg.refline(x=0)\n",
    "    fg.refline(y=0)\n",
    "    fg.fig.suptitle('Different statistics vs err sens')\n",
    "    plt.tight_layout()    \n",
    "    plt.savefig( pjoin(path_fig, f'trial2stat_{varn0}_{ind}.pdf') )\n",
    "    plt.close()\n",
    "    ind += 1\n",
    "    \n",
    "    del df__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7af79b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "varnames_toshow = []\n",
    "for varn0 in ['error_pscadj_abs']:#'error_change']:\n",
    "    for std_mavsz_ in [2,3,4] + list(range(5,30) )[::3]:\n",
    "        #varnames_toshow0_ = []\n",
    "        for varn in  ['{varn0}_Tan{std_mavsz_}']:        \n",
    "            varnames_toshow += [varn.format(varn0=varn0,std_mavsz_=std_mavsz_)]\n",
    "        #varnames_toshow0 += [varnames_toshow0_[:3],varnames_toshow0_[3:]]\n",
    "varnames_toshow        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab34aae7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot Tan vesions\n",
    "import gc;gc.collect()\n",
    "ind = 0\n",
    "# fg,df__ = relplot_multi(sep_ys_by = 'col', data=dfcs_fixhistlen, x='trials',\n",
    "#                       ys=varnames_toshow + ['err_sens'], \n",
    "#                         hue='pert_stage', height = 5, kind='line',\n",
    "#                      palette='Set1')\n",
    "fg,df__ = relplot_multi(sep_ys_by = 'row', data=dfcs_fixhistlen, x='trials',\n",
    "                          ys=varnames_toshow + ['err_sens'], hue='pert_stage', \n",
    "                        height = 5, kind='line',\n",
    "                         palette='Paired')\n",
    "\n",
    "for ax in fg.axes.flatten():\n",
    "    ttl = ax.get_title().replace('__varname = ','').replace('env = ','')\n",
    "    ax.set_title(ttl)\n",
    "fg.refline(x=0)\n",
    "fg.refline(y=0)\n",
    "fg.fig.suptitle('Different statistics vs err sens')\n",
    "plt.tight_layout()    \n",
    "plt.savefig( pjoin(path_fig, f'trial2Tan_{varn0}_{ind}h.pdf') )\n",
    "plt.close()\n",
    "ind += 1\n",
    "\n",
    "del df__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90815b6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show that low history stds are related to erro change\n",
    "sns.scatterplot(data=df_, x='error_pscadj_change',\n",
    "               y='error_pscadj_std2')\n",
    "plt.figure()\n",
    "sns.scatterplot(data=df_, x='error_pscadj_change',\n",
    "               y='error_pscadj_std3')\n",
    "\n",
    "plt.figure()\n",
    "sns.scatterplot(data=df_, x='error_pscadj_change',\n",
    "               y='error_pscadj_std10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c650d74e",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### supp plots2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46817ade",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df__ = dfcs.query('thr == \"mestd*1.0\"')\n",
    "df__['err_sens'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33801cf7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40443fa7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfcs[dfcs['subject'].isin(subjects[:2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65095af5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with warnings.catch_warnings():\n",
    "#     warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "#     sns.catplot(data=dfcs[dfcs['subject'].isin(subjects[:2])], \n",
    "#                 kind='scatter',\n",
    "#                 y='err_sens', \n",
    "#             x=f'error_pscadj_std5', col='subject',\n",
    "#             col_wrap=5, hue='env' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934112a1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#dfcs_ = dfcs[dfcs['subject'].isin(subjects[:2])]\n",
    "# one subj\n",
    "for subj in subjects[:6]:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "        sns.pairplot(data=dfcs.query('subject == @subj'), \n",
    "                     vars=['err_sens',\n",
    "                    f'error_pscadj_std5',\n",
    "                  f'error_pscadj_invstd5' ], hue='env' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5559ee",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# all subj\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "    sns.pairplot(data=dfcs, vars=['err_sens',f'error_pscadj_std5',\n",
    "                              f'error_pscadj_invstd5' ], hue='env' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dc78de",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "    sns.pairplot(data=dfcs.query('env == \"stable\"'), \n",
    "             vars=['err_sens',f'error_pscadj_std5',\n",
    "                              f'error_pscadj_invstd5',\n",
    "                               f'error_pscadj_mav5',\n",
    "                   f'error_pscadj_mavsq5',\n",
    "                   f'error_pscadj_mav_d_std5',\n",
    "                   f'error_pscadj_mav_d_var5',\n",
    "                  f'error_pscadj_Tan5' ],corner=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb37a520",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905e99ce",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Compute corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a75b348",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from behav_proc import compare0\n",
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b14d580",
   "metadata": {
    "code_folding": [
     57
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# compute corrs within subject\n",
    "# env\n",
    "import pingouin as pg\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import product\n",
    "import warnings\n",
    "\n",
    "def run_corr(df_big, corr_method, cocoln, std_mavsz_, varn0, varn_suffix):\n",
    "    def f(df_):\n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            warnings.filterwarnings('ignore',category=UserWarning)\n",
    "            warnings.filterwarnings('ignore',category=RuntimeWarning)\n",
    "\n",
    "            r = pg.corr( df_[varn], df_['err_sens'],  method=corr_method)\n",
    "        r['method'] = corr_method\n",
    "        return r\n",
    "    \n",
    "    #dfcs_fixhistlen, cocoln, std_mavsz_, varn0, varn_suffix = args\n",
    "    varn = f'{varn0}_{varn_suffix}{std_mavsz_}'\n",
    "    #cols = ['thr','subject']\n",
    "    cols = ['subject']\n",
    "    if cocoln != 'None':\n",
    "        cols += [cocoln]\n",
    "    assert not df_big.duplicated(cols + ['trials']).any()\n",
    "    corrs_per_subj = df_big.groupby(cols, \n",
    "        observed=True).apply(f, include_groups=False)\n",
    "    corrs_per_subj = corrs_per_subj.rename(columns={'p-val':'pval'})\n",
    "    corrs_per_subj['std_mavsz'] = std_mavsz_\n",
    "    corrs_per_subj['varn'] = varn\n",
    "    corrs_per_subj['cocoln'] = cocoln\n",
    "    \n",
    "    print(cocoln, std_mavsz_, varn0, varn_suffix)\n",
    "    return corrs_per_subj.reset_index()\n",
    "\n",
    "# if use shepherd, it is rather slow even in parallel mode\n",
    "#corr_methods = ['spearman','shepherd']\n",
    "corr_methods = ['spearman']\n",
    "cocols = ['None', 'env', 'ps2_']\n",
    "#std_mavsz_range = range(2, maxhl+1, 3)\n",
    "std_mavsz_range = histlens\n",
    "varn0s = ['error_pscadj', 'error_pscadj_abs']\n",
    "varn_suffixes = ['std', 'invstd', 'mavsq', 'mav_d_std', 'mav_d_var', 'Tan']\n",
    "args = list(product(corr_methods, cocols, std_mavsz_range, varn0s, varn_suffixes))\n",
    "print(len(args))\n",
    "\n",
    "n_jobs = 40\n",
    "\n",
    "ind = 0\n",
    "if n_jobs > 1:\n",
    "    # Execute in parallel\n",
    "    #backend = 'multiprocessing' # 'loky'\n",
    "    backend = 'loky' \n",
    "    prlcorr = Parallel(n_jobs=n_jobs, backend = backend)\\\n",
    "        (delayed(run_corr)( dfcs_fixhistlen,*arg ) for arg in args)\n",
    "    \n",
    "    cocoln2corrs_per_subj = pd.concat(prlcorr)\n",
    "else:\n",
    "    raise ValueError('I m lazy to implement')\n",
    "    \n",
    "#cocoln2corrs_per_subj = {}\n",
    "#dfs = []\n",
    "# for cocoln in ['None', 'env','ps_']:\n",
    "#     for std_mavsz_ in range(2,30):\n",
    "#         print(cocoln, std_mavsz_)\n",
    "#         for varn0 in ['error_pscadj','error_pscadj_abs']:#'error_change']:\n",
    "#             for varn in  [f'{varn0}_std{std_mavsz_}',\n",
    "#                           f'{varn0}_invstd{std_mavsz_}',                     \n",
    "#                          f'{varn0}_mavsq{std_mavsz_}',\n",
    "#                           f'{varn0}_mav_d_std{std_mavsz_}',\n",
    "#                           f'{varn0}_mav_d_var{std_mavsz_}',\n",
    "#                          f'{varn0}_Tan{std_mavsz_}']:\n",
    "#                 def f(df_):\n",
    "#                     r = pg.corr( df_[varn], df_['err_sens'],  method='spearman')\n",
    "#                     r['method'] = 'spearman'\n",
    "#                     return r\n",
    "#                 #cols = ['thr','subject']\n",
    "#                 cols = ['subject']\n",
    "#                 if cocoln != 'None':\n",
    "#                     cols += [cocoln]\n",
    "#                 assert not dfcs_fixhistlen.duplicated(cols + ['trials']).any()\n",
    "#                 corrs_per_subj = dfcs_fixhistlen.groupby(cols, \n",
    "#                     observed=True).apply(f, include_groups=False)\n",
    "#                 corrs_per_subj = corrs_per_subj.rename(columns={'p-val':'pval'})\n",
    "#                 corrs_per_subj['std_mavsz'] = std_mavsz_\n",
    "#                 corrs_per_subj['varn'] = varn\n",
    "#                 dfs += [corrs_per_subj.reset_index()]\n",
    "#         #display(corrs_per_subj)\n",
    "#     corrs_per_subj = pd.concat(dfs, ignore_index=1)\n",
    "#     cocoln2corrs_per_subj[cocoln] =     corrs_per_subj \n",
    "\n",
    "# for cocoln in cocoln2corrs_per_subj:\n",
    "#     cocoln2corrs_per_subj[cocoln]['cocoln'] = cocoln\n",
    "#cocoln2corrs_per_subj_ = pd.concat(cocoln2corrs_per_subj.values())\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67543640",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# compute corrs after average across subjects (pretty useless acutally) \n",
    "# env\n",
    "std_mavsz_range_ = list(range(3,6)) + list( range(6, maxhl+1, 3) )\n",
    "dfs = []\n",
    "cocoln2corrs_mesubj = {}\n",
    "for cocoln in ['None', 'env','ps2_']:\n",
    "    for std_mavsz_ in std_mavsz_range_:\n",
    "        print(cocoln, std_mavsz_)\n",
    "        for varn0 in ['error_pscadj','error_pscadj_abs']:#'error_change']:\n",
    "            for varn in  [f'{varn0}_std{std_mavsz_}',\n",
    "                          f'{varn0}_invstd{std_mavsz_}',                     \n",
    "                         f'{varn0}_mavsq{std_mavsz_}',\n",
    "                          f'{varn0}_mav_d_std{std_mavsz_}',\n",
    "                          f'{varn0}_mav_d_var{std_mavsz_}',\n",
    "                         f'{varn0}_Tan{std_mavsz_}']:\n",
    "                def f(df_):\n",
    "                    with warnings.catch_warnings(record=True) as w:\n",
    "                        warnings.filterwarnings('ignore',category=UserWarning)\n",
    "                        warnings.filterwarnings('ignore',category=RuntimeWarning)\n",
    "                        r = pg.corr( df_[varn], df_['err_sens'],  method='spearman')\n",
    "                    r['method'] = 'spearman'\n",
    "                    return r\n",
    "                #cols = ['thr','subject']\n",
    "                cols_av = ['trials']\n",
    "                cols = []\n",
    "                if cocoln != 'None':\n",
    "                    cols += [cocoln]\n",
    "                cols_keep = cols_av + cols + ['err_sens',varn]\n",
    "                dfcs_fixhistlen_me = dfcs_fixhistlen[cols_keep].\\\n",
    "                    groupby(cols_av + cols).mean().reset_index()\n",
    "                assert not dfcs_fixhistlen_me.duplicated(cols + ['trials']).any()                \n",
    "                if len(cols) == 0:\n",
    "                    corrs_mesubj = f(dfcs_fixhistlen_me)\n",
    "                else:\n",
    "                    corrs_mesubj = dfcs_fixhistlen_me.groupby(cols, \n",
    "                        observed=True).apply(f, include_groups=False)\n",
    "                corrs_mesubj = corrs_mesubj.rename(columns={'p-val':'pval'})\n",
    "                corrs_mesubj['std_mavsz'] = std_mavsz_\n",
    "                corrs_mesubj['varn'] = varn\n",
    "                dfs += [corrs_mesubj.reset_index()]\n",
    "        #display(corrs_mesubj)\n",
    "    corrs_mesubj = pd.concat(dfs, ignore_index=1)\n",
    "    cocoln2corrs_mesubj[cocoln] =     corrs_mesubj \n",
    "\n",
    "for cocoln in cocoln2corrs_mesubj:\n",
    "    cocoln2corrs_mesubj[cocoln]['cocoln'] = cocoln\n",
    "cocoln2corrs_mesubj_ = pd.concat(cocoln2corrs_mesubj.values())\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54a34b6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Mixed effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef51eef",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b0b815",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#sm.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e4ff5d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfcs_fixhistlen['environment'] = dfcs_fixhistlen['environment'].astype(int)\n",
    "df_ = dfcs_fixhistlen[['environment','subject','trials','error_pscadj_abs_Tan29']]\n",
    "assert not df_.duplicated(['subject','trials']).any()\n",
    "#df_.to_csv('/home/demitau/dfcs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d598b6fc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del summary,result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a56e08",
   "metadata": {
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import dateutil\n",
    "#dtstart = dateutil.parser.parse('march 31 2024  18:10')\n",
    "dtstart = dateutil.parser.parse('april 12 2024  01:00')\n",
    "\n",
    "import glob\n",
    "prls_fnf = glob.glob(path_data + '/prl_*_2024*')\n",
    "\n",
    "prl = []\n",
    "for p in prls_fnf:    \n",
    "    #p=  pjoin(path_data, f'prl_{ind}.npz')\n",
    "    if not os.path.exists(p):\n",
    "        continue\n",
    "    \n",
    "    dt = datetime.fromtimestamp(os.path.getmtime(p))\n",
    "    if not dt >= dtstart:\n",
    "        continue    \n",
    "    print(p, dt)\n",
    "    prl_ = np.load(p,allow_pickle=1)['arr_0']\n",
    "    print(len(prl_))\n",
    "    for item in prl_:\n",
    "        item['dt'] = dt\n",
    "    #prl__ = [(dt,_item) for _item in prl_]\n",
    "    prl += list(prl_)\n",
    "\n",
    "print('Total len ',len(prl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2260fe01",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del summ,fet,fet0,tab        \n",
    "del summ,fet,summary\n",
    "del res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3c1743",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# READ: extract stuff from prl\n",
    "import re\n",
    "def cnv(s):\n",
    "    v = np.nan\n",
    "    if s != '':\n",
    "        v = float(s)\n",
    "    return v\n",
    "\n",
    "#DEBUG = 1\n",
    "DEBUG = 0\n",
    "ind = 0 \n",
    "mixmr = []\n",
    "for ip,p in enumerate(prl):\n",
    "#for ip,p in enumerate(prl[136:136+1]):        \n",
    "    dd_ = p.copy()\n",
    "    dd_['ind_in_prl'] = ip\n",
    "    #del dd_['s']    \n",
    "    \n",
    "    varn = dd_['varn']\n",
    "    s2summ = dd_['s2summary']\n",
    "    \n",
    "    for (s,scov),summ in s2summ.items():                \n",
    "        if summ is None:\n",
    "            dd_['converged'] = False\n",
    "            continue        \n",
    "        dd = {}\n",
    "        dd.update(dd_)        \n",
    "        dd = dd.copy()\n",
    "        \n",
    "        co = dd['cocoln']\n",
    "        if co == 'env':\n",
    "            dd['refcond'] = 'random'\n",
    "        else:\n",
    "            dd['refcond'] = 'pert'\n",
    "        \n",
    "        del dd['s2summary'] # because we need only one\n",
    "            \n",
    "        tab = summ.tables[0]\n",
    "        converged  = tab.loc[4,3] == 'Yes'\n",
    "        converged2 = tab.loc[5,3] == 'Yes'\n",
    "\n",
    "        fet = summ.tables[1].rename(columns={'P>|z|':'pval', 'Coef.':'coef'} )    \n",
    "\n",
    "        fet.pval = fet.pval.apply(cnv)\n",
    "        fet.coef = fet.coef.apply(cnv)\n",
    "        fet0 = fet.reset_index()\n",
    "        dd['fet0'] = fet0\n",
    "        \n",
    "        def f(row):\n",
    "            # Find all occurrences between [T. and ]\n",
    "            s = row['index']\n",
    "            match = re.findall(r\"\\[T\\.([^\\]]*)\\]\", s)\n",
    "            if match:\n",
    "                return match[0]\n",
    "            else:\n",
    "                return dd['refcond']\n",
    "        fet0['cond'] = fet0.apply(f,1)\n",
    "\n",
    "        d = fet[['pval','coef']].T.to_dict()\n",
    "        dd['intercept_pval'] = summ.pvalues['Intercept'] #d['Intercept']['pval']\n",
    "        dd['intercept_coef'] = summ.params['Intercept'] #d['Intercept']['coef']\n",
    "                \n",
    "        dd['varn_coef'] = summ.params[varn] #d[varn]['coef']\n",
    "        dd['varn_pval'] = summ.pvalues[varn] #d[varn]['pval']\n",
    "        dd['converged']  = converged\n",
    "        dd['converged2'] = converged2\n",
    "        dd['s'] = s\n",
    "        dd['scov'] = scov\n",
    "        dd['summary'] = summ\n",
    "        \n",
    "        dd['coefp_sig_max'] = np.nan\n",
    "        dd['coefp_sig_min'] = np.nan\n",
    "        if (s.find('*') < 0) and dd['varn_pval'] < 0.05:\n",
    "            dd['coefp_sig_max'] = dd['varn_coef'] \n",
    "            dd['coefp_sig_min'] = dd['varn_coef'] \n",
    "            \n",
    "        #row = mixmr.iloc[6]\n",
    "        #fet0 = row['fet0']\n",
    "        strs = fet0.query('index.str.contains(@varn) and pval <= 0.05')['cond'].values\n",
    "        condssig = ','.join(strs)\n",
    "        dd['condssig'] = condssig\n",
    "\n",
    "        print(varn,s,scov,converged,converged2)\n",
    "        if DEBUG:\n",
    "            display(summ)\n",
    "        if converged and s.find('*') >= 0:\n",
    "            interactions = fet0.query('index.str.contains(\":\")').index.values\n",
    "            fet0int = fet0.loc[interactions]\n",
    "                                    \n",
    "            fet0['coefp'] = np.nan\n",
    "            fet0.loc[fet0int.index,'coefp'] =fet0.loc[fet0int.index,'coef'] + dd['varn_coef']\n",
    "            fet0.loc[fet0.query('index == @varn').index,'coefp'] = dd['varn_coef']\n",
    "            fet0int = fet0.loc[interactions] # for it to have coefp now\n",
    "            \n",
    "            \n",
    "            \n",
    "            fet0sig = fet0.query('pval <= 0.05')\n",
    "            if len(fet0sig):\n",
    "                dd['coefp_sig_max'] = fet0sig['coefp'].max()\n",
    "                dd['coefp_sig_min'] = fet0sig['coefp'].min()\n",
    "            dd['coefp_max'] = fet0['coefp'].max()\n",
    "            dd['coefp_min'] = fet0['coefp'].min()\n",
    "\n",
    "            rs = fet0int.query('pval <= 0.05')\n",
    "            lsig = len( rs )            \n",
    "            #lsigp = len( rs )\n",
    "#             if dd['cocoln'] == 'env':\n",
    "#                 num_sig_inter = lsig + int( cnv(d[varn]['pval']) <= 0.05 )\n",
    "\n",
    "#                 #v1 = dd['varn_coef'] + fet0.loc[interactions].iloc[0].pval        \\\n",
    "#                 # compute effec t in the other environment\n",
    "#                 v2 = dd['varn_coef'] + fet0.loc[interactions].iloc[0].coef        \n",
    "#                 num_sig_inter_pos = 0\n",
    "#                 num_sig_inter_pos += int( dd['varn_coef'] > 0 ) * int( dd['varn_pval'] < 0.05 )\n",
    "#                 num_sig_inter_pos += int( v2 > 0) * (fet0.loc[interactions].iloc[0].pval < 0.05)\n",
    "#                 dd['num_inter'] = 2\n",
    "#             else:\n",
    "            num_sig_inter = lsig + int( cnv(d[varn]['pval']) <= 0.05 )\n",
    "                \n",
    "            num_sig_inter_pos = int( dd['varn_coef'] > 0 ) * int( dd['varn_pval'] < 0.05 )\n",
    "            for ir,r in rs.iterrows():\n",
    "                coef_full = d[varn]['coef'] + float(r['coef'])\n",
    "                num_sig_inter_pos += int(coef_full > 0)\n",
    "            dd['coefp_nm_max'] = fet0int['coefp'].max()  # nm means not meain effect\n",
    "            dd['coefp_nm_min'] = fet0int['coefp'].min()\n",
    "            \n",
    "            dd['num_inter'] = len(interactions) + 1                        \n",
    "            dd['num_sig_inter'] = num_sig_inter\n",
    "            dd['num_sig_inter_pos'] = num_sig_inter_pos\n",
    "            \n",
    "            \n",
    "        \n",
    "            if scov == \"1\" and DEBUG:\n",
    "                raise ValueError('st')        \n",
    "#        display(summ.wmess)\n",
    "        del summ,fet,fet0,tab        \n",
    "#             if scov != \"1\":\n",
    "#                 display(summ)\n",
    "#                 display(fet)\n",
    "#                 raise Exception('f')\n",
    "        \n",
    "\n",
    "    #del dd_['res']\n",
    "\n",
    "        mixmr += [dd.copy()]\n",
    "        ind += 1\n",
    "    #break\n",
    "mixmr= pd.DataFrame(mixmr)\n",
    "print('completed')\n",
    "\n",
    "mixmr['inter'] = mixmr['s'].str.contains('\\*')\n",
    "mixmr['sshrt'] = mixmr['s'].str[10:]\n",
    "\n",
    "def f(row):\n",
    "    varn = row['varn']\n",
    "    s = row['sshrt']\n",
    "    if isinstance(s,str):\n",
    "        s = s.replace(varn,'{varn}')\n",
    "    return s\n",
    "mixmr['sshrt'] = mixmr.apply(f,1)\n",
    "\n",
    "print(len(prl),len(mixmr))\n",
    "\n",
    "mixmr.loc[mixmr['num_inter'].isna(),'num_inter'] = 0\n",
    "mixmr = mixmr.loc[~mixmr.s.str.contains('\\* error_pscadj_abs')] # they are weird, because not prev\n",
    "\n",
    "# take newer calcs\n",
    "grp = mixmr.groupby(['cocoln','varn','sshrt','scov'])\n",
    "mixmr = aggRows(mixmr,'dt','max', grp =grp )\n",
    "\n",
    "def f(row):\n",
    "    statn = row['varn'][len(row['varn0'])+1:]\n",
    "    hl = row['histlen']\n",
    "    hl_l = len(str(hl))\n",
    "    statn = statn[:-hl_l]\n",
    "    return statn\n",
    "                  \n",
    "mixmr['statn'] = mixmr.apply(f,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327703cf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save = 0\n",
    "if save:    \n",
    "    s = str(datetime.now())[:-7].replace(' ','_')\n",
    "    mixmr.to_pickle(pjoin(path_data, f'mll_{s}.pkl.zip'), compression='zip')\n",
    "    print('saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c09e556",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#summ.params[varn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18816f7d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sz = mixmr.groupby(['cocoln','varn','sshrt','scov']).size()\n",
    "print(sz.max())\n",
    "#display(sz)\n",
    "assert sz.max() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bb1291",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#mixmr = mixmr.drop_duplicates(subset= list(set(cols0) - set('ind_in_prl') ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e1110d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#mixmr.query('varn == \"error_pscadj_Tan33\" and cocoln == \"ps2_\"').sort_values(cols_fav)[cols0]#[cols_fav + ['sshrt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a5cab3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#sz[sz==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf25ccb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#mixmr.loc[112].summary.tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eb0851",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cols_exc = ['histlen','varn0','res','summary','varn_suffix', 's2summary','s']\n",
    "cols_exc = ['histlen','varn0','res','summary','varn_suffix', 's2summary','converged',\n",
    "            'converged2','s', 'excfmt','fet0']\n",
    "cols0 = [c for c in mixmr.columns if c not in cols_exc]; cols0\n",
    "#display(mixmr[cols])\n",
    "\n",
    "cols_fav = ['cocoln', 'varn', 'scov', \n",
    " 'coefp_sig_max', 'coefp_sig_min', 'coefp_nm_max', 'coefp_nm_min', \n",
    "    'num_sig_inter_pos','sshrt','condssig'] #'num_inter',\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dc4828",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# cols = [c for c in mixmr.columns if c not in  ['res','varn','s2summary','s','summary']]\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "#     display(mixmr.query('cocoln == \"env\" and inter == True and converged == True')[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54cfe38",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1dc03c",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "qs = 'cocoln == \"env\" and varn_pval <= 0.05 and converged2 == True and excfmt.isnull()'\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "#     display(mixmr.sort_values('s').query(qs)[cols])\n",
    "    \n",
    "qs += ' and coefp_sig_max > 0'\n",
    "display(mixmr.sort_values('s').query(qs)[cols0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21fe7b4",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### All positive slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa8b3f",
   "metadata": {
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# with significant interactions with ALL positive slopes (so the most inconsistent slopes across conditions)\n",
    "# there is only one for ps_ error_pscadj_abs_invstd7 and the slope size is pretty low\n",
    "cols = [c for c in mixmr.columns if c not in cols_exc]; cols\n",
    "\n",
    "qs = 'converged2 == True'\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "#     display(mixmr.sort_values('s').query(qs)[cols])\n",
    "    \n",
    "qs += ' and coefp_sig_max > 0 and inter == True and num_sig_inter_pos == num_inter'\n",
    "ds_ = mixmr.sort_values(['inter','varn']).query(qs)\n",
    "inds = ds_.index._data\n",
    "display(ds_[cols])\n",
    "\n",
    "ds_2 = mixmr.sort_values(['inter','varn']).query(qs + ' and scov != \"1\"')\n",
    "inds2 = ds_2.index._data\n",
    "print('and with random effects inds = ', inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a3513d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 252 has pretty small slopes in pres and rnd, but large in rnd and pert\n",
    "cc = ['Coef.','P>|z|']\n",
    "for ind in inds:\n",
    "    row = mixmr.loc[ind]\n",
    "    print(ind, row['s'], row['scov'])    \n",
    "    fet = row['summary'].tables[1]\n",
    "    #rowis = fet.index[:-3] # .iloc[:-2]\n",
    "    print(fet[cc])\n",
    "    #break\n",
    "varnames = list( mixmr.loc[inds]['varn'].values )\n",
    "print(varnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb96b3b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot relationship\n",
    "h=4\n",
    "me = dfcs_fixhistlen.\\\n",
    "    groupby(['subject','env'])[ ['err_sens']+varnames].mean().reset_index()\n",
    "fg,df = relplot_multi(sep_ys_by = 'col', data=me, x='err_sens',ys=varnames, row='env',\n",
    "                     height = h)\n",
    "fg.refline(x=0)\n",
    "fg.refline(y=0)\n",
    "fg.fig.suptitle('Mean within subject')\n",
    "\n",
    "fg,df = relplot_multi(sep_ys_by = 'col', data=dfcs_fixhistlen, x='err_sens',ys=varnames, row='env',\n",
    "                     height = h)\n",
    "fg.refline(x=0)\n",
    "fg.refline(y=0)\n",
    "fg.fig.suptitle('Pooled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9515cdcf",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with at least 1 condition signif different (so with slopes not fully consistent)\n",
    "cols = [c for c in mixmr.columns if c not in cols_exc + ['varn_pval'] ]; cols\n",
    "\n",
    "qs = 'converged2 == True'\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "#     display(mixmr.sort_values('s').query(qs)[cols])\n",
    "qs += ' and coefp_sig_max > 0 and inter == True and num_sig_inter > 1 and coefp_sig_max >= 0.01'\n",
    "qs += ' and not s.str.contains(\"error_pscadj_abs\")'\n",
    "df_ = mixmr.sort_values(['cocoln','inter','varn']).query(qs)\n",
    "inds = df_.index._data\n",
    "#display(df_[cols])\n",
    "\n",
    "df_[cols_fav]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad933c4c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### some positive slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddee82c9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with >= 1 significant slopes\n",
    "# there is only one for ps_ error_pscadj_abs_invstd7 and the slope size is pretty low\n",
    "cols = [c for c in mixmr.columns if c not in cols_exc]; cols\n",
    "\n",
    "qs = 'converged2 == True'\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "#     display(mixmr.sort_values('s').query(qs)[cols])\n",
    "    \n",
    "qs += ' and coefp_sig_max > 0 and inter == True and not s.str.contains(\"prev_\")' \n",
    "ds_ = mixmr.sort_values(['inter','varn']).query(qs)\n",
    "inds = ds_.index._data\n",
    "display(ds_[cols])\n",
    "\n",
    "ds_2 = mixmr.sort_values(['inter','varn']).query(qs + ' and scov != \"1\"')\n",
    "inds2 = ds_2.index._data\n",
    "print(f'and with random effects {len(inds2)} inds2 = ', inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109757b1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#[c for c in dfc.columns if c.find('error') >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d6e893",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#mixmr.iloc[0]['s2summary'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7555d10",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ds_2[cols_fav ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51d7863",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# the first one (with random effects for ps_) is error_pscadj_invstd19, it has rahter small slope (0.022)\n",
    "# and it has a tendency (not signif) to decrease in random (-0.048)\n",
    "\n",
    "# other indices (w/o random effects for env) are for std with high histlen 25+, \n",
    "# they have very high slope in random with strong (not signif) reduction in stable\n",
    "# but it goes doown\n",
    "cc = ['Coef.','P>|z|']\n",
    "for ind in inds2:\n",
    "    row = mixmr.loc[ind]\n",
    "    print(ind, row['s'], '---  ',row['scov'], row['converged2'])    \n",
    "    #print(row['s'], '---  ',row['scov'])    \n",
    "    #display(row['summary'].wmess)\n",
    "    print(row['varn'])#, '---  ',row['scov'])    \n",
    "    fet0 = row['fet0'][['index','cond','coef','coefp','pval']]#.tables[1]\n",
    "    #rowis = fet.index[:-3] # .iloc[:-2]\n",
    "    #display(fet[cc])\n",
    "    display(fet0)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a52c5b7",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  with just one signif condition (so with slopes kinda consistent across conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b814f0b4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with just one signif condition (so with slopes kinda consistent across conditions)\n",
    "cols = [c for c in mixmr.columns if c not in cols_exc + ['varn_pval'] ]; cols\n",
    "\n",
    "qs = 'converged2 == True'\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "#     display(mixmr.sort_values('s').query(qs)[cols])\n",
    "qs += ' and coefp_sig_max > 0 and inter == True and num_sig_inter == 1 '#'and coefp_sig_max >= 0.01'\n",
    "qs += ' and not s.str.contains(\"error_pscadj_abs\")'\n",
    "df_ = mixmr.sort_values(['cocoln','inter','varn0','histlen']).query(qs)\n",
    "inds = df_.index._data\n",
    "print(len(inds))\n",
    "varnames = mixmr.loc[inds,'varn'].values\n",
    "#display(df_[cols])\n",
    "\n",
    "#df_2 = mixmr.sort_values(['cocoln','inter','varn']).query(qs + ' and scov != \"1\"')\n",
    "#inds = ds_2.index._data\n",
    "#print(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fe1754",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#print(set(varnames) )\n",
    "from collections import OrderedDict\n",
    "#my_list = [1, 2, 3, 2, 5, 1]\n",
    "list(OrderedDict.fromkeys(varnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9531d42",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a330076",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#print(cols)\n",
    "df_[cols_fav] #,'intercept_pval', 'intercept_coef',num_sig_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5e8d8a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# the first one (with random effects for ps_) is error_pscadj_invstd19, it has rahter small slope (0.022)\n",
    "# and it has a tendency (not signif) to decrease in random (-0.048)\n",
    "\n",
    "# other indices (w/o random effects for env) are for std with high histlen 25+, \n",
    "# they have very high slope in random with strong (not signif) reduction in stable\n",
    "# but it goes doown\n",
    "cc = ['Coef.','P>|z|']\n",
    "for ind in inds:\n",
    "    row = mixmr.loc[ind]\n",
    "    print(ind, row['s'], '---  ',row['scov'], row['converged2'])    \n",
    "    #print(row['s'], '---  ',row['scov'])    \n",
    "    display(row['summary'].wmess)\n",
    "    print(row['varn'])#, '---  ',row['scov'])    \n",
    "    fet = row['summary'].tables[1]\n",
    "    #rowis = fet.index[:-3] # .iloc[:-2]\n",
    "    #display(fet[cc])\n",
    "    display(fet)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110eb5eb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mixmr.varn.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a377a670",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from figure.plots import relplot_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbff2c9b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# scatter plots don't show a very clear relationship between std for high histlen and err_sens\n",
    "fg,df__ = relplot_multi(sep_ys_by = 'row', data=dfcs_fixhistlen,x='err_sens',ys=varnames, col='env')\n",
    "             #row='subject');\n",
    "fg.refline(x=0)\n",
    "fg.refline(y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cfd971",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# histograms of error_std for large histlen show that they have fat tail towards zero for many participants\n",
    "dfcs_fixhistlen.query('subject_ind == 13').hist(varnames[-1])\n",
    "dfcs_fixhistlen.hist(varnames[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bda9f4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display(mixmr.query('varn == @varnames[-1]')[cols0])\n",
    "display(mixmr.loc[39].summary.tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e13de4",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### --- with more restriction on coefp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eed0b64",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# --- with more restriction on coefp\n",
    "qs = 'converged2 == True'\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "#     display(mixmr.sort_values('s').query(qs)[cols])\n",
    "qs += ' and coefp_sig_max > 0 and inter == True and num_sig_inter == 1 and coefp_sig_max >= 0.1'\n",
    "qs += ' and coefp_min > -0.3'\n",
    "df_ = mixmr.sort_values(['cocoln','varn0','histlen','scov']).query(qs)\n",
    "inds = df_.index.values\n",
    "\n",
    "#cc = ['Coef.','P>|z|']\n",
    "for ind in inds:\n",
    "    row = mixmr.loc[ind]\n",
    "    print(ind, row['s'], '---  ',row['scov'], row['coefp_sig_min'])    \n",
    "    fet0 = row['fet0']\n",
    "    display(fet0.iloc[:-1][['index','coef','coefp','pval']])\n",
    "    #rowis = fet.index[:-3] # .iloc[:-2]\n",
    "    #display(fet[cc])\n",
    "    #break\n",
    "print(len(inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fbceae",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for small histlen (up to 4 inc)  std has large slope in stable (and small/moderate insignif diff in random)\n",
    "# for large histlen (since 25) std has large slope for random (and moderate/large insignif diff in stable )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53cead9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "varnames = mixmr.loc[inds,'varn'].values\n",
    "print(varnames, set(varnames))\n",
    "#varnames_toshow = #[varnames[0]] + [varnames[-1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1292a22f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "relplot_multi(data=dfcs_fixhistlen,x='err_sens',ys=varnames_toshow[:1], col='env');\n",
    "relplot_multi(data=dfcs_fixhistlen,x='err_sens',ys=varnames_toshow[1:], col='env');\n",
    "             #row='subject');\n",
    "#sns.relplot(kind='scatter',data=dfcs_fixhistlen, x="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9196332d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### No inter env (for Tan comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbf326a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# no inter\n",
    "# for env all intercepts are significant\n",
    "# for ps_ all non-random intercepts are significant\n",
    "qs = 'varn_pval <= 0.05 and converged2 == True '\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "#     display(mixmr.sort_values('s').query(qs)[cols])\n",
    "qs += ' and coefp_sig_max > 0 and inter == False and scov != \"1\" and cocoln == \"env\"'\n",
    "# we exclude std3 because it is too close to std2 which is algebraically close to err sens formula\n",
    "qs += ' and not s.str.contains(\"error_pscadj_abs\") and varn != \"error_pscadj_std3\"'\n",
    "qs += ' and coefp_sig_max >= 1e-3'\n",
    "df_ = mixmr.sort_values(['cocoln','inter','varn0','histlen']).query(qs)\n",
    "inds = df_.index._data\n",
    "display(df_[cols_fav[:4] + ['intercept_coef','intercept_pval']])\n",
    "print(len(inds))\n",
    "\n",
    "varn_suffixes_nointer = df_['varn_suffix'].unique()\n",
    "print(varn_suffixes_nointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c35028",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_srt = df_.sort_values('varn_coef', ascending=False)[cols_fav + ['varn_pval']]\n",
    "display(df_srt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5444d498",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#df_.iloc[0]['fet0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2857322",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TODO: apply to env for stable\n",
    "def addcols(df, cocoln, cond, pref, prek_pattern):\n",
    "    '''pref determines names of the output columns'''\n",
    "    #prek = 'C(ps2_)[T.washout]'\n",
    "    prek = prek_pattern.format(cocoln,cond)\n",
    "    #prek = f'C({cocoln})[T.{cond}]'\n",
    "    def f(row):\n",
    "        #fet0 = row['fet0']\n",
    "        varn_cur = row['varn']\n",
    "        #k = prek + f':{varn_cur}'\n",
    "        ps,pvs = row['summary'].params, row['summary'].pvalues\n",
    "        \n",
    "        k = prek\n",
    "        if k not in ps:\n",
    "            return None,None\n",
    "        coef = ps[k]\n",
    "        pv   = pvs[k]            \n",
    "        icpt,icpt_pv = ps[k], pvs[k]\n",
    "\n",
    "        return icpt,icpt_pv\n",
    "    cols = []\n",
    "    for s in ['icpt','icptpv']:\n",
    "        cols += [pref + s]\n",
    "    df[cols] = df.apply(f,1,result_type='expand')\n",
    "    return cols\n",
    "addcols(df_, 'env', 'stable', 's_', 'C({})[T.{}]')    \n",
    "addcols(df_, 'env', 'stable', 'r_', 'Intercept')    \n",
    "df_[cols_fav + ['s_icpt','s_icptpv','r_icpt','r_icptpv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5b5b59",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#row.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34434d16",
   "metadata": {
    "hidden": true,
    "tags": [
     "final_output"
    ]
   },
   "outputs": [],
   "source": [
    "br = df_.query('r_icptpv < 0.05')#\n",
    "#print('random intercept is signif')\n",
    "#display(br[cols_fav + ['s_icpt','s_icptpv','r_icpt','r_icptpv']])\n",
    "hlsig2,s_icpt2,s_icptpv2,r_icpt2,r_icptpv2 =\\\n",
    "    br.iloc[1][['histlen'] + ['s_icpt','s_icptpv','r_icpt','r_icptpv'] ]\n",
    "\n",
    "br = df_.query('s_icptpv < 0.05 and r_icptpv < 0.05')#\n",
    "print('When both intercepts are signif and different')\n",
    "display(br[cols_fav + ['s_icpt','s_icptpv','r_icpt','r_icptpv']])\n",
    "_,s_icpt,s_icptpv,r_icpt,r_icptpv =\\\n",
    "    br.iloc[0][['histlen'] + ['s_icpt','s_icptpv','r_icpt','r_icptpv'] ]\n",
    "histlens_both_signif = br['histlen'].values\n",
    "hlsig = histlens_both_signif\n",
    "hlsig = ', '.join( map(str, hlsig ) )\n",
    "print(histlens_both_signif)\n",
    "\n",
    "rows = br.iloc[[0,-1]]\n",
    "s0_icpt = ('With growing history length the slope estimate grows, while random and stable' \n",
    "      ' intercept values decrease: ')\n",
    "for rowi,row in rows.iterrows():\n",
    "# h1,h2 = histlens_both_signif[[0,-1]]\n",
    "# c1,c2 = print(br['coefp_sig_max'].values[[0,-1]])\n",
    "# r1,r2 = print(br['r_icpt'].values[[0,-1]])\n",
    "# s1,s2 = print(br['s_icpt'].values[[0,-1]])\n",
    "    s = ('for history length {}: slope {:.2f} (p-value = {:.2e}), ' \n",
    "    'random intercept = {:.2e} (p-value = {:.2e})'\n",
    "    'stable intercept correction = {:.2e} (p-value = {:.2e}). ')\\\n",
    "        .format(row['histlen'], row['varn_coef'], row['varn_pval'], row['r_icpt'], row['r_icptpv'],\n",
    "               row['s_icpt'],row['s_icptpv'])\n",
    "    s0_icpt += s\n",
    "print(s0_icpt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f616e249",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "br = df_.nlargest(1,'varn_coef')\n",
    "display(br[cols_fav + ['ind_in_prl']])#[['varn_coef','varn_pval']]\n",
    "row = br.iloc[0]; print(row.name)\n",
    "pv,coef, hlmax = row[['varn_pval','varn_coef','histlen']].values\n",
    "\n",
    "br = df_.nsmallest(1,'varn_coef')\n",
    "display(br[cols_fav + ['ind_in_prl']])#[['varn_coef','varn_pval']]\n",
    "row = br.iloc[0]; print(row.name)\n",
    "pv_min,coef_min, hlmin = row[['varn_pval','varn_coef','histlen']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479007ac",
   "metadata": {
    "hidden": true,
    "tags": [
     "final_output"
    ]
   },
   "outputs": [],
   "source": [
    "dfu = df_.groupby(['cocoln','statn'])['histlen'].unique()\n",
    "print( dfu  )\n",
    "lens =  dfu['env']['invstd'] \n",
    "mnl,mxl,diffl = min(lens),max(lens), np.diff(lens)\n",
    "print(mnl,mxl,diffl)\n",
    "lens = ', '.join( map(str, lens ) )\n",
    "#between {mnl} and {mxl}. \n",
    "s = f'''We ran mixed linear models ES ~ error statistics\n",
    "with two conditions (random,stable)\n",
    "without interactions but with random effects. Here \"error statistics\" is one of \n",
    "many possible statistics of previous errors: mean, standard deviation, inverse standard deviation,\n",
    "mean/standard deviation, mean squared/variance.\n",
    "We selected those models that converged and have a significant positive slope.\n",
    "We found that only models with 1 / standard deviation with history lengths {lens}.\n",
    "In by publication by Tan at al [CITE] authors used mean squared/variance with history lengths 20. \n",
    "However for our data this statistics appears to be not the right one.\n",
    "The maximum histlen we tried was 39 so it is possible that for longer lengths same holds, \n",
    "probably because standard deviation stops changing much. \n",
    "History length higher than 6 was increased in 3-trial step.\n",
    "The largest slope {coef:.3f} (p-value = {pv:.2e}) was for history of length {hlmax}.\n",
    "The smallest slope {coef_min:.3f} (p-value = {pv_min:.2e}) was for history of length {hlmin}.\n",
    "The only history lengths for which intercepts for both conditions were significantly \n",
    "positive and different was {hlsig}.'''\n",
    "s += s0_icpt\n",
    "s += '''In all other cases intercepts were not significantly different from zero.\n",
    "'''.replace('\\n',' ').replace('  ',' ')\n",
    "print('\\n'+s)\n",
    "\n",
    "# (intercept for random = {r_icpt:.3f}, it is > 0 \n",
    "# with p-value {r_icptpv:.2e} and for stable it's difference from random was\n",
    "# {s_icpt:.3f}, it is > 0 with p-value {s_icptpv:.2e}). \n",
    "# In addition for history length {hlsig2} the intercept {r_icpt:.3f} for random > 0 was significant \n",
    "# with p-value {r_icptpv:.2e}."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094c99ff",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### No inter ps2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a38b2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#dfall.query('subj == \"01\" and ps2_ == \"washout\" and block_name == \"stable1\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a93cad6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# no inter\n",
    "# for env all intercepts are significant\n",
    "# for ps_ all non-random intercepts are significant\n",
    "qs = 'varn_pval <= 0.05 and converged2 == True '\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "#     display(mixmr.sort_values('s').query(qs)[cols])\n",
    "qs += ' and coefp_sig_max > 0 and inter == False and scov != \"1\" and cocoln == \"ps2_\"'\n",
    "# we exclude std3 because it is too close to std2 which is algebraically close to err sens formula\n",
    "qs += ' and not s.str.contains(\"error_pscadj_abs\") and varn != \"error_pscadj_std3\"'\n",
    "qs += ' and histlen <= 24'\n",
    "qs += ' and coefp_sig_max >= 1e-05'\n",
    "df_ = mixmr.sort_values(['cocoln','inter','varn0','histlen']).query(qs)\n",
    "inds = df_.index._data\n",
    "display(df_[cols_fav[:4] + ['intercept_coef','intercept_pval']])\n",
    "print(len(inds))\n",
    "\n",
    "varn_suffixes_nointer = df_['varn_suffix'].unique()\n",
    "print(varn_suffixes_nointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a7fd7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_srt = df_.sort_values('varn_coef', ascending=False)[cols_fav + ['varn_pval']]\n",
    "display(df_srt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b424b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "br = df_.query('cocoln == \"ps2_\"').nlargest(1,'varn_coef')\n",
    "display(br[cols_fav + ['ind_in_prl']])#[['varn_coef','varn_pval']]\n",
    "row = br.iloc[0]\n",
    "print(row.name)\n",
    "pv,coef, hlmax = row['varn_pval'],row['varn_coef'],row['histlen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d0c15a",
   "metadata": {
    "hidden": true,
    "tags": [
     "final_output"
    ]
   },
   "outputs": [],
   "source": [
    "dfu = df_.groupby(['cocoln','statn'])['histlen'].unique()\n",
    "print( dfu  )\n",
    "\n",
    "lens = dfu['ps2_']['invstd']\n",
    "mnl,mxl,diffl = min(lens),max(lens), np.diff(lens)\n",
    "lens = ', '.join(map(str,lens))\n",
    "print(mnl,mxl,diffl)\n",
    "\n",
    "#between {mnl} and {mxl}. \n",
    "s = f'''We also ran mixed linear models for\n",
    "four conditions (random, zero perturbation, perturbation, washout)\n",
    "without interactions but with random effects. \n",
    "We selected those models that converged and have a significant positive slope.\n",
    "Similar to the case with two conditions above, \n",
    "we found that only models with 1 / standard deviation with historly lengths {lens} \n",
    "satisfy these requirements.\n",
    "This time the maximum histlen we used was 24 because it is the lenght of the shortest condition.\n",
    "The largest slope {coef:.3f} (p-value = {pv:.2e}) was for history of length {hlmax}.\n",
    "'''.replace('\\n',' ').replace('  ',' ')\n",
    "print('\\n'+s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699ba212",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#for ind in inds:\n",
    "for ind in [340]:\n",
    "    row = mixmr.loc[ind]\n",
    "    print(ind, row['s'], '---  ',row['scov'], row['coefp_sig_min'])    \n",
    "    print(row['varn'])\n",
    "\n",
    "    display(mixmr.loc[ind].summary.tables[1][['Coef.','P>|z|']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429bef74",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### some slopes WITH interaction, only those stats that work for no interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4625b0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with >= 1 significant slopes\n",
    "# there is only one for ps_ error_pscadj_abs_invstd7 and the slope size is pretty low\n",
    "cols = [c for c in mixmr.columns if c not in cols_exc]; cols\n",
    "\n",
    "qs = 'converged2 == True and cocoln == \"ps2_\" '\n",
    "qs += ' and coefp_sig_max > 0 and inter == True and not s.str.contains(\"prev_\")' \n",
    "qs += ' and varn_suffix.isin(@varn_suffixes_nointer)'\n",
    "# choose those that have more than one signif interaction (not necessarily positive)\n",
    "qs += ' and condssig.str.contains(\",\")'  \n",
    "qs += ' and histlen <= 24'\n",
    "\n",
    "df_ = mixmr.sort_values(['cocoln','inter','varn_suffix','histlen']).query(qs + ' and scov != \"1\"')\n",
    "\n",
    "display(df_[cols_fav])\n",
    "inds = df_.index._data\n",
    "print(f'and with random effects {len(inds)} inds = ', inds)\n",
    "\n",
    "dftmp = df_.copy()\n",
    "dftmp = dftmp.set_index('histlen', verify_integrity=True)\n",
    "\n",
    "print( dftmp.index.values )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa87d21",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TODO: apply to env for stable\n",
    "def addcols(df, cocoln, cond, pref):\n",
    "    '''pref determines names of the output columns'''\n",
    "    #prek = 'C(ps2_)[T.washout]'\n",
    "    prek = f'C({cocoln})[T.{cond}]'\n",
    "    def f(row):\n",
    "        #fet0 = row['fet0']\n",
    "        varn_cur = row['varn']\n",
    "        k = prek + f':{varn_cur}'\n",
    "        ps,pvs = row['summary'].params, row['summary'].pvalues\n",
    "        if k not in ps:\n",
    "            return None,None,None,None\n",
    "        coef = ps[k]\n",
    "        pv   = pvs[k]    \n",
    "\n",
    "        k = prek\n",
    "        icpt,icpt_pv = ps[k], pvs[k]\n",
    "\n",
    "        return coef,pv,icpt,icpt_pv\n",
    "    cols = []\n",
    "    for s in ['coef','pv','icpt','icptpv']:\n",
    "        cols += [pref + s]\n",
    "    df[cols] = df.apply(f,1,result_type='expand')\n",
    "    return cols\n",
    "addcols(dftmp, 'ps2_', 'washout', 'w')    \n",
    "dftmp[['varn','varn_coef','varn_pval','intercept_coef','intercept_pval'] + ['wcoef','wpv','wicpt','wicptpv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a5059",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rows = dftmp.reset_index().iloc[[0,-1]]\n",
    "s0_slope = ('''with growing history length the slope estimate in perturbation grows and\n",
    "the postive significant correction to it in washout as well\n",
    "while random and stable intercept values decrease: ''').replace('\\n',' ')\n",
    "for rowi,row in rows.iterrows():\n",
    "# h1,h2 = histlens_both_signif[[0,-1]]\n",
    "# c1,c2 = print(br['coefp_sig_max'].values[[0,-1]])\n",
    "# r1,r2 = print(br['r_icpt'].values[[0,-1]])\n",
    "# s1,s2 = print(br['s_icpt'].values[[0,-1]])\n",
    "    s = ('for history length {}: ' \n",
    "    'perturbation slope = {:.2e} (p-value = {:.2e}) '\n",
    "    'washout slope correction = {:.2e} (p-value = {:.2e}). ')\\\n",
    "        .format(row['histlen'], row['varn_coef'], row['varn_pval'], row['wcoef'], row['wpv'])\n",
    "    s0_slope += s\n",
    "print(s0_slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e21ddc",
   "metadata": {
    "hidden": true,
    "tags": [
     "final_output"
    ]
   },
   "outputs": [],
   "source": [
    "coef1,pv1 = dftmp.loc[12][['wcoef','wpv']].values\n",
    "coef2,pv2 = dftmp.loc[15][['wcoef','wpv']].values\n",
    "\n",
    "refcond = 'pert'\n",
    "othercond = 'washout'\n",
    "lens = ', '.join(map(str,df_.histlen.values))\n",
    "s = f'''To check whether the slope changes across conditions, \n",
    "for those statistical measures we found above we also computed mixed linear model with interactions \n",
    "and random effects. We found that only two models had significant slope difference between some conditins:\n",
    "for models with with history lengths = {lens}\n",
    "where in {othercond} condition slopes were significantly different.\n",
    "For all the models the intercept in this condition was not significantly different from the \n",
    "reference condition ({refcond}) but the slope was significantly higher than in reference condition. \n",
    "''' \n",
    "s = s.replace('\\n',' ').replace('  ',' ') + '\\n\\nMore specifically, ' + s0_slope\n",
    "s += ' This is consistent with naive visual inspection of Fig 2A'\n",
    "s += ' suggesting that adaptation is washout is faster than in perturbation stage.'\n",
    "print(s)\n",
    "\n",
    "# For len 12: slope correction {coef1:.3f}, p-value = {pv1:.2e}, \n",
    "# for len 15: slope correction {coef2:.3f}, p-value {pv2:.2e}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5916b1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cc = ['Coef.','P>|z|']\n",
    "for ind in inds:\n",
    "    row = mixmr.loc[ind]\n",
    "    print(ind, row['s'], '---  ',row['scov'], row['converged2'])    \n",
    "    #print(row['s'], '---  ',row['scov'])    \n",
    "    #display(row['summary'].wmess)\n",
    "    print(row['varn'])#, '---  ',row['scov'])    \n",
    "    fet0 = row['fet0'][['index','cond','coef','coefp','pval']]#.tables[1]\n",
    "    #rowis = fet.index[:-3] # .iloc[:-2]\n",
    "    #display(fet[cc])\n",
    "    display(fet0)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491bc559",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## corr for all without regard for env/ps2_ (of ES and windows-stat measues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305cef8a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mean across\n",
    "ttrs_pos = cocoln2corrs_mesubj['None'].query('pval <= 0.05 and r > 0')\n",
    "varnames = list(ttrs_pos.reset_index()['varn'].values)\n",
    "#print(varnames )\n",
    "print('For mean,then corr {} varnames are >0 correlated'.format(len(varnames) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaab0037",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# all trial together\n",
    "def f(df):\n",
    "    if len(df) == 0:\n",
    "        return None\n",
    "    ttrs = compare0(df, 'r', cols_addstat=['r'])\n",
    "    return ttrs\n",
    "m2vns={}\n",
    "\n",
    "    # include groups is whether df that f receives as arg has grouping columns or not\n",
    "ttrs = cocoln2corrs_per_subj.query('cocoln == \"None\"').\\\n",
    "    groupby(['varn','method'], observed=True).apply(f, include_groups=False)\n",
    "print(getAddInfo())\n",
    "#display(ttrs.query('pval <= 0.05 and ttstr == \"r < 0\"')\\\n",
    "#        [['pval','ttstr']])\n",
    "\n",
    "ttrs_pos = ttrs.query('pval <= 0.05 and ttstr == \"r > 0\"')\n",
    "#display(ttrs_pos[['pval','ttstr']])\n",
    "for method in cocoln2corrs_per_subj.method.unique():\n",
    "    varnames = ttrs_pos.loc[ttrs_pos.index.get_level_values('method') == method].reset_index()['varn'].values\n",
    "    varnames = list(varnames)\n",
    "    #varnames = list(ttrs_pos[(None,method)])\n",
    "    #print(varnames )\n",
    "    print(method, len(varnames), ' varnames are >0 correlated' )\n",
    "    m2vns[method] = varnames\n",
    "\n",
    "#print( ', '.join(varnames) )\n",
    "\n",
    "\n",
    "#print ('Dif between methods ',set(m2vns['spearman']) ^ set(m2vns['shepherd']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debe6d51",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ttrs_pos = ttrs_pos.query('method == \"spearman\"')\n",
    "ttrs_pos = ttrs_pos.sort_values(['pval'])\n",
    "ttrs_pos[['pval','T','r_mean','r_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99bfdeb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ttrs_pos = ttrs_pos.query('varn.str.contains(\"_invstd\")').sort_values(['r_mean'], ascending=False)\n",
    "ttrs_pos[['pval','T','r_mean','r_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b93970",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#ttrs_pos.query('varn.str.endswith(\"std2\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5185c55b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#df_ = pd.DataFrame( {'varn':m2vns['spearman'] } )\n",
    "#df_['']\n",
    "\n",
    "# std2\n",
    "# invstd 4-39\n",
    "# abs invstd 2-39\n",
    "# abs mav d var 4-39\n",
    "\n",
    "m2vns['spearman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e5228f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot ES vs windows stats\n",
    "import warnings\n",
    "varnames = list(ttrs_pos.reset_index()['varn'].values)\n",
    "if len(varnames) <= 10:\n",
    "    print(varnames)\n",
    "    for env in ['stable','random']:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "            me = dfcs_fixhistlen.query('env == @env').\\\n",
    "                groupby(['subject','env'])[['err_sens']+varnames].mean().reset_index()\n",
    "            fg = sns.pairplot(data=me, \n",
    "                     y_vars = ['err_sens'], hue='env',\n",
    "                         x_vars=['err_sens'] + varnames)#,corner=1)\n",
    "\n",
    "    me = dfcs_fixhistlen.\\\n",
    "        groupby(['subject'])[['err_sens']+varnames].mean().reset_index()\n",
    "    fg = sns.pairplot(data=me, \n",
    "             y_vars = ['err_sens'], \n",
    "                 x_vars=['err_sens'] + varnames)#,corner=1)\n",
    "else:\n",
    "    print('Too long list of varnames ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d429140e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb72463",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## corr within env (of ES and windows-stat measues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fed5b1",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mesubj (useless)\n",
    "# it gives 0 because for random it does not make sense to average across participants\n",
    "# because randomness is not consistent across them\n",
    "env2varnames = {}\n",
    "ttrs = cocoln2corrs_mesubj['env']\n",
    "for env in ['stable','random']:\n",
    "    ttrs_pos = ttrs.query('pval <= 0.05 and r > 0 and'\n",
    "                         ' env == @env')\n",
    "#display(ttrs_pos[['pval','ttstr']])\n",
    "    varnames = list(ttrs_pos.reset_index()['varn'].values)\n",
    "    print(env,len(varnames))\n",
    "    env2varnames[env] = varnames\n",
    "varnames_isec = set(env2varnames['stable']) & set(env2varnames['random'])\n",
    "varnames_isec = list(varnames_isec)\n",
    "print('random ', set(env2varnames['random']))\n",
    "print('isec varnames',varnames_isec  )\n",
    "\n",
    "print('For mean, stable&random corr {} varnames are >0 correlated'.format(len(varnames) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f3523f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Find with windows stats are positive bot for random AND for stable\n",
    "from behav_proc import compare0\n",
    "def f(df):\n",
    "    if len(df) == 0:\n",
    "        return None\n",
    "    ttrs_ = compare0(df, 'r')\n",
    "    return ttrs_\n",
    "for method in cocoln2corrs_per_subj.method.unique():\n",
    "    ttrs = cocoln2corrs_per_subj.query('cocoln == \"env\" and method == @method').\\\n",
    "        groupby(['varn','env'], observed=True).apply(f)\n",
    "    print(getAddInfo())\n",
    "    #display(ttrs.query('pval <= 0.05 and thr in @thrs')\\\n",
    "    #        [['pval','ttstr']])\n",
    "\n",
    "    ttrs_pos = ttrs.query('pval <= 0.05 and ttstr == \"r > 0\"')\n",
    "    print('All positive, both envs (separately)')\n",
    "    #display(ttrs_pos[['pval','ttstr']])\n",
    "\n",
    "    env2varnames = {}\n",
    "    for env in ['stable','random']:\n",
    "        ttrs_pos = ttrs.query('pval <= 0.05 and ttstr == \"r > 0\" and'\n",
    "                             ' env == @env')\n",
    "    #display(ttrs_pos[['pval','ttstr']])\n",
    "        varnames = list(ttrs_pos.reset_index()['varn'].values)\n",
    "        env2varnames[env] = varnames\n",
    "    varnames_isec = set(env2varnames['stable']) & set(env2varnames['random'])\n",
    "    varnames_isec = list(varnames_isec)\n",
    "    print(method, 'isec varnames',varnames_isec  )\n",
    "#print(varnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9856b291",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# To be put into paper\n",
    "mer = cocoln2corrs_per_subj.query('cocoln == \"env\"').\\\n",
    "    groupby(['varn','env'], observed=True)['r'].mean()\n",
    "\n",
    "print(getAddInfo(),'\\n')\n",
    "r = ttrs.query('pval <= 0.05 and ttstr == \"r > 0\" '\n",
    "    ' and varn.isin(@varnames_isec)').reset_index()[['varn','env','pval']].set_index(['varn','env'])\n",
    "#d = r.T.to_dict()\n",
    "#print(d)\n",
    "\n",
    "for varn in varnames_isec:\n",
    "    st = r.loc[(varn,'stable'),'pval']\n",
    "    ra = r.loc[(varn,'random'),'pval']\n",
    "    stabr = mer[(varn,'stable')]\n",
    "    randr = mer[(varn,'random')]\n",
    "    \n",
    "    s = (f\"{varn}: For random r>0 has p-val={ra:.2e} (mean r = {randr:.3f})\"\n",
    "        f\" and for stable r>0 has p-val={st:.2e} (mean r = {stabr:.3f})\")\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058017d6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#me['env']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf66852",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "h=4\n",
    "varnames_toshow = varnames_isec[1:]\n",
    "fg,df = relplot_multi(sep_ys_by = 'col', data=dfcs_fixhistlen, x='err_sens',ys=varnames_toshow, row='env',\n",
    "                     height = h)\n",
    "for ax in fg.axes.flatten():\n",
    "    ttl = ax.get_title().replace('__varname = ','').replace('env = ','')\n",
    "    ax.set_title(ttl)\n",
    "\n",
    "fg.refline(x=0)\n",
    "fg.refline(y=0)\n",
    "fg.fig.suptitle('Pooled')\n",
    "plt.tight_layout()\n",
    "\n",
    "me = dfcs_fixhistlen.\\\n",
    "    groupby(['subject','env'])[['err_sens']+varnames_toshow].mean().reset_index()\n",
    "fg,df = relplot_multi(sep_ys_by = 'col', data=me, x='err_sens',ys=varnames_toshow, row='env',\n",
    "                     height = h)\n",
    "for ax in fg.axes.flatten():\n",
    "    ttl = ax.get_title().replace('__varname = ','').replace('env = ','')\n",
    "    ax.set_title(ttl)\n",
    "fg.refline(x=0)\n",
    "fg.refline(y=0)\n",
    "fg.fig.suptitle('Mean within subject')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d3b3d5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fg = sns.relplot(data=dfcs_fixhistlen, col='subject',\n",
    "#     y = 'err_sens', x=varnames_isec[0], row='env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed6c29b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from behav_proc import formatRecentStatVarnames\n",
    "isec_nice = formatRecentStatVarnames(varnames_isec)\n",
    "display(isec_nice)\n",
    "print('; '.join(isec_nice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa35e8ce",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "isec = set(env2varnames['stable']) & set(env2varnames['random'])\n",
    "if len(isec):\n",
    "    print('If we fix the history length first, then compute correlation '\n",
    "      'within participant (separately for both environments)'\n",
    "      ' and then choose variables for which r>0 stat significantly in both environments'\n",
    "      ' simultaneously, we get ',', '.join(list(isec) ) )\n",
    "else:\n",
    "    print('We get nothing signif postive in both separately')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4632449",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#ttrs.query('varn == \"error_pscadj_invstd10\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afcb5ea",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "varnames = list(ttrs_pos.reset_index()['varn'].values)\n",
    "print(varnames)\n",
    "for env in ['stable','random']:\n",
    "    plt.figure()\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "        fg = sns.pairplot(data=dfcs.query('env == @env').\\\n",
    "            groupby(['subject','env'])[['err_sens']+env2varnames[env]].mean().reset_index(), \n",
    "            y_vars = ['err_sens'], hue='env',\n",
    "            x_vars=['err_sens'] + env2varnames[env])#,corner=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f95f7c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# You are an expert in python pandas and data science.\n",
    "# I have a pandas dataframe with the following columns\n",
    "# ttrs_pos.columns = ['alt', 'val1', 'ttstr','varn','env']\n",
    "# 'ttstr' can take two possible string values '>0' and '<0'. \n",
    "# 'env' can take two string values 'stable' and 'random'. \n",
    "# 'varn' can take several possible string values.\n",
    "# I want to select rows that have ttstr = '>0' for both stable and random values of 'env'.\n",
    "# How to do it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac95bf45",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## corr within ps2_ (of ES and windows-stat measues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288bbe9d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# PS_\n",
    "# all corrs are positive within participants\n",
    "from behav_proc import compare0\n",
    "def f(df):\n",
    "    if len(df) == 0:\n",
    "        return None\n",
    "    ttrs = compare0(df, 'r')\n",
    "    return ttrs\n",
    "ttrs = cocoln2corrs_per_subj.query('cocoln == \"ps2_\"').\\\n",
    "    groupby(['varn','ps2_'], observed=True).apply(f)\n",
    "print(getAddInfo())\n",
    "ttrssig = ttrs.query('pval <= 0.05')\n",
    "#display(ttrssig[['pval','ttstr','T']])\n",
    "\n",
    "ttrs_pos = ttrs.query('pval <= 0.05 and ttstr == \"r > 0\"')\n",
    "display(ttrs_pos[['pval','ttstr']])\n",
    "varnames = list(ttrs_pos.reset_index()['varn'].values)\n",
    "print(varnames)\n",
    "#loc[:,'error_pscadj_std5',:]\n",
    "\n",
    "# ttrs = corrs_per_subj2.\\\n",
    "#     groupby(['thr','ps_']).apply(f)\n",
    "# print(getAddInfo())\n",
    "# display(ttrs.query('pval <= 0.05 and thr in @thrs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a90b13",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ps_v = dfall.reset_index()['ps2_'].unique()\n",
    "len(ps_v), ps_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb7c10d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# count number of significant phases\n",
    "nu = ttrs_pos.reset_index().groupby(['varn'])[['ttstr','ps2_']].nunique()\n",
    "nu = nu.reset_index()\n",
    "display(nu[nu['ps2_'] > 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c581df",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "varns_good = nu[nu['ps2_'] == len(ps_v)].varn.values\n",
    "print(varns_good)\n",
    "\n",
    "varns_pre_good = nu[nu['ps2_'] == len(ps_v)-1].varn.values\n",
    "print(varns_pre_good)\n",
    "\n",
    "from behav_proc import formatRecentStatVarnames\n",
    "isec_nice = formatRecentStatVarnames(varns_good)\n",
    "display(varns_good)\n",
    "print('; '.join(isec_nice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f007b0da",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ttrs_pos.query('varn.isin(@varns_pre_good)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29476d90",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ttrssig_g = ttrssig_pos.reset_index().query('varn in @varns_good')\\\n",
    "    [['varn','ps_','pval','ttstr']]\n",
    "display(ttrssig_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99fcde7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mer = cocoln2corrs_per_subj.query('cocoln == \"ps2_\"').\\\n",
    "    groupby(['varn','ps2_'], observed=True)['r'].mean()\n",
    "\n",
    "for varn in varns_good:\n",
    "    print('  ',varn)    \n",
    "    \n",
    "    r = ttrssig_g.query('varn == @varn').\\\n",
    "        reset_index()[['varn','ps2_','pval']]\n",
    "    d = r.T.to_dict()\n",
    "    #print(d)\n",
    "    s = ''\n",
    "    for k,v in d.items(): \n",
    "        ps_nice = ps_2nice[v['ps2_']].lower()\n",
    "        fv = v['pval']\n",
    "        s += f\"for {ps_nice} \"            \n",
    "        s += f' mean r = {mer[(varn,v[\"ps2_\"])]:.3f} and p-val={fv:.3e}; '        \n",
    "            \n",
    "        \n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a823fb4d",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Histlen individ per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f046d3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dfcs_multi\n",
    "# good to add block name because we make a pause between so supposedly we loose memory about last errors\n",
    "dfcs2 = dfc.sort_values(\n",
    "    ['pert_seq_code', 'subject', 'trial_group_col_calc','trials'])\n",
    "grp = dfcs2.\\\n",
    "    groupby(['pert_seq_code', 'subject', 'trial_group_col_calc','block_name'],\n",
    "           observed=True)\n",
    "\n",
    "vars_to_av = ['error_pscadj', 'error_pscadj_abs'] \n",
    "\n",
    "dfs = []\n",
    "#for std_mavsz_ in range(2,4):\n",
    "for std_mavsz_ in range(2,30):    \n",
    "    print(std_mavsz_)\n",
    "    df_ = dfcs2.copy()\n",
    "    df_['histlen'] = std_mavsz_\n",
    "    for varn in vars_to_av:\n",
    "        for g,gi in grp.groups.items():\n",
    "            df_.loc[gi,f'{varn}_std'] = df_.loc[gi,varn].shift(1).rolling(std_mavsz_).std()   \n",
    "            df_.loc[gi,f'{varn}_mav'] = df_.loc[gi,varn].shift(1).rolling(std_mavsz_).mean()   \n",
    "                \n",
    "        df_[f'{varn}_invstd'] = 1/df_[f'{varn}_std']\n",
    "        df_[f'{varn}_var']    = df_[f'{varn}_std'] ** 2\n",
    "        df_[f'{varn}_mavsq']  = df_[f'{varn}_mav'] ** 2\n",
    "        df_[f'{varn}_mav_d_std']  = df_[f'{varn}_mav'].abs() / df_[f'{varn}_std']\n",
    "        df_[f'{varn}_mav_d_var']  = df_[f'{varn}_mav'].abs() / df_[f'{varn}_var']\n",
    "        df_[f'{varn}_Tan']    = df_[f'{varn}_mavsq'] / df_[f'{varn}_var']\n",
    "    dfs += [df_]        \n",
    "dfcs0 = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# only chose points where prev error is not too small (to compare with ES later)\n",
    "dfcs_multi  = truncateDf(dfcs0, 'err_sens', q=0.0, infnan_handling='discard', \n",
    "                   cols_uniqify = ['subject','histlen']) #'env','thr',\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfb2cab",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# compute corrs\n",
    "from behav_proc import compare0\n",
    "# env\n",
    "# here dfcs_multi varnames don't contain histlen, it is a sep column\n",
    "histlens = dfcs_multi['histlen'].unique()\n",
    "dfs = []\n",
    "import pingouin as pg\n",
    "for cocoln in ['None', 'env']:#,'ps_']:\n",
    "    #for std_mavsz_ in histlens:    \n",
    "    for varn0 in ['error_pscadj','error_pscadj_abs']:\n",
    "        for varn in  [f'{varn0}_std',\n",
    "                      f'{varn0}_invstd',                     \n",
    "                     f'{varn0}_mavsq',\n",
    "                      f'{varn0}_mav_d_std',\n",
    "                      f'{varn0}_mav_d_var',\n",
    "                     f'{varn0}_Tan']:            \n",
    "            def f(df_):\n",
    "                r = pg.corr( df_[varn], df_['err_sens'],  method='spearman')\n",
    "                r['method'] = 'spearman'\n",
    "                return r\n",
    "            cols = ['histlen','subject']\n",
    "            if cocoln != 'None':\n",
    "                cols += [cocoln]\n",
    "            print('Starting ' ,cocoln, varn, cols)\n",
    "            assert not dfcs_multi.duplicated(cols + ['trials']).any()\n",
    "            corrs_per_subj = dfcs_multi.groupby(cols, observed=True).apply(f)\n",
    "            corrs_per_subj = corrs_per_subj.rename(columns={'p-val':'pval'})            \n",
    "            corrs_per_subj['varn'] = varn                    \n",
    "            corrs_per_subj['cocoln'] = cocoln #corrs_per_subj \n",
    "            dfs += [corrs_per_subj.reset_index()]\n",
    "    \n",
    "cocoln2corrs_per_subj_multi = pd.concat(dfs, ignore_index = True)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dab1f6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(cocoln2corrs_per_subj_multi),len(cocoln2corrs_per_subj_.query('cocoln.isin([\"None\",\"env\"])'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f9f58e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from behav_proc import formatRecentStatVarnames\n",
    "def printNice(ttrs):\n",
    "    for rowi,row in ttrs.iterrows():\n",
    "        varn = row['varn']\n",
    "        varn_nice = formatRecentStatVarnames([varn],'')[0]\n",
    "        s = varn_nice\n",
    "        s += f\" (history length mean={row['histlen_mean']:.1f} trials, std={row['histlen_std']:.1f} trials)\"\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb1df7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def f(df):\n",
    "    if len(df) == 0:\n",
    "        return None\n",
    "    ttrs = compare0(df, 'r', cols_addstat = ['histlen'])\n",
    "    return ttrs\n",
    "\n",
    "for cocoln in ['None', 'env']: #,'ps_']:\n",
    "    # within env or not?\n",
    "    print('###### cocoln = ',cocoln)\n",
    "    \n",
    "    # choose best p-value among different histlens\n",
    "    if cocoln != 'None':\n",
    "        cocoln_add = [cocoln]\n",
    "    else:\n",
    "        cocoln_add = []    \n",
    "    df_ = cocoln2corrs_per_subj_multi.query('cocoln == @cocoln')\n",
    "    cols0 = ['subject','varn']    \n",
    "    cols0 += cocoln_add\n",
    "    grp = df_.groupby(cols0, observed=True )\n",
    "    \n",
    "    # take with with the lower p-value among all histlens\n",
    "    dfr = aggRows(df_, 'pval', 'min',  grp, coltake = 'corresp') \n",
    "    \n",
    "    display('r info:', dfr.\\\n",
    "        groupby(cocoln_add + ['varn'], observed=True)['r'].describe() )\n",
    "    display('(for r>0) histlen info:', \n",
    "        dfr.query('r > 0').groupby(cocoln_add + ['varn'], \n",
    "                                   observed=True)['histlen'].describe() )\n",
    "    display('(for r>0) pval info:', \n",
    "        dfr.query('r > 0').groupby(cocoln_add + ['varn'], \n",
    "                                   observed=True)['pval'].describe() )\n",
    "    # compare r with zero\n",
    "    cols1 = ['varn']\n",
    "    cols1 += cocoln_add\n",
    "    ttrs = dfr.\\\n",
    "        groupby(cols1, observed=True).apply(f).reset_index()\n",
    "    print(getAddInfo())\n",
    "    \n",
    "    cols = ['varn','pval','ttstr','histlen_mean','histlen_std']\n",
    "    cols = cocoln_add + cols\n",
    "    \n",
    "    ttrs_neg= ttrs.query('pval <= 0.05 and ttstr == \"r < 0\"')        \n",
    "    ttrs_pos = ttrs.query('pval <= 0.05 and ttstr == \"r > 0\"')   \n",
    "    display(ttrs_neg[cols])\n",
    "    display(ttrs_pos[cols])\n",
    "    \n",
    "    varnames = list(ttrs_pos.reset_index()['varn'].values)    \n",
    "    if cocoln != 'None':\n",
    "        varnames_ext = zip(varnames, list(ttrs_pos.reset_index()[cocoln].values) )\n",
    "        varnames_ext  = list(varnames_ext)\n",
    "        print('r>0 varnames ',varnames_ext)\n",
    "    else:\n",
    "        print('r>0 varnames' , ', '.join(varnames) )\n",
    "    \n",
    "    printNice(ttrs_pos)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85192947",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Error consist vs stats (useless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd158c1c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfcs2 = truncateDf(dfcs_fixhistlen, 'err_sens_change', \n",
    "       q=0.0, infnan_handling='discard', \n",
    "       cols_uniqify = ['subject','env'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a3eb30",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for varn in varnames_toshow:\n",
    "    coln_same = 'err_sign_same3'\n",
    "    qs = f'{coln_same} != 0.'\n",
    "    grp = dfcs2.query(qs).groupby(['subject',coln_same,'env'],\n",
    "                                 observed=True)\n",
    "    dfme = grp.mean(numeric_only=1).reset_index()\n",
    "    dfme['Environment'] = dfme['env']\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "        warnings.filterwarnings('ignore',category=UserWarning)\n",
    "        fg = sns.catplot(data=dfme, kind='box',\n",
    "             y =varn, x=coln_same,\n",
    "             hue='Environment',hue_order=['stable','random'],\n",
    "             palette=['tab:orange','tab:grey'],\n",
    "            showfliers=True, legend_out=False, height=4)\n",
    "    for ax in fg.axes.flatten():\n",
    "        ax.axhline(0,ls=':',c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c61344",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## plot of var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a9c8c3",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot VAR\n",
    "use_var_pubnames = False\n",
    "#%debug\n",
    "for suff in ['std5','invstd5']:\n",
    "    for varn, pertc in [('error_pscadj', 0.01), ('error_change',0.01), \n",
    "                        ('err_sens', 0.017)]:\n",
    "        c = 1 / np.pi  * 180\n",
    "        #for truncs, df in zip(['truncate q=5%','truncate no'],[dfc, dfc0]):\n",
    "        for truncs, df in zip(['mestd * 1.0'],[dfcs]):\n",
    "            plt.figure(figsize=(12,4))\n",
    "            #qs = 'trial_group_col_calc in [\"trialwe\",\"trialwtgt_we\"]'\n",
    "            #qs += ' and pert_seq_code == 0'\n",
    "            #df_= df.query(qs)\n",
    "            df_ = df\n",
    "            varn_eff = f\"{varn}_{suff}\"    \n",
    "            ax = sns.lineplot(x=\"trials\", y=varn_eff,  estimator='mean', ci='sd',\n",
    "                         data=df_)\n",
    "            vshift = 0.\n",
    "            if varn.startswith('err_sens'):\n",
    "                vshift = 0.5  \n",
    "            # important to put this legend call before plotting pert and env\n",
    "            #plt.legend(title='', loc='lower right', labels=['within tgt', 'across tgt'])\n",
    "            ax.plot(tr, vshift + pert * pertc, c='violet', ls= '--', label='perturbation')\n",
    "            #ax.plot(tr, vshift + envv * 30 * pertc, c='black', ls = ':', lw=0, marker='.' ,\n",
    "            #        alpha=0.2, label='environment')\n",
    "\n",
    "            axlbl = varn\n",
    "            if use_var_pubnames:\n",
    "                axlbl = var_pubnames[varn]\n",
    "            else:\n",
    "                ax.set_title(f'{varn}  {truncs}')\n",
    "\n",
    "            ax.axhline(0,ls=':',c='red', alpha=0.7)\n",
    "            ax.set_ylabel(axlbl + f'_{suff}' )\n",
    "            addTitleInfo(ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59303692",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mavsz = 10\n",
    "fg = sns.relplot(kind='line', x=\"trials\", \n",
    "                 y=f'err_sens_mav{mavsz}',  estimator='mean', ci='sd',\n",
    "                 col='subject', col_wrap=4,\n",
    "                data=df_)\n",
    "for ax in fg.axes.flatten():\n",
    "    ax.plot(tr, vshift + pert * pertc, c='violet', ls= '--', label='perturbation')\n",
    "    ax.axhline(0,ls=':',c='red', alpha=0.7)\n",
    "        \n",
    "plt.suptitle(f'err_sens_mav {mavsz}')\n",
    "addTitleInfo(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9940998",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot MAV\n",
    "mavsz = 10\n",
    "use_var_pubnames = False\n",
    "#%debug\n",
    "for varn, pertc in [('error_pscadj', 0.01), \n",
    "                    ('error_change',0.001),\n",
    "                    ('err_sens', 0.017)]:\n",
    "    c = 1 / np.pi  * 180\n",
    "    #for truncs, df in zip(['truncate q=5%','truncate no'],[dfc, dfc0]):\n",
    "    for truncs, df in zip(['mestd * 1.0'],[dfcs]):\n",
    "        plt.figure(figsize=(12,4))\n",
    "        df_ = df\n",
    "        varn_eff = f\"{varn}_mav{mavsz}\"  \n",
    "        ax = sns.lineplot(x=\"trials\", y=varn_eff,  estimator='mean', ci='sd',\n",
    "                     data=df_)\n",
    "\n",
    "        vshift = 0.\n",
    "        if varn.startswith('err_sens'):\n",
    "            vshift = 0.5\n",
    "  \n",
    "        # important to put this legend call before plotting pert and env\n",
    "        #plt.legend(title='', loc='lower right', labels=['within tgt', 'across tgt'])\n",
    "        ax.plot(tr, vshift + pert * pertc, c='violet', ls= '--', label='perturbation')\n",
    "        #ax.plot(tr, vshift + envv * 30 * pertc, c='black', ls = ':', lw=0, marker='.' ,\n",
    "        #        alpha=0.2, label='environment')\n",
    "        \n",
    "        axlbl = varn\n",
    "        if use_var_pubnames:\n",
    "            axlbl = var_pubnames[varn]\n",
    "        else:\n",
    "            ax.set_title(f'{varn}  {truncs}')\n",
    "            \n",
    "        ax.axhline(0,ls=':',c='red', alpha=0.7)\n",
    "        ax.set_ylabel(axlbl + '_mav' )\n",
    "        addTitleInfo(ax)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38c6ea6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# #Modifying @jfb method, gives the function below which worked fine on ipykernel-5.3.4.\n",
    "# from IPython.display import display, Javascript\n",
    "# def getNotebookName():\n",
    "#     display(Javascript('IPython.notebook.kernel.execute(\"NotebookName = \" + \"\\'\"+window.document.getElementById(\"notebook_name\").innerHTML+\"\\'\");'))\n",
    "#     try:\n",
    "#         _ = type(NotebookName)\n",
    "#         return NotebookName\n",
    "#     except:\n",
    "#         return None\n",
    "# getNotebookName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9471829",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfall.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9490e4a7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfall.groupby('subject')['movement_duration'].mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434343be",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfall.groupby('subject')['trial_duration'].mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311b7b30",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.get_su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a4c68d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "os.environ.get(\"NOTEBOOK_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c182fa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cd71bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Error consist vs ES (Herzfeld test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9503d1",
   "metadata": {},
   "source": [
    "## Error change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1244ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncateDf(df_wthr, 'err_sens', \n",
    "#        q=0.0, infnan_handling='discard', \n",
    "#        cols_uniqify = ['subject','env'], verbose=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24fda28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = df_wthr.copy() # df_thr is untruncated and we need it to compute error change\n",
    "\n",
    "\n",
    "dfc = dfc.query('err_sens.abs() <= @ES_thr')\n",
    "\n",
    "dfcs_ = truncateDf(dfc, 'err_sens_change', \n",
    "       q=0.0, infnan_handling='discard', \n",
    "       cols_uniqify = ['subject','env'], verbose=True)\n",
    "\n",
    "# make sure I have not changed the algo\n",
    "assert len(dfcs_.query('err_sign_same == 0')) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b30f5f0",
   "metadata": {
    "tags": [
     "final_output"
    ]
   },
   "outputs": [],
   "source": [
    "behav_proc.getQueryPct(dfcs_,'err_sign_same == 0')\n",
    "for i in range(2,4):\n",
    "    behav_proc.getQueryPct(dfcs_,f'err_sign_same{i} == 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e271f90a",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#from figure.plots import relplot_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5037a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.get_xticks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77be650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfme.query('env == @env').query('err_sign_same3 == -1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dd68a9",
   "metadata": {
    "tags": [
     "final_output"
    ]
   },
   "outputs": [],
   "source": [
    "# Error change\n",
    "import warnings\n",
    "from figure.mystatann import plotSig0All, plotSig0\n",
    "from figure import renameTickLabels\n",
    "dfcs2  = truncateDf(dfcs_, 'err_sens_change', q=0.0,\n",
    "                    infnan_handling='discard', \n",
    "                   cols_uniqify = ['subject','env'])\n",
    "\n",
    "#coln_same = 'err_sign_same3'\n",
    "coln_same = 'err_sign_same'\n",
    "qs = f'{coln_same} != 0.'\n",
    "grp = dfcs2.query(qs).groupby(['subject',coln_same,'env'],\n",
    "                             observed=True)\n",
    "dfme = grp.mean(numeric_only=1).reset_index()\n",
    "dfme['Environment'] = dfme['env']\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "    warnings.filterwarnings('ignore',category=UserWarning)\n",
    "    fg = sns.catplot(data=dfme, kind='box',\n",
    "         y ='err_sens_change', x=coln_same,\n",
    "         hue='Environment',hue_order=['stable','random'],\n",
    "         palette=['tab:orange','tab:grey'],\n",
    "        showfliers=True, legend_out=False)\n",
    "#fg.apply(lambda ax: ax.axline(y=0))\n",
    "#def f(data, **kwargs):\n",
    "#    plt.axhline(y=0)\n",
    "#fg.map(f, ls=\":\", c=\".5\" )\n",
    "for ax in fg.axes.flatten():\n",
    "    ax.axhline(0,ls=':',c='r')\n",
    "    \n",
    "ttrs0,ttrssigs0 = [],[]\n",
    "for env_,xt,xv in [('stable',-0.25,-1),('random',0.25,-1),\n",
    "                  ('stable',0.75,1),('random',1., 1)]:\n",
    "    #for xv in [-1,1]:\n",
    "    for alt in ['greater','less','two-sided']:\n",
    "        ttrs0_,ttrssig0 = plotSig0(ax, x=xv, y=0.63, df=dfme.query('env == @env_'), \n",
    "                 coln='err_sens_change', colx = coln_same, xt=xt, alt=alt)\n",
    "        ttrs0_['env'] = env_\n",
    "        ttrs0_[coln_same] = xv\n",
    "        ttrs0 += [ttrs0_]\n",
    "        if len(ttrssig0):\n",
    "            row = ttrssig0.iloc[0]\n",
    "            ttrssig0['env'] = env_\n",
    "            ttrssig0[coln_same] = xv\n",
    "            #print(env_,xv,row['pval'],ttstr)\n",
    "            ttrssigs0 += [ttrssig0]\n",
    "ttrssigs0 = pd.concat(ttrssigs0, ignore_index=1)\n",
    "ttrs0 = pd.concat(ttrs0, ignore_index=1)\n",
    "        \n",
    "#plotSigAll(ax, 1, 0.1,  df=dfme, lab2tick = )\n",
    "    \n",
    "plt.suptitle('Error sensitivity dependence \\non error sign consitency',y=1.1)\n",
    "ax.set_ylabel('Error sensitivity change,\\nmean within participant')\n",
    "ax.set_xlabel('Sign consistency')\n",
    "renameTickLabels(ax, {'-1':'inconsistent', '1':'consistent' })\n",
    "plt.savefig(pjoin(path_fig, f'ESchange_per_sign_consist_{coln_same}.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613a012f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e5afb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcs2.groupby()['err_sens_change']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db98c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfme[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53f91dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcs2  = truncateDf(dfcs_.query('trialwpertstage_wb <= 60'), 'err_sens_change', q=0.0,\n",
    "                    infnan_handling='discard', \n",
    "                   cols_uniqify = ['subject','env'])\n",
    "fg = sns.relplot(data=dfcs2, kind='line',  x='trialwpertstage_wb',y='err_sens_change', hue='err_sign_same', col='env' )\n",
    "#kind='line',\n",
    "fg.refline(y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dfde91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error change, but without initial trials in pert\n",
    "dfcs2  = truncateDf(dfcs_, 'err_sens_change', q=0.0,\n",
    "                    infnan_handling='discard', \n",
    "                   cols_uniqify = ['subject','env']).query('trialwpertstage_wb != 1')\n",
    "\n",
    "#coln_same = 'err_sign_same3'\n",
    "coln_same = 'err_sign_same'\n",
    "qs = f'{coln_same} != 0.'\n",
    "grp = dfcs2.query(qs).groupby(['subject',coln_same,'env'],\n",
    "                             observed=True)\n",
    "dfme = grp.mean(numeric_only=1).reset_index()\n",
    "dfme['Environment'] = dfme['env']\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "    warnings.filterwarnings('ignore',category=UserWarning)\n",
    "    fg = sns.catplot(data=dfme, kind='box',\n",
    "         y ='err_sens_change', x=coln_same,\n",
    "         hue='Environment',hue_order=['stable','random'],\n",
    "         palette=['tab:orange','tab:grey'],\n",
    "        showfliers=True, legend_out=False)\n",
    "#fg.apply(lambda ax: ax.axline(y=0))\n",
    "#def f(data, **kwargs):\n",
    "#    plt.axhline(y=0)\n",
    "#fg.map(f, ls=\":\", c=\".5\" )\n",
    "for ax in fg.axes.flatten():\n",
    "    ax.axhline(0,ls=':',c='r')\n",
    "    \n",
    "ttrs0,ttrssigs0 = [],[]\n",
    "for env_,xt,xv in [('stable',-0.25,-1),('random',0.25,-1),\n",
    "                  ('stable',0.75,1),('random',1., 1)]:\n",
    "    #for xv in [-1,1]:\n",
    "    for alt in ['greater','less','two-sided']:\n",
    "        ttrs0_,ttrssig0 = plotSig0(ax, x=xv, y=0.63, df=dfme.query('env == @env_'), \n",
    "                 coln='err_sens_change', colx = coln_same, xt=xt, alt=alt)\n",
    "        ttrs0_['env'] = env_\n",
    "        ttrs0_[coln_same] = xv\n",
    "        ttrs0 += [ttrs0_]\n",
    "        if len(ttrssig0):\n",
    "            row = ttrssig0.iloc[0]\n",
    "            ttrssig0['env'] = env_\n",
    "            ttrssig0[coln_same] = xv\n",
    "            #print(env_,xv,row['pval'],ttstr)\n",
    "            ttrssigs0 += [ttrssig0]\n",
    "ttrssigs0 = pd.concat(ttrssigs0, ignore_index=1)\n",
    "ttrs0 = pd.concat(ttrs0, ignore_index=1)\n",
    "        \n",
    "#plotSigAll(ax, 1, 0.1,  df=dfme, lab2tick = )\n",
    "    \n",
    "plt.suptitle('Error sensitivity dependence \\non error sign consitency',y=1.1)\n",
    "ax.set_ylabel('Error sensitivity change,\\nmean within participant')\n",
    "ax.set_xlabel('Sign consistency')\n",
    "renameTickLabels(ax, {'-1':'inconsistent', '1':'consistent' })\n",
    "#plt.savefig(pjoin(path_fig, f'ESchange_per_sign_consist_{coln_same}.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b60ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrs0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4419d3c0",
   "metadata": {
    "tags": [
     "final_output"
    ]
   },
   "outputs": [],
   "source": [
    "# for positive, negative signs of \n",
    "display(ttrssigs0)\n",
    "s0 =''\n",
    "for i,row in ttrssigs0.query('alt != \"two-sided\"').iterrows():\n",
    "    sign = row['ttstr'][-3:]\n",
    "    sc = None\n",
    "    if row[coln_same] == 1:\n",
    "        sc = 'consistent'\n",
    "    elif row[coln_same] == -1:\n",
    "        sc = 'inconsistent'\n",
    "    s = 'In {} environment for {} consecutive error signs ES change mean is {:.2f} (std={:.2f}) {} with p-value = {:.2e}'.\\\n",
    "        format(row['env'],sc,row['err_sens_change_mean'],row['err_sens_change_std'],sign,row['pval'])\n",
    "    s0 += s + '.\\n'\n",
    "print(s0)\n",
    "\n",
    "s0 =''\n",
    "for i,row in ttrs0.query('alt == \"two-sided\" and pval > 0.05').iterrows():\n",
    "    sign = row['ttstr'][-3:]\n",
    "    sc = None\n",
    "    if row[coln_same] == 1:\n",
    "        sc = 'consistent'\n",
    "    elif row[coln_same] == -1:\n",
    "        sc = 'inconsistent'\n",
    "    s = 'In {} environment for {} consecutive error signs ES change mean {:.2f} has unclear sign (std={:.2f}) with p-value = {:.2e}'.\\\n",
    "        format(row['env'],sc,row['err_sens_change_mean'],row['err_sens_change_std'],row['pval'])\n",
    "    s0 += s + '.\\n'\n",
    "print(s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2299b37b",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#%debug\n",
    "from figure.mystatann import square_updiag\n",
    "from itertools import product\n",
    "def f(df, coln, colx, colhue, colx_vals= None, colhue_vals=None,\n",
    "     xts=None):\n",
    "    \n",
    "    if colx_vals is None:\n",
    "        colx_vals = list(sorted(df[colx].unique()))\n",
    "    if colhue_vals is None:\n",
    "        colhue_vals = list(sorted(df[colhue].unique()))\n",
    "    hierpairs = product(colx_vals, colhue_vals)\n",
    "    \n",
    "    qss = []\n",
    "    for a,b in hierpairs:\n",
    "        if isinstance(b,str):\n",
    "            b = '\"' + b + '\"'\n",
    "        if isinstance(a,str):\n",
    "            a = '\"' + a + '\"'\n",
    "        qs = '{} == {} and {} == {}'.format(colx,a,colhue,b)\n",
    "        qss += [qs]\n",
    "        \n",
    "    #print(qss)\n",
    "    qs_pairs = square_updiag(qss)\n",
    "    ttrssig,ttrs = comparePairs(df, coln, [colx,colhue], paired=True, qspairs = qs_pairs)\n",
    "    return ttrssig,ttrs\n",
    "ttrssig,_ = f(dfme,'err_sens_change', coln_same, 'env')\n",
    "ttrssig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9011a858",
   "metadata": {
    "code_folding": [
     1
    ],
    "tags": [
     "final_output"
    ]
   },
   "outputs": [],
   "source": [
    "import re    \n",
    "def parseQs(qs):\n",
    "    pattern = r\"(?P<var1>\\w+)\\s*==\\s*(?P<val1>.*?)\\s+and\\s+(?P<var2>\\w+)\\s*==\\s*(?P<val2>.*)\"\n",
    "    match = re.search(pattern, qs)\n",
    "    if match:\n",
    "        var1 = match.group('var1')\n",
    "        val1 = match.group('val1')\n",
    "        var2 = match.group('var2')\n",
    "        val2 = match.group('val2')\n",
    "        #print(f\"Variable 1: {var1}, Value 1: {val1}\")\n",
    "        #print(f\"Variable 2: {var2}, Value 2: {val2}\")\n",
    "        \n",
    "        return {var1:eval(val1), var2:eval(val2 )}\n",
    "    print('no match for ',qs)\n",
    "    return None\n",
    "#parseQs(s)\n",
    "# for s in set(ttrssig.qs1.unique()) | set(ttrssig.qs2.unique()) :    \n",
    "#     print(s)\n",
    "#     d = parseQs(s)\n",
    "#     print(d)\n",
    "\n",
    "sign2nice = {1:'consistent', -1:'inconsistent'}\n",
    "\n",
    "#ttrssig_ps,_ = comparePairs(me_ps, 'err_sens', 'ps_', alt=['greater'], paired=True, updiag=False)\n",
    "#display(ttrssig_ps[ttrssig_ps.columns[-5:]])\n",
    "# within env\n",
    "s1 = ''\n",
    "for i,row in ttrssig.query('alternative != \"two-sided\"').iterrows():\n",
    "    \n",
    "    d1 = parseQs( row['qs1'] )\n",
    "    d2 = parseQs( row['qs2'] )\n",
    "    sc1 = sign2nice[d1[coln_same]]\n",
    "    sc2 = sign2nice[d2[coln_same]]\n",
    "    \n",
    "    if d1['env'] != d2['env']:\n",
    "        continue\n",
    "    s = f\"ES change for {d1['env']} environment for {sc1} errors is {row['alternative']} than \"\n",
    "    s += f\"ES change for {d2['env']} environment for {sc2} errors is {row['alternative']},\"\n",
    "    #ttstr = row['ttstr']\n",
    "    #s = ttstr.replace(row['val2'], ps_2nice[row['val2']] ).replace(row['val1'], ps_2nice[row['val1']] )    \n",
    "    s += f\" p-value={row['pval']:.2e}; \\n\"\n",
    "    s1 += s\n",
    "#s = f\"Stable > random p-value={row['pval']:.2e}\"\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7aad91",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### to be implem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934e4944",
   "metadata": {
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#qss += []\n",
    "    \n",
    "    for qs1,qs2 in qs_pairs:\n",
    "#     for x1,x2  in pairs:\n",
    "#     #for i,x1 in enumerate(vals):\n",
    "#     #    for x2 in vals[i+1:]:\n",
    "#         try:\n",
    "#             r = plotSig(ax,x1,x2,ycur,ticklen=ticklen,txt=txt,\n",
    "#                         hor=hor, df=df, coln=coln, colpair=colpair,\n",
    "#                         paired=paired,pooled=pooled, verbose=verbose,\n",
    "#                         alt=alt, meanloc_voffset = meanloc_voffset, graded_signif = graded_signif,\n",
    "#                         fontsize = fontsize)\n",
    "#             if len(r):\n",
    "#                 ycur += yinc\n",
    "#         except KeyError as e:\n",
    "#             print(str(e))\n",
    "\n",
    "    \n",
    "        if lab2tick is None:\n",
    "            lab2tick = getLab2Tick(ax, hor)\n",
    "        #print(lab2tick)\n",
    "\n",
    "        df_ = df.query(f'{colpair} in [@x1,@x2]')\n",
    "        assert len(df_)\n",
    "        ttrssig,ttrs = comparePairs(df_, coln, colpair, paired=paired, alt=alt)\n",
    "        if (ttrssig is None):\n",
    "            if verbose:\n",
    "                display(ttrs)\n",
    "            #print('no sig')\n",
    "            return []\n",
    "        pooled = bool(pooled)\n",
    "        ttrssig = ttrssig.query('pooled == @pooled and alternative == @alt')\n",
    "        if len(ttrssig) == 0:\n",
    "            return []\n",
    "        assert len(ttrssig) <= 1\n",
    "\n",
    "        if verbose:\n",
    "            display(ttrssig)\n",
    "\n",
    "        # draw hor line connecting\n",
    "        if not isinstance(x1,str):\n",
    "            x1 = str(x1)\n",
    "        if not isinstance(x2,str):\n",
    "            x2 = str(x2)\n",
    "        x1t,x2t = lab2tick[x1],lab2tick[x2]\n",
    "        meanloc = np.mean([x1t,x2t]) + meanloc_voffset\n",
    "        if hor:\n",
    "            ax.plot([y-ticklen,y,y,y-ticklen], [x1t,x1t,x2t,x2t], c='k')\n",
    "        else:\n",
    "            ax.plot([x1t,x1t,x2t,x2t],\n",
    "                    [y-ticklen,y,y,y-ticklen], c='k')\n",
    "\n",
    "        if graded_signif:\n",
    "            assert txt is None\n",
    "            txt = ttrssig.iloc[0]['starcode']\n",
    "            #print(ttrssig)\n",
    "        #print(x1,x2, y, len(ttrssig))\n",
    "        #print(meanloc)\n",
    "        #meanloc = 0\n",
    "        if hor:\n",
    "            ax.text(y,meanloc,txt)\n",
    "        else:\n",
    "            ax.text(meanloc,y,txt, ha='center', fontsize = fontsize)\n",
    "        return ttrssig\n",
    "\n",
    "    \n",
    "    \n",
    "    #return list(pairs)\n",
    "f(dfme, coln_same, 'env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4297f633",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## ES itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3efa16",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from figure import renameTickLabels\n",
    "dfcs2  = truncateDf(dfcs_, 'err_sens', q=0.0,\n",
    "                    infnan_handling='discard', \n",
    "                   cols_uniqify = ['subject','env'])\n",
    "\n",
    "coln_same = 'err_sign_same3'\n",
    "qs = f'{coln_same} != 0.'\n",
    "grp = dfcs2.query(qs).groupby(['subject',coln_same,'env'],\n",
    "                             observed=True)\n",
    "dfme = grp.mean(numeric_only=1).reset_index()\n",
    "dfme['Environment'] = dfme['env']\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "    warnings.filterwarnings('ignore',category=UserWarning)\n",
    "    fg = sns.catplot(data=dfme, kind='box',\n",
    "         y ='err_sens', x=coln_same,\n",
    "         hue='Environment',hue_order=['stable','random'],\n",
    "         palette=['tab:orange','tab:grey'],\n",
    "        showfliers=True, legend_out=False)\n",
    "#fg.apply(lambda ax: ax.axline(y=0))\n",
    "#def f(data, **kwargs):\n",
    "#    plt.axhline(y=0)\n",
    "#fg.map(f, ls=\":\", c=\".5\" )\n",
    "for ax in fg.axes.flatten():\n",
    "    ax.axhline(0,ls=':',c='r')\n",
    "    \n",
    "plt.suptitle('Error sensitivity dependence \\non error sign consitency',y=1.1)\n",
    "ax.set_ylabel('Error sensitivity, \\nmean within participant')\n",
    "ax.set_xlabel('Sign consistency')\n",
    "renameTickLabels(ax, {'-1':'inconsistent', '1':'consistent' })\n",
    "#plt.savefig(pjoin(path_fig, 'ESchange_per_sign_consist.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ef53b4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Generalization (Fig 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1f54ec",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Need to re-read entire dataset and don't limit to just one columns calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4cc099",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# already truncated\n",
    "#dfc_multi_tsz = dfall_mshsz#.query('thr == \"mestd*0\"')\n",
    "dfc_multi_tsz = dfall_mshsz.query('retention_factor_s == \"0.924\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820cec2b-87d4-44ac-9ba4-ff2f9c30cfe0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('min,max ES {:.3f}, {:.3f}'.format( dfc_multi_tsz.err_sens.min(), dfc_multi_tsz.err_sens.max() ) )\n",
    "assert dfc_multi_tsz['retention_factor_s'].nunique() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e3d214-8ca1-452f-afe0-291a2d6fa1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dfc_multi_tsz['dist_rad_from_prevtgt_shiftrespect'] == dfc_multi_tsz['dist_rad_from_prevtgt2']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256e6288-e3a7-4ef2-a060-1d23660a0836",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = dfc_multi_tsz.query('trial_shift_size > 1 and trial_group_col_calc == \"trialwe\"')\n",
    "neq = (df_['dist_rad_from_prevtgt_shiftrespect'] != df_['dist_rad_from_prevtgt2']).sum()\n",
    "eq = (df_['dist_rad_from_prevtgt_shiftrespect'] == df_['dist_rad_from_prevtgt2']).sum()\n",
    "print( neq/len(df_), eq/len(df_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087a5363-ff24-4db0-9c6c-5567ef035ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_[['subject_ind','trial_index','trial_shift_size','target_locs',\n",
    "    'dist_rad_from_prevtgt_shiftrespect','dist_rad_from_prevtgt2']]).iloc[12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3bc90c-3085-4bb0-98d0-31f9506a1857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8663212b-8dea-40ab-b379-736f225d713c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#distcol = 'dist_rad_from_prevtgt2'\n",
    "distcol = 'dist_rad_from_prevtgt_shiftrespect'\n",
    "\n",
    "drs = dfc_multi_tsz[distcol].unique();\n",
    "drs_f = np.array( list(map( float, drs) ) )\n",
    "drs = list(sorted(drs,key = lambda x: float(x)))\n",
    "\n",
    "\n",
    "#dfc_s = dfc[dfc['trial_group_col_calc'] == 'trialwtgt_we']\n",
    "# TODO: should I restrict to one env?\n",
    "dfc_s = dfc_multi_tsz.query('trial_group_col_calc == \"trialwe\"')\n",
    "grp = dfc_s.groupby(['trial_shift_size', distcol])\n",
    "dts = dfc_multi_tsz['trial_shift_size'].unique()\n",
    "nt = len(dts)\n",
    "\n",
    "print(drs, dts)\n",
    "\n",
    "assert nt == 4, nt\n",
    "assert len(drs) == 4, len(drs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec18374b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "drpairs = [(drs[i],drs[i+1] ) for i in range(3)]\n",
    "drpairs += [(drs[0],drs[i] ) for i in range(2,4)]\n",
    "drpairs += [(drs[1],drs[3] )]\n",
    "print(drpairs)\n",
    "\n",
    "dtpairs = [(dts[i],dts[i+1] ) for i in range(3)]\n",
    "dtpairs += [(dts[0],dts[i] ) for i in range(2,4)]\n",
    "dtpairs += [(dts[1],dts[3] )]\n",
    "dtpairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51846f68",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getPvals(dftmp,fitcol,pairs):\n",
    "    from scipy.stats import ttest_ind\n",
    "    pvalues = []\n",
    "    for drp in pairs:\n",
    "        if isinstance(drp[0],str):\n",
    "            vs1 = dftmp.query(f'{fitcol} == \"{drp[0]}\"')['err_sens']\n",
    "            vs2 = dftmp.query(f'{fitcol} == \"{drp[1]}\"')['err_sens']\n",
    "        else:\n",
    "            vs1 = dftmp.query(f'{fitcol} == {drp[0]}')['err_sens']\n",
    "            vs2 = dftmp.query(f'{fitcol} == {drp[1]}')['err_sens']\n",
    "        #ttr = ttest_ind(vs1,vs2)\n",
    "        ttr = ttest_ind(vs1,vs2, alternative='greater')\n",
    "        pvalues += [ttr.pvalue]\n",
    "        \n",
    "        print(drp, ttr.pvalue)\n",
    "\n",
    "    formatted_pvalues = [f'p={pvalue:.2e}' for pvalue in pvalues]\n",
    "    return pvalues, formatted_pvalues\n",
    "\n",
    "# make polynomial fits\n",
    "def plotPolys(ax, dftmp, fitcol, degs=range(2,6), mean=1):\n",
    "    if mean:\n",
    "        me = dftmp.groupby(fitcol).median(numeric_only=1).reset_index()\n",
    "        dftmp = me\n",
    "    dftmp[fitcol] = pd.to_numeric(dftmp[fitcol] )\n",
    "    esv, dv = dftmp[['err_sens',fitcol]]._values.T\n",
    "    print(np.min(dv),dv,dv-np.min(dv),esv)\n",
    "    #pr = np.polyfit(esv,dv,2)\n",
    "    from numpy.linalg import LinAlgError\n",
    "    dvu = np.unique(dv)\n",
    "    dvu = np.array( list(sorted(dvu)) )\n",
    "    print(dvu)\n",
    "    for deg in degs:\n",
    "        try:\n",
    "            pr = np.polyfit(dv-np.min(dv),esv-np.min(esv),deg)        \n",
    "        except (SystemError,LinAlgError):\n",
    "            print(f'Failed deg={deg}')\n",
    "            print(dv,esv, np.std(dv))\n",
    "            continue\n",
    "            \n",
    "        poly = np.poly1d(pr)\n",
    "        #if len(degs) > 1:\n",
    "        if mean:\n",
    "            lbl = f'polynomial fit of means deg={deg}'\n",
    "        else:\n",
    "            lbl = f'polynomial fit deg={deg}'\n",
    "        #else:\n",
    "        #    lbl = None\n",
    "        esv2 = poly(dvu-np.min(dvu)) + np.min(esv)\n",
    "        print(dvu-np.min(dvu), esv)\n",
    "        ax.plot(range(len(dvu)) , poly(dvu-np.min(dvu)) + np.min(esv), \n",
    "                label=lbl, c='grey', lw=0.85 )\n",
    "    return pr\n",
    "    #ax.legend(loc='lower right')\n",
    "\n",
    "#plotPolys(ax,dftmp,fitcol,mean=0)\n",
    "#ax = plt.gca()\n",
    "#plotPolys(ax,dftmp,fitcol, degs=rng, mean=meanfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b171f7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfc_multi_tsz.groupby(['subject','environment',distcol]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddf0f82-2aa9-484a-b787-b549d762e7a5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from figure.mystatann import plotSigAll\n",
    "# not pooled\n",
    "#%debug\n",
    "\n",
    "hue = 'env'\n",
    "env2color = {'stable':'lightblue', 'random':'orange'}\n",
    "aspect=1.3\n",
    "#rng = [2]\n",
    "#rng = [2,3,4,5,6,7]\n",
    "rng = [2]\n",
    "ylim = [-2,3]\n",
    "meanfit=1\n",
    "qs_spatial = f'trial_group_col_calc == \"trialwe\" and err_sens >= {ylim[0]} and err_sens <= {ylim[1]} and trial_shift_size == 1'\n",
    "qs_temporal = f'trial_group_col_calc == \"trialwe\" and {distcol} == \"0.00\"'\n",
    "#bnqs = [  ('grid_line_violin_spatial','Spatial distance [deg]',drs,drpairs,'dist_rad_from_prevtgt2', f'trial_group_col_calc == \"trialwe\" and err_sens >= {ylim[0]} and err_sens <= {ylim[1]} and trial_shift_size == 1'),\n",
    "#        ( 'grid_line_violin_temporal','Temporal distance [number of trials]',dts,dtpairs,'trial_shift_size','trial_group_col_calc == \"trialwe\" and dist_rad_from_prevtgt2 == \"0.00\"')]\n",
    "bnqs = {'grid_line_violin_spatial': ('Spatial distance [deg]',drs,drpairs,\n",
    "            distcol, qs_spatial),\n",
    "        'grid_line_violin_temporal':('Temporal distance [number of trials]',dts,dtpairs,\n",
    "            'trial_shift_size',qs_temporal)}\n",
    "\n",
    "dfr = []\n",
    "for env_type in ['stable','random']:\n",
    "    color = env2color[env_type]\n",
    "#    for bn,xlab,order,pairs,fitcol,qs in bnqs:\n",
    "    for bn,(xlab,order,pairs,fitcol,qs) in bnqs.items():\n",
    "        #qs0 = f'trial_group_col_calc == \"trialwe\" and err_sens >= {ylim[0]} and err_sens <= {ylim[1]}'\n",
    "        #qs = qs + ' and trial_shift_size == 1'\n",
    "        if env_type in ['stable', 'random']:\n",
    "            qs += ' and env == @env_type'\n",
    "            hue = None\n",
    "            \n",
    "        dftmp0 = dfc_multi_tsz.query(qs).groupby(['subject','environment',fitcol])\n",
    "        dftmp0 = dftmp0.mean(numeric_only = True).reset_index()                \n",
    "        dfr += [dftmp0]\n",
    "\n",
    "        #dftmp0 = dfc_multi_tsz.query(qs)\n",
    "        #fitcol = 'dist_rad_from_prevtgt2'\n",
    "        fg = sns.catplot(kind='violin', data=dftmp0, y='err_sens', \n",
    "                         hue=hue, x=fitcol, order = order,\n",
    "                          color=color, aspect=aspect, cut=True)\n",
    "        #dftmp = dfc_multi_tsz.query(qs).copy()\n",
    "        dftmp = dftmp0.copy()\n",
    "        #pvalues, formatted_pvalues = getPvals(dftmp,fitcol, pairs)\n",
    "\n",
    "        ax = fg.axes.flatten()[0]\n",
    "        ttrs,ttrs_sig = plotSigAll(ax, 1.3, 0.2, 0.05, df=dftmp, \n",
    "                   coln = 'err_sens', colpair = fitcol,\n",
    "                  verbose = 0)\n",
    "\n",
    "        for ax in fg.axes.flatten():\n",
    "            ax.axhline(0,ls=':',c='r')\n",
    "            ax.set_ylabel('Error sensitivity', fontdict={'fontsize':12})\n",
    "            ax.set_xlabel(xlab, fontdict={'fontsize':12} )\n",
    "            if bn == 'grid_line_violin_spatial':\n",
    "                ax.set_xticklabels(['same target', 45, 90, 135])\n",
    "            ax.set_ylim(ylim)\n",
    "            ax.set_title(f'{env_type} environment', y = 1,\n",
    "                        fontdict={'fontsize':15, 'fontweight':'bold'})\n",
    "\n",
    "\n",
    "#         from statannotations.Annotator import Annotator    \n",
    "#         annotator = Annotator(ax,pairs, data=dftmp0, x=fitcol, y='err_sens',\n",
    "#                              plot='violinplot', order=order)\n",
    "#         #annotator.set_custom_annotations(formatted_pvalues)\n",
    "#         annotator.set_pvalues(pvalues)\n",
    "#         annotator.annotate()\n",
    "\n",
    "        ax.set_ylim(-1,3)\n",
    "\n",
    "        plotPolys(ax,dftmp,fitcol, degs=rng, mean=meanfit)\n",
    "        #bn = 'grid_line_violin_spatial'\n",
    "        plt.savefig(pjoin(path_fig,'behav',f'nopool_{env_type}_{bn}.svg'))\n",
    "        plt.savefig(pjoin(path_fig,'behav',f'nopool_{env_type}_{bn}.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c57f1a5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#corrMean?\n",
    "#compare0?\n",
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78170500",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# compute mean pearson corr between temporal/spatial distance and err sens\n",
    "dfr = []\n",
    "for bn,(xlab,order,pairs,fitcol,qs) in bnqs.items():\n",
    "    dftmp0 = dfc_multi_tsz.query(qs).groupby(['subject','env',fitcol])\n",
    "    dftmp0 = dftmp0.mean(numeric_only = True).reset_index()\n",
    "    #dftmp0['thr'] = \"_\"\n",
    "    dftmp0[fitcol] = dftmp0[fitcol].astype(float)\n",
    "    corrme,corrme_sep = corrMean(dftmp0, coltocorr=fitcol, \n",
    "        stagecol='env' , coln='err_sens', method='spearman')\n",
    "    corrme_sep['antype'] = bn\n",
    "    dfr += [corrme_sep.reset_index()]\n",
    "dfr = pd.concat(dfr, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03866800",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfr['method']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e3fd0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ttrss = []\n",
    "for antype in bnqs.keys():\n",
    "    for env in dfr.env.unique():\n",
    "        ttrs = compare0(dfr.query('antype == @antype and env == @env'), 'r', ['less'], 'r')\n",
    "        ttrs['antype'] = antype\n",
    "        ttrs['env'] = env\n",
    "        ttrss += [ttrs]\n",
    "ttrs = pd.concat(ttrss, ignore_index=True)\n",
    "assert len(ttrs.query('pval <= 0.05')) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e896474b",
   "metadata": {
    "hidden": true,
    "tags": [
     "final_output"
    ]
   },
   "outputs": [],
   "source": [
    "# slope sign\n",
    "s0 = ''\n",
    "for i,row in ttrs.iterrows():\n",
    "    ant = row['antype'].split('_')[-1]        \n",
    "    #row['alt']\n",
    "    ttsshrt = row['ttstr'][-3:]\n",
    "    s = 'for {} environment the the mean pearson correlation of ES versus {} distance is {:.2f} (std={:.2f}) {}, p-value = {:.2e}'.format(\n",
    "        row['env'], ant, row['r_mean'], row['r_std'], ttsshrt, row['pval']\n",
    "    )\n",
    "    #print(s)\n",
    "    s0 += s[0].upper() + s[1:] + '. \\n'\n",
    "print(s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507b5b0a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#dfr.query('antype == @antype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177e7c39",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ttrss = []\n",
    "for antype in bnqs.keys():    \n",
    "    ttrssig,ttrs = comparePairs(dfr.query('antype == @antype'), 'r', 'env', \n",
    "            alt = ['greater','less','two-sided'], \n",
    "                        paired=True, pooled=0 )\n",
    "    ttrs['antype'] = antype\n",
    "    #ttrs['env'] = env\n",
    "    ttrss += [ttrs]\n",
    "ttrs = pd.concat(ttrss, ignore_index=True)\n",
    "#assert len(ttrs.query('pval <= 0.05')) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea9aa80",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display(ttrs)\n",
    "ttrssig = ttrs.query('pval <= 0.05 and alternative == \"less\"')\n",
    "print('sig only')\n",
    "display(ttrssig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25b141f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ttrs.query('alternative == \"two-sided\" and antype == \"grid_line_violin_temporal\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cee5f8f",
   "metadata": {
    "hidden": true,
    "tags": [
     "final_output"
    ]
   },
   "outputs": [],
   "source": [
    "#ttrs_sig\n",
    "if len(ttrssig):\n",
    "    print('!! SOME SIG !!!')\n",
    "    pv = ttrssig.iloc[0]['pval']\n",
    "else:\n",
    "    pv = ttrs.query('alternative == \"two-sided\" and antype == \"grid_line_violin_temporal\"').iloc[0]['pval']\n",
    "s_ = '{:.2e}'.format( pv )\n",
    "pvtemp = pv\n",
    "\n",
    "pv = ttrs.query('alternative == \"two-sided\" and antype == \"grid_line_violin_spatial\"').iloc[0]['pval']\n",
    "pvspat = pv\n",
    "s_2 = '{:.2e}'.format( pv )\n",
    "if len(ttrssig):\n",
    "    s = f'Temporal slope in random is stronger negative than in stable, p-value={s_}. '\n",
    "else:\n",
    "    s = f'Temporal slopes in random and stable are not different, p-value={s_}. '\n",
    "s += f'Spatial slopes in random and stable are not different, p-value={s_2}. '\n",
    "#print(s)\n",
    "\n",
    "\n",
    "print(s0,'\\n',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1567c95",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f'{pvspat:.2e}, {pvtemp:.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24a9304-a565-4df4-9455-b3968e4f2f1e",
   "metadata": {},
   "source": [
    "## new stats (D. Herzfeld -suggetsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b8de7-fc5c-4166-9e9f-a4544acec49e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643b4cb2-3786-4c2e-9b83-cf3bf575a464",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc_multi_tsz.query(qs).groupby(['subject','env',fitcol,'trial_index']).size().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7baeb8-3d9a-4a74-b5c5-66294635636e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### take all trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7bcc6-4579-49cf-8a27-b8c7e4861f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = 'trial_group_col_calc == \"trialwe\"'# and dist_rad_from_prevtgt2 == \"0.00\"'\n",
    "df_ = dfc_multi_tsz.query(qs)\n",
    "print(len(df_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ab328-5fd9-428b-8388-5cdb600f1240",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_shifts = df_.groupby(['subject','env','trial_index'])\n",
    "grp_shifts.size().min(), grp_shifts.size().mean(), grp_shifts.size().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1398641a-a5fa-4283-a9c4-7b897de55a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# super long\n",
    "method = 'spearman' # 'pearson'\n",
    "def f(subdf):\n",
    "    r = pg.corr( subdf['trial_shift_size'], subdf['err_sens'], method=method)\n",
    "    r['method'] = method\n",
    "    return r\n",
    "corrs_shifts = grp_shifts.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ef6ac-ad38-4729-b0bd-37eba249d53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_shifts.to_pickle(pjoin(path_data, f'corrs_shifts_{method}.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee2dad-a878-450e-8a5c-7e57fbf2d005",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_per_subj = corrs_shifts.reset_index().groupby(['env','subject'])['r'].mean().reset_index()\n",
    "r_per_subj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e8ba8a-4f7f-4bda-9cb2-43e27cb20ab8",
   "metadata": {},
   "source": [
    "I have tried to implement what D. Herzfeld suggested (at least as I understood him): to calculate statistics for temporal generalization differently. For every environment for every subject for every trial I have taken the four numbers (corresponding to 4 temporal shifts used to compute ES) and computes correlations between these four numbers and the shift size. Then I averaged the spearman rho across trial indices and compared the result with zero within environment (so 20 numbers for each environment).\n",
    "\n",
    "It gave me a bit puzzling result at first sight not consistent with the generalization picture (Fig 4 of the manuscript): for random, as previously, the rho is significantly negative. But for stable it is significantly positive!\n",
    "\n",
    "Probably it is the case because the error mostly shrinks in time in stable environment and thus the quantity\n",
    "   correction_{n-1} / e_{n-k}\n",
    "grows\n",
    "\n",
    "How do you think, shall we report it in results? Or just leave for discussion (or even supplementary)? It might be about confusing for the reader. Also, I have not yet managed to find where this method was used before (it seems not to be there in the reference that Herzfeld gave us during the call. Or maybe it requires deeper reading of that paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740014f3-b0c1-4750-a506-066522c1ba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for env,alt in zip(['stable','random'],['greater','less']):\n",
    "    print(env)\n",
    "    r = compare0(r_per_subj.query('env == @env'), 'r', alt, ['r'])\n",
    "    display(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec6a94c-88ff-4c7b-9e9e-2a223440a9af",
   "metadata": {},
   "source": [
    "### take only same target trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255a5ca1-58f7-4ff5-abff-ed85fc47159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d901aca-5d00-49e4-be54-a90e260fe202",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = f'trial_group_col_calc == \"trialwe\" and {distcol} == \"0.00\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bc6fce-8b3f-4588-a768-0be87c3d3ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = dfc_multi_tsz.query(qs)\n",
    "print(len(df_))\n",
    "grp_shifts = df_.groupby(['subject','env','trial_index'])\n",
    "grp_shifts.size().min(), grp_shifts.size().mean(), grp_shifts.size().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b13084b-d80b-45f0-90ac-ab7eca430257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# super long\n",
    "method = 'spearman'\n",
    "def f(subdf):\n",
    "    r = pg.corr( subdf['trial_shift_size'], subdf['err_sens'], method=method)\n",
    "    r['method'] = method\n",
    "    return r\n",
    "corrs_shifts = grp_shifts.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef9d38-d598-48bb-81e0-e58aad2a5bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ebc8e4-7a27-4062-a71b-aaa20e59b627",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_per_subj = corrs_shifts.reset_index().groupby(['env','subject'])[['r','n']].mean().reset_index()\n",
    "r_per_subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490f85be-a5c0-442e-8896-da3ba0f8b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for env,alt in zip(['stable','random'],['less','less']):\n",
    "    print(env)\n",
    "    r = compare0(r_per_subj.query('env == @env'), 'r', alt, ['r'])\n",
    "    display(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4185d9",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Break stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7030fadc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "break_stat = dfall.loc[dfall['pre_break_duration'] > 0].groupby('subject', observed=True) ['pre_break_duration'].describe().mean()\n",
    "me,std = break_stat['mean'], break_stat['std']\n",
    "print('Mean pause duration was = {:.1f}s (std = {:.1f}s)'.format(me,std))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c604dd",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ES vs prev err (supp plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5664a786",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#dfc = df_wthr.copy()\n",
    "dfc = dfall.copy()\n",
    "assert dfc.err_sens.max() < 40\n",
    "\n",
    "# #bins = np.linspace(-1.5,1.5,10)\n",
    "# bins = np.linspace(-1.5,1.5,10)\n",
    "# dfc['prev_error_bin'] = pd.cut(dfc['prev_error'], bins)\n",
    "# grp = dfc.groupby( ['subj','prev_error_bin','env'] )\n",
    "# dfme = grp['err_sens'].mean().reset_index()\n",
    "# dfme['prev_error_mid'] = dfme['prev_error_bin'].apply(lambda x: x.mid )\n",
    "# dfme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6f3874",
   "metadata": {
    "code_folding": [
     33
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from figure.plots import genStRandLegendHandles\n",
    "handles = genStRandLegendHandles(rect=False, include_labels=True)\n",
    "\n",
    "r2d = 180 / np.pi\n",
    "savefig = 1\n",
    "bins = np.linspace(-1.2,1.2,15) * r2d; \n",
    "#bins = np.linspace(-1.5,1.5,15)  * r2d\n",
    "#bins = np.linspace(-1.5,1.5,10) * r2d\n",
    "dfc['prev_error_deg_bin'] = pd.cut(dfc['prev_error'] * r2d, bins) # important to use true error, not pscadj\n",
    "grp = dfc.groupby( ['subj','prev_error_deg_bin','env','dist_rad_from_prevtgt2'] )\n",
    "dfme = grp['err_sens'].mean().to_frame()\n",
    "dfmesz = grp['err_sens'].size().to_frame()\n",
    "dfme['sz'] = dfmesz['err_sens']\n",
    "dfme = dfme.reset_index()\n",
    "dfme['prev_error_deg_mid'] = dfme['prev_error_deg_bin'].apply(lambda x: x.mid )\n",
    "\n",
    "nbins = len(bins)\n",
    "minsz = 4\n",
    "ylim = -0.65,1.1\n",
    "df_ = dfme.query('sz >= @minsz')\n",
    "\n",
    "def custom_axis_label(ax, data):\n",
    "    env = data.env.values[0]\n",
    "    d = data.dist_rad_from_prevtgt2.values[0]\n",
    "    ax.set_label_text(f'Dist = {d}')\n",
    "    \n",
    "def set_custom_titles(grid, data):\n",
    "    for ax, (col_val, data_cur_axis) in zip(grid.axes.flat, grid.facet_data()):\n",
    "        d = data_cur_axis.dist_rad_from_prevtgt2.values[0]\n",
    "        d = float(d) * r2d\n",
    "        ax.set_title(f'Distance from\\nprevious target = {d:.0f} [deg]')                \n",
    "\n",
    "#row='env',\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "    fg = sns.relplot(kind='line', data=df_, x='prev_error_deg_mid', y='err_sens', \n",
    "                      col='dist_rad_from_prevtgt2', hue='env',\n",
    "                    height=5, hue_order=['stable','random'], palette=['tab:orange','tab:grey'],\n",
    "                     col_order=['0.00', '0.79', '1.57', '2.36'],\n",
    "                    legend=False, aspect=0.9)\n",
    "    #fg = sns.scatterplot(data=dfc.query('env == \"stable\"'), x='prev_error', y='err_sens', hue='block_name')\n",
    "    #fg.axhline(0,c='r',ls=':')\n",
    "    for ax in fg.axes.flatten():\n",
    "        ax.axhline(0,c='r',ls=':')\n",
    "        ax.axvline(0,c='r',ls=':')\n",
    "        ax.set_ylabel('error sensitivity')\n",
    "        ax.set_xlabel('previous error [deg]')\n",
    "        ax.set_ylim(ylim)\n",
    "        \n",
    "    set_custom_titles(fg, df_)\n",
    "    \n",
    "    ax.legend(handles=handles, facecolor='white',                                                                                                                                                                                                       \n",
    "    loc='lower right', framealpha=0.75, fontsize='medium')  \n",
    "\n",
    "        #ax.set_ylim(-15,15)\n",
    "    #addTitleInfo(ax)\n",
    "    \n",
    "    plt.suptitle('ES dependence on previous error')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    print('minsz = ',minsz)\n",
    "    if savefig:\n",
    "        plt.savefig(pjoin(path_fig, f'ES_per_prev_error_binned_inctgt_minsz={minsz}_{nbins}.pdf'))\n",
    "    else:\n",
    "        print('Skipping fig saving')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7093c4b",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Additional stats (supp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e89c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = 0.754\n",
    "st = 0.190\n",
    "s = f'Mean movement time = {mt:.2f}s (std = {st:.2f}s)'\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8244bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall.groupby('subject')['trial_duration'].mean().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10de1c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall.groupby('subject')['movement_duration'].mean().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1da470",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from behav_proc import comparePairs    \n",
    "df_ = dfall.query('thr == \"mestd*0\" and env == \"random\"')\n",
    "varn = 'err_sens'\n",
    "col = 'block_name'\n",
    "\n",
    "print('Compare different random blocks')\n",
    "df_ = dfall.query('env == \"random\"')\n",
    "varn = 'err_sens'\n",
    "col = 'block_name'\n",
    "\n",
    "ttrssig, ttrs = comparePairs(df_,varn,col)\n",
    "if ttrssig is None:\n",
    "    print('None')\n",
    "else:\n",
    "    ttrssig[statcols_toshow]\n",
    "ttrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcdc022",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#'val1','val2',\n",
    "statcols_toshow = ['varn','T','pval','val1_nice','val2_nice','alternative','pooled','ttstr', 'ttstr_nice','dof']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2731ac",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stages = ['pre1','pert1_1','washout1_1','pert1_2','washout1_2'] + ['pre2','pert2_1','washout2_1','pert2_2','washout2_2']\n",
    "ind2stage = dict(zip(np.arange(len(stages)),stages))\n",
    "ind2stage[-1] = 'random'\n",
    "ind2stage\n",
    "\n",
    "def nicener(s):\n",
    "    # we have to start from -1 otherwise bad\n",
    "    inds = [-1] + list(range(10))\n",
    "    for i in inds:\n",
    "        ps = ind2stage[i]\n",
    "        \n",
    "        si = str(i)\n",
    "        sil = len(si)\n",
    "        if s.startswith(si + ' '):# or s.startswith(si + '>'):\n",
    "            s = ps + s[sil:]\n",
    "        elif s.endswith(' ' + si):# or s.endswith('>' + si):\n",
    "            s = s[:-sil] + ps\n",
    "        \n",
    "    return s\n",
    "ttrssig['ttstr_nice'] = ttrssig['ttstr'].apply(nicener)\n",
    "ttrssig['ttstr_nice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ab204c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "me = dfall.groupby(['thr','subject','pert_stage']).\\\n",
    "    mean(numeric_only=1).reset_index()\n",
    "me_pert_stage = me\n",
    "\n",
    "for col, me in [('pert_stage',me_pert_stage)]:#[('env', me_env), ('ps_', me_ps)]:\n",
    "    for qs in ['thr == \"mestd*0\"']:\n",
    "        df_ = dfall #me.query(qs)\n",
    "        print(col, qs)\n",
    "        varn = 'err_sens'\n",
    "        ttrssig, ttrs = comparePairs(df_,varn,col)\n",
    "        ttrssig['val1_nice'] = ttrssig['val1'].apply(lambda x: ind2stage[x])\n",
    "        ttrssig['val2_nice'] = ttrssig['val2'].apply(lambda x: ind2stage[x])\n",
    "        ttrssig['ttstr_nice'] = ttrssig['ttstr'].apply(nicener)\n",
    "        \n",
    "        display(ttrssig.query('alternative != \"two-sided\"')\\\n",
    "                [statcols_toshow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c027198a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display( ttrssig.query('alternative != \"two-sided\" and not ttstr.str.contains(\"-1\")')[['ttstr_nice','pval']] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493a07c9",
   "metadata": {
    "hidden": true,
    "tags": [
     "final_output"
    ]
   },
   "outputs": [],
   "source": [
    "display( ttrssig.query('alternative != \"two-sided\" and not ttstr.str.contains(\"-1\") and val1_nice.str.contains(\"pert\") and val2_nice.str.contains(\"pert\")')[['ttstr_nice','pval']] )\n",
    "display( ttrssig.query('alternative != \"two-sided\" and not ttstr.str.contains(\"-1\") and val1_nice.str.contains(\"wash\") and val2_nice.str.contains(\"wash\")')[['ttstr_nice','pval']] )\n",
    "display( ttrssig.query('alternative != \"two-sided\" and not ttstr.str.contains(\"-1\") and val1_nice.str.contains(\"pre\") and val2_nice.str.contains(\"pre\")')[['ttstr_nice','pval']] )\n",
    "print(\"Last pertrubation has lower ES compared to first and third perturbations (p-values 0.035 and 0.016.\")\n",
    "print(\"First washout has lower ES compared to the second one (p-value 0.014).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc186bc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "837de388",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# within tgt main stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb5b5c6",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## no savings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be380c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corrs_per_subj_me_,corrs_per_subj  = corrMean(dfall_witgt, \n",
    "                stagecol = 'pert_stage', coln='err_sens')\n",
    "\n",
    "# show stat signif\n",
    "stage_pairs = [(1,6),(3,8)]\n",
    "ttrs = []\n",
    "for s1,s2 in stage_pairs:    \n",
    "    cps1 = corrs_per_subj.reset_index().query('pert_stage == @s1').set_index(['subject'])\n",
    "    cps2 = corrs_per_subj.reset_index().query('pert_stage == @s2').set_index(['subject'])\n",
    "    cps_dif = cps1['r'] - cps2['r'] \n",
    "    cps_dif= cps_dif.to_frame()        \n",
    "    ttr = compare0(cps_dif, 'r', alt='two-sided')\n",
    "    ttr['stage_pair'] = f'{s1}-{s2}'\n",
    "    ttrs += [ttr]\n",
    "ttrs = pd.concat(ttrs)\n",
    "display( ttrs.query('pval <= 1e-2') )\n",
    "\n",
    "stage_pairs_nice = {\"1-6\":'first and last', \"3-8\":'second and third'}\n",
    "\n",
    "display(ttrs)\n",
    "print('\\n\\nNo savings:')\n",
    "for irow,row in ttrs.iterrows():\n",
    "    sp = row['stage_pair']\n",
    "    pv=row['pval']\n",
    "\n",
    "    #print(sp,pv)\n",
    "    print('ES during {} perturbations are not significantly different, p-value = {:.2e}.'.\\\n",
    "              format(stage_pairs_nice[sp],pv) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1789917c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f056b41",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Fig 2 CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66870eff",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbca0a33",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#me.subject.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8425faeb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from figure import renameTickLabels, palette_stabrand\n",
    "\n",
    "thr = \"mestd*0\"\n",
    "me = dfall_witgt.groupby(['thr','subject','env'], observed=True).\\\n",
    "    mean(numeric_only=1).reset_index()\n",
    "me_env = me\n",
    "#me.groupby(['env','thr']).size()\n",
    "sns.set(font_scale=1.3)\n",
    "fg = sns.catplot(data = me.query('thr == @thr'), \n",
    "                 kind='violin', y='err_sens', \n",
    "    x='env', col='thr', order=['stable','random'],\n",
    "                palette = palette_stabrand)\n",
    "#addTitleInfo(fg.axes.flatten()[0])\n",
    "for ax in fg.axes.flatten():\n",
    "    ax.axhline(y=0, c='r', ls=':'); #ax.set_ylim(-5,5)\n",
    "    \n",
    "from figure.mystatann import plotSigAll\n",
    "ylast, ttrssig_env = plotSigAll(ax, 0.83, 0.05, ticklen=0.02,\n",
    "       df=me, coln='err_sens', colpair = 'env')\n",
    "    \n",
    "ax.annotate('C', xy=(0, 1), xytext=(-60, 60), \n",
    "      fontsize=19, fontweight='bold', va='top', ha='left',\n",
    "      xycoords='axes fraction', textcoords='offset points')\n",
    "fg.set_ylabels('Error sensitivity')\n",
    "ax.set_xlabel('Environment')\n",
    "\n",
    "fign = 'Fig2C'\n",
    "plt.savefig(pjoin(path_fig,fign + '.svg'))\n",
    "plt.savefig(pjoin(path_fig,fign + '.pdf'))\n",
    "plt.show()\n",
    "    \n",
    "###################\n",
    "# non-pooled stages and env comparison\n",
    "me = dfall_witgt.groupby(['thr','subject','ps2_'], observed=True).\\\n",
    "    mean(numeric_only=1).reset_index()\n",
    "me_ps = me\n",
    "#me.groupby(['ps_','thr']).size()\n",
    "sns.set(font_scale=1.3)\n",
    "fg = sns.catplot(data = me.query('thr == @thr'), kind='violin', y='err_sens', \n",
    "    x='ps2_', col='thr', order=['pre','pert','washout','rnd'],\n",
    "                hue = 'ps2_')\n",
    "for ax in fg.axes.flatten():\n",
    "    ax.axhline(y=0, c='r', ls=':'); #ax.set_ylim(-5,5)\n",
    "#addTitleInfo(fg.axes.flatten()[0])\n",
    "#plt.gcf().add_subplot_labels(['C'])\n",
    "\n",
    "ylast, ttrssig_ps = plotSigAll(ax, 2.05, 0.14, ticklen=0.05,\n",
    "       df=me, coln='err_sens', colpair = 'ps2_', fontsize = 10)\n",
    "\n",
    "ax.annotate('D', xy=(0, 1), xytext=(-60, 60), \n",
    "      fontsize=19, fontweight='bold', va='top', ha='left',\n",
    "      xycoords='axes fraction', textcoords='offset points')\n",
    "\n",
    "ax.set_xlabel('Experiment stage')\n",
    "#ax.set_xticklabels(['No perturbation','Perturbation','Washout','Random'], \n",
    "#                   rotation=30)\n",
    "ps_2nice = dict( zip(['pre','pert','washout','rnd'], \n",
    "        ['No perturbation','Perturbation','Washout','Random']) )\n",
    "renameTickLabels(ax, ps_2nice, rotation=30)\n",
    "\n",
    "fg.set_ylabels('Error sensitivity')\n",
    "fign = 'Fig2D'\n",
    "plt.savefig(pjoin(path_fig,fign + '.svg'))\n",
    "plt.savefig(pjoin(path_fig,fign + '.pdf'))\n",
    "\n",
    "#fg.set_titles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a361227c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f6cb91",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# to put in results\n",
    "ttrs = []\n",
    "for env in me_env.env.unique():\n",
    "    r = compare0(me_env.query('env == @env'),'err_sens',cols_addstat=['err_sens'])\n",
    "    r['env'] = env\n",
    "    ttrs += [r]\n",
    "ttrs_pos = pd.concat(ttrs).query('pval <= 0.05').set_index('env')\n",
    "assert len(ttrs_pos) == 2\n",
    "display(ttrs_pos)\n",
    "\n",
    "s0 = 'Averages of ES within participant. \\n'\n",
    "for env in me_env.env.unique():\n",
    "    row = ttrs_pos.loc[env]\n",
    "    s = (f\"{env} ES mean = {row['err_sens_mean']:.2f} (std = {row['err_sens_std']:.2f}),\"\n",
    "        f\" ES > 0 p-value = {row['pval']:.2e}. \\n\" )\n",
    "    s = s[0].upper() + s[1:]\n",
    "    s0 += s\n",
    "\n",
    "display(ttrssig_env)\n",
    "row = ttrssig_env.iloc[0]\n",
    "\n",
    "s = f\"Stable > random p-value={row['pval']:.2e}\"\n",
    "print(s0)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953df7de",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# to put in results\n",
    "#cocoln = 'ps2_'\n",
    "ttrs = []\n",
    "for ps in me_ps.ps2_.unique():\n",
    "    r = compare0(me_ps.query('ps2_ == @ps'),'err_sens',cols_addstat=['err_sens'])\n",
    "    r['ps2_'] = ps\n",
    "    ttrs += [r]\n",
    "ttrs_pos = pd.concat(ttrs).query('pval <= 0.05')\n",
    "assert len(ttrs_pos) == 4\n",
    "display(ttrs_pos)\n",
    "ttrs_pos = ttrs_pos.set_index('ps2_')\n",
    "\n",
    "s0 = 'Averages of ES within participant: \\n'\n",
    "for ps in me_ps.ps2_.unique():\n",
    "    row = ttrs_pos.loc[ps]\n",
    "    s = (f\"{ps} ES mean = {row['err_sens_mean']:.2f} (std = {row['err_sens_std']:.2f}),\"\n",
    "        f\" ES > 0 p-value = {row['pval']:.2e}. \\n\" )\n",
    "    s = s[0].upper() + s[1:]\n",
    "    s0 += s\n",
    "\n",
    "#display(ttrssig_ps)\n",
    "#row = ttrssig_ps.iloc[0]\n",
    "\n",
    "ttrssig_ps,_ = comparePairs(me_ps, 'err_sens', 'ps2_', alt=['greater'], \n",
    "                            paired=True, updiag=False)\n",
    "display(ttrssig_ps[ttrssig_ps.columns[-5:]])\n",
    "s1 = ''\n",
    "for i,row in ttrssig_ps.iterrows():\n",
    "    ttstr = row['ttstr']\n",
    "    s = ttstr.replace(row['val2'], ps_2nice[row['val2']] ).replace(row['val1'],\n",
    "                                                                   ps_2nice[row['val1']] )    \n",
    "    s += f\" p-value={row['pval']:.2e}; \\n\"\n",
    "    s1 += s\n",
    "#s = f\"Stable > random p-value={row['pval']:.2e}\"\n",
    "print(s0)\n",
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e018373",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show that dif between pert and rand is not there\n",
    "psvals = [\"pert\",\"rnd\"]\n",
    "ttrssig,ttrssig_all = comparePairs(me_ps.query('ps2_.isin(@psvals)'),\n",
    "                         'err_sens', 'ps2_', alt=['two-sided'], \n",
    "                        paired=True, updiag=True, pooled=0)\n",
    "display(ttrssig_all)\n",
    "assert len(ttrssig_all) == 1\n",
    "row = ttrssig_all.iloc[0]\n",
    "if row['pval'] > 0.05:    \n",
    "    s = 'The difference between ES in '\n",
    "    s += '{} and {} conditions is not significant ('.format( \n",
    "        ps_2nice[row['val2']], ps_2nice[row['val1'] ] )\n",
    "    s += f\" p-value={row['pval']:.2e}).\"\n",
    "    #s1 += s\n",
    "    print(s)\n",
    "else:\n",
    "    print('Actually there is significance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715975ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# New stats for err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad319ed",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\",category=UserWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c90aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrssig,ttrs = comparePairs(dfall,'error_pscadj','block_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeb1992",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttrssig.query('alternative != \"two-sided\"')[['pval','ttstr','pooled']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabf8638",
   "metadata": {},
   "outputs": [],
   "source": [
    "me = dfall.groupby(['subject','env','block_name'])['error_pscadj'].mean().to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7221a5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751ae5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from behav_proc import compare0\n",
    "for bn in dfall.block_name.unique():\n",
    "    df_ = dfall.query('block_name == @bn')\n",
    "    ttrs = compare0(df_,'error_pscadj').query('pval <= 0.05')\n",
    "    print(bn)\n",
    "    display(ttrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d911a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = sns.catplot(data = dfall,kind='violin',y='error_pscadj',\n",
    "           x='block_name', hue='env')\n",
    "fg.refline(y=0)\n",
    "\n",
    "fg = sns.catplot(data = me,kind='violin',y='error_pscadj',\n",
    "           x='block_name', hue='env')\n",
    "fg.refline(y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf621ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "conda_merrbeh_py3113",
   "language": "python",
   "name": "conda_merrbeh_py3113"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
