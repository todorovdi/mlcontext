{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41604565",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "ipy = get_ipython()\n",
    "#data_dir_general = '/home/demitau/data_Quentin'\n",
    "#data_subdir_mem_err_main = 'full_experiments/data2'\n",
    "from os.path import join as pjoin\n",
    "import os,sys; sys.path.append(os.path.expandvars('$CODE_MEMORY_ERRORS'))\n",
    "import error_sensitivity\n",
    "#data_dir_input = pjoin(data_dir_general,data_subdir_mem_err_main)\n",
    "import pandas as pd\n",
    "import seaborn as sns; print(sns.__version__)\n",
    "\n",
    "#data_dir_general = '/home/demitau/data_Quentin'\n",
    "#data_subdir_mem_err_main = 'full_experiments/data2'\n",
    "#data_dir_input = pjoin(data_dir_general,data_subdir_mem_err_main)\n",
    "#scripts_dir = pjoin(data_dir_general,'full_experiments','scripts2')\n",
    "\n",
    "data_dir_general = os.path.expandvars('$DATA_QUENTIN')\n",
    "data_dir_input = os.path.expandvars('$DATA_MEMORY_ERRORS_STAB_AND_STOCH')\n",
    "#scripts_dir = pjoin( os.path.expandvars('$CODE_MEMORY_ERRORS'), 'previous_analyses')\n",
    "scripts_dir = pjoin( os.path.expandvars('$CODE_MEMORY_ERRORS'))\n",
    "\n",
    "\n",
    "print(data_dir_input, scripts_dir)\n",
    "\n",
    "subjects = [f for f in os.listdir(data_dir_input) if f.startswith('sub') ]\n",
    "subjects = list(sorted(subjects))\n",
    "print(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac36398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "// needed to access notebook path later\n",
    "var nb = IPython.notebook;\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var command = \"NOTEBOOK_FULL_PATH = '\" + nb.base_url + nb.notebook_path + \"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111b7ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def getAddInfo():\n",
    "    import datetime\n",
    "    # Get the current date and time in the format YYYY-MM-DD HH:MM:SS\n",
    "    now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    # Get the name of the current jupyter notebook\n",
    "    #notebook_name = os.path.basename(os.environ.get(\"NOTEBOOK_PATH\", \"\"))\n",
    "    notebook_name = NOTEBOOK_FULL_PATH\n",
    "    #print(notebook_name)\n",
    "    add_ttle = f\"{now}\\n{notebook_name}\"\n",
    "    return add_ttle\n",
    "\n",
    "def addTitleInfo(axs):\n",
    "    add_ttle = getAddInfo()\n",
    "    # Add a linebreak and the date, time, and notebook name to the ylabel of each axis\n",
    "    if axs is not None:\n",
    "        if isinstance(axs, (list, np.ndarray)): # If axs is a list or an array of axes\n",
    "            for ax in axs:\n",
    "                title = ax.get_title()\n",
    "                new_title = f\"{title}\\n{add_ttle}\"\n",
    "                ax.set_title(new_title)\n",
    "        else: # If axs is a single axis\n",
    "            title = axs.get_title()\n",
    "            new_title = f\"{title}\\n{add_ttle}\"\n",
    "            axs.set_title(new_title)\n",
    "    else:\n",
    "        title = plt.gcf()._suptitle.get_text()\n",
    "        new_title = f\"{title}\\n{add_ttle}\"\n",
    "        plt.suptitle(new_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69581e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from config2 import path_data\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from behav_proc import *\n",
    "\n",
    "import numpy as np\n",
    "#from collections import OrderedDict as odict\n",
    "from config2 import envcode2env\n",
    "from pingouin import ttest\n",
    "\n",
    "from base2 import radius_cursor\n",
    "radius_cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574e4357",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnf = pjoin(path_data,'df_all_multi_tsz.pkl.zip')\n",
    "print(fnf)\n",
    "df_all_multi_tsz = pd.read_pickle(fnf)\n",
    "#dfc_multi_tsz = pd.   read_pickle(pjoin(path_data,'df_all_multi_tsz_trunc_q=0.05.pkl.zip'))\n",
    "df = df_all_multi_tsz.query('trial_shift_size == 1 and trial_group_col_calc == \"trialwe\"').copy()\n",
    "df_orig = df\n",
    "#del df_all_multi_tsz\n",
    "\n",
    "df['env'] = df['environment'].apply(lambda x: envcode2env[x])\n",
    "df['feedback_deg'] = df['feedback'] / np.pi * 180\n",
    "\n",
    "def f(x):    \n",
    "    if x > np.pi:\n",
    "        x -= 2*np.pi\n",
    "    elif x < -np.pi:\n",
    "        x += 2*np.pi\n",
    "    return x\n",
    "df['error'] = df['error'].apply(f)\n",
    "\n",
    "df['error_deg'] = df['error'] / np.pi * 180 \n",
    "\n",
    "def f(x):    \n",
    "    if x > np.pi:\n",
    "        x -= 2*np.pi\n",
    "    elif x < -np.pi:\n",
    "        x += 2*np.pi\n",
    "    return x\n",
    "df['prev_error'] = df['prev_error'].apply(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77e0ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate error at second halfs of init stage\n",
    "qs_initstage = 'pert_stage_wb.abs() < 1e-10'\n",
    "df_init = df.query(qs_initstage + ' and trialwb >= 10')\n",
    "grp = df_init.groupby(['subject','pert_stage'])\n",
    "#display(grp.size())\n",
    "#df_init['feedback_deg'].min(), df_init['feedback_deg'].max()\n",
    "\n",
    "grp['error_deg'].std()\n",
    "\n",
    "stds = df_init.groupby(['subject'])['error_deg'].std()#.std()\n",
    "mestd = stds.mean()\n",
    "print(mestd, stds.std() )\n",
    "\n",
    "stds = stds.to_frame().reset_index().rename(columns={'error_deg':'error_deg_initstd'})\n",
    "df_wthr = df.merge(stds, on='subject')\n",
    "#df_wthr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4bccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_multi_tsz_whtr = df_all_multi_tsz.merge(stds, on='subject')\n",
    "df_all_multi_tsz_whtr_ = df_all_multi_tsz_whtr.\\\n",
    "    query('trial_group_col_calc == \"trialwe\"')\n",
    "\n",
    "df_all_multi_tsz_whtr_['env'] = df_all_multi_tsz_whtr_['environment'].apply(lambda x: envcode2env[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db028cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shiftszs = df_all_multi_tsz_whtr_['trial_shift_size'].unique()\n",
    "shiftszs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e559ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN=5; st=0.4 #maxmult=1.2\n",
    "#thrs =  np.linspace(mestd/NN, mestd, NN); print(mestd, thrs)\n",
    "mults = st + (1-st) * np.arange(NN) / ( (NN - 1) )\n",
    "mults = [0] + list(mults)\n",
    "#thrs = mestd * mults\n",
    "mults#, thrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6775ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pooled random vs stable\n",
    "dfs = []\n",
    "ttrs = []\n",
    "#for thri, thr in enumerate(mults):\n",
    "for shiftsz in shiftszs:\n",
    "    for multi, mult in enumerate(mults):\n",
    "        # prev_error is not enough, it does not respect shift size\n",
    "        df_ = df_all_multi_tsz_whtr_.query('trial_shift_size == @shiftsz').copy()\n",
    "        df_ = df_[df_.error_deg.shift(shiftsz).abs() >= \\\n",
    "                df_['error_deg_initstd'] * mults[multi] ]\n",
    "        #df_ = df_.query('error_deg.shift(1).abs() >= @thr')\n",
    "        #thr_s = '{:.3f}'.format(thr)\n",
    "        #thr_s = f'{maxmult}*mestd/{ NN - (thri)}'\n",
    "        #thr_s = f'mestd/{ NN - (thri)}'\n",
    "        thr_s = f'mestd*{mults[multi]}'\n",
    "        df_['thr'] = thr_s\n",
    "        dfs += [df_]\n",
    "        print(thr_s, len(df_))\n",
    "dfall_notclean = pd.concat(dfs)\n",
    "# ttrs = pd.concat(ttrs)\n",
    "# ttrs = ttrs.rename(columns={'p-val':'pval'})\n",
    "\n",
    "from behav_proc import truncateDf\n",
    "dfall_mshsz  = truncateDf(dfall_notclean, 'err_sens', q=0.0, infnan_handling='discard', \n",
    "                   cols_uniqify = ['subject','environment','thr','trial_shift_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30d74cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc_multi_tsz = dfall_mshsz.query('thr == \"mestd*1.0\"')\n",
    "#dfc_multi_tsz = dfall_mshsz.query('thr == \"mestd*0\"')\n",
    "\n",
    "drs = dfc_multi_tsz['dist_rad_from_prevtgt'].unique();\n",
    "drs_f = np.array( list(map( float, drs) ) )\n",
    "drs = list(sorted(drs,key = lambda x: float(x)))\n",
    "\n",
    "#dfc_s = dfc[dfc['trial_group_col_calc'] == 'trialwtgt_we']\n",
    "# TODO: should I restrict to one env?\n",
    "dfc_s = dfc_multi_tsz.query('trial_group_col_calc == \"trialwe\"')\n",
    "grp = dfc_s.groupby(['trial_shift_size', 'dist_rad_from_prevtgt2'])\n",
    "dts = dfc_multi_tsz['trial_shift_size'].unique()\n",
    "nt = len(dts)\n",
    "\n",
    "drpairs = [(drs[i],drs[i+1] ) for i in range(3)]\n",
    "drpairs += [(drs[0],drs[i] ) for i in range(2,4)]\n",
    "drpairs += [(drs[1],drs[3] )]\n",
    "print(drpairs)\n",
    "\n",
    "dtpairs = [(dts[i],dts[i+1] ) for i in range(3)]\n",
    "dtpairs += [(dts[0],dts[i] ) for i in range(2,4)]\n",
    "dtpairs += [(dts[1],dts[3] )]\n",
    "dtpairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPvals(dftmp,fitcol,pairs):\n",
    "    from scipy.stats import ttest_ind\n",
    "    pvalues = []\n",
    "    for drp in pairs:\n",
    "        if isinstance(drp[0],str):\n",
    "            vs1 = dftmp.query(f'{fitcol} == \"{drp[0]}\"')['err_sens']\n",
    "            vs2 = dftmp.query(f'{fitcol} == \"{drp[1]}\"')['err_sens']\n",
    "        else:\n",
    "            vs1 = dftmp.query(f'{fitcol} == {drp[0]}')['err_sens']\n",
    "            vs2 = dftmp.query(f'{fitcol} == {drp[1]}')['err_sens']\n",
    "        #ttr = ttest_ind(vs1,vs2)\n",
    "        ttr = ttest_ind(vs1,vs2, alternative='greater')\n",
    "        pvalues += [ttr.pvalue]\n",
    "        \n",
    "        print(drp, ttr.pvalue)\n",
    "    # pvalues = [\n",
    "    #     sci_stats.mannwhitneyu(robots, flight, alternative=\"two-sided\").pvalue,\n",
    "    #     sci_stats.mannwhitneyu(flight, sound, alternative=\"two-sided\").pvalue,\n",
    "    #     sci_stats.mannwhitneyu(robots, sound, alternative=\"two-sided\").pvalue\n",
    "    # ]\n",
    "\n",
    "    # pvalues\n",
    "    # [0.00013485140468088997, 0.2557331102364572, 0.00022985464929005115]\n",
    "\n",
    "    # Transform each p-value to \"p=\" in scientific notation\n",
    "    formatted_pvalues = [f'p={pvalue:.2e}' for pvalue in pvalues]\n",
    "    return pvalues, formatted_pvalues\n",
    "\n",
    "# make polynomial fits\n",
    "def plotPolys(ax, dftmp, fitcol, degs=range(2,6), mean=1):\n",
    "    if mean:\n",
    "        me = dftmp.groupby(fitcol).median(numeric_only=1).reset_index()\n",
    "        dftmp = me\n",
    "    dftmp[fitcol] = pd.to_numeric(dftmp[fitcol] )\n",
    "    esv, dv = dftmp[['err_sens',fitcol]]._values.T\n",
    "    print(np.min(dv),dv,dv-np.min(dv),esv)\n",
    "    #pr = np.polyfit(esv,dv,2)\n",
    "    from numpy.linalg import LinAlgError\n",
    "    dvu = np.unique(dv)\n",
    "    dvu = np.array( list(sorted(dvu)) )\n",
    "    print(dvu)\n",
    "    for deg in degs:\n",
    "        try:\n",
    "            pr = np.polyfit(dv-np.min(dv),esv-np.min(esv),deg)        \n",
    "        except (SystemError,LinAlgError):\n",
    "            print(f'Failed deg={deg}')\n",
    "            print(dv,esv, np.std(dv))\n",
    "            continue\n",
    "            \n",
    "        poly = np.poly1d(pr)\n",
    "        #if len(degs) > 1:\n",
    "        if mean:\n",
    "            lbl = f'polynomial fit of means deg={deg}'\n",
    "        else:\n",
    "            lbl = f'polynomial fit deg={deg}'\n",
    "        #else:\n",
    "        #    lbl = None\n",
    "        esv2 = poly(dvu-np.min(dvu)) + np.min(esv)\n",
    "        print(dvu-np.min(dvu), esv)\n",
    "        ax.plot(range(len(dvu)) , poly(dvu-np.min(dvu)) + np.min(esv), \n",
    "                label=lbl, c='grey', lw=0.85 )\n",
    "    return pr\n",
    "    #ax.legend(loc='lower right')\n",
    "\n",
    "#plotPolys(ax,dftmp,fitcol,mean=0)\n",
    "ax = plt.gca()\n",
    "plotPolys(ax,dftmp,fitcol, degs=rng, mean=meanfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121fc009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not pooled\n",
    "#%debug\n",
    "\n",
    "hue = 'env'\n",
    "env2color = {'stable':'lightblue', 'random':'orange'}\n",
    "aspect=1.3\n",
    "#rng = [2]\n",
    "#rng = [2,3,4,5,6,7]\n",
    "rng = [2]\n",
    "ylim = [-2,3]\n",
    "meanfit=1\n",
    "bnqs = [  ('grid_line_violin_spatial','Spatial distance [deg]',\n",
    "           drs,drpairs,'dist_rad_from_prevtgt2', \n",
    "           f'trial_group_col_calc == \"trialwe\" and err_sens >= {ylim[0]} and err_sens <= {ylim[1]} and trial_shift_size == 1'),\n",
    "        ( 'grid_line_violin_temporal','Temporal distance [number of trials]',\n",
    "         dts,dtpairs,'trial_shift_size',\n",
    "         'trial_group_col_calc == \"trialwe\" and dist_rad_from_prevtgt2 == \"0.00\"')]\n",
    "\n",
    "outfiles = []\n",
    "for env_type in ['stable','random']:\n",
    "    color = env2color[env_type]\n",
    "    for bn,xlab,order,pairs,fitcol,qs in bnqs:\n",
    "        #qs0 = f'trial_group_col_calc == \"trialwe\" and err_sens >= {ylim[0]} and err_sens <= {ylim[1]}'\n",
    "        #qs = qs + ' and trial_shift_size == 1'\n",
    "        if env_type in ['stable', 'random']:\n",
    "            qs += ' and env == @env_type'\n",
    "            hue = None\n",
    "            \n",
    "        dftmp0 = dfc_multi_tsz.query(qs).groupby(['subject','environment',fitcol])\n",
    "        dftmp0 = dftmp0.mean(numeric_only = True).reset_index()\n",
    "\n",
    "        #dftmp0 = dfc_multi_tsz.query(qs)\n",
    "        #fitcol = 'dist_rad_from_prevtgt2'\n",
    "        fg = sns.catplot(kind='violin', data=dftmp0, y='err_sens', \n",
    "                         hue=hue, x=fitcol, order = order,\n",
    "                          color=color, aspect=aspect, cut=True)\n",
    "        #dftmp = dfc_multi_tsz.query(qs).copy()\n",
    "        dftmp = dftmp0.copy()\n",
    "        pvalues, formatted_pvalues = getPvals(dftmp,fitcol, pairs)\n",
    "\n",
    "\n",
    "        for ax in fg.axes.flatten():\n",
    "            ax.axhline(0,ls=':',c='r')\n",
    "            ax.set_ylabel('Error sensitivity', fontdict={'fontsize':12})\n",
    "            ax.set_xlabel(xlab, fontdict={'fontsize':12} )\n",
    "            if bn == 'grid_line_violin_spatial':\n",
    "                ax.set_xticklabels(['same target', 45, 90, 135])\n",
    "            ax.set_ylim(ylim)\n",
    "            ax.set_title(f'{env_type} environment', y = 0.967,\n",
    "                        fontdict={'fontsize':15, 'fontweight':'bold'})\n",
    "\n",
    "\n",
    "        from statannotations.Annotator import Annotator    \n",
    "        annotator = Annotator(ax,pairs, data=dftmp0, x=fitcol, y='err_sens',\n",
    "                             plot='violinplot', order=order)\n",
    "        #annotator.set_custom_annotations(formatted_pvalues)\n",
    "        annotator.set_pvalues(pvalues)\n",
    "        annotator.annotate()\n",
    "\n",
    "        #ax.set_ylim(-1,1.5)\n",
    "\n",
    "        print('            ',env_type)\n",
    "        plotPolys(ax,dftmp,fitcol, degs=rng, mean=meanfit)\n",
    "        #bn = 'grid_line_violin_spatial'\n",
    "        fnfig = pjoin(path_fig,'behav',f'nopool_{env_type}_{bn}')\n",
    "        plt.savefig(fnfig + '.svg')\n",
    "        plt.savefig(fnfig + '.pdf')\n",
    "        outfiles += [fnfig + '.pdf']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722d2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1e9915",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftmp0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e0ad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how entire generalization lines are related (maybe useless)\n",
    "print(getAddInfo())\n",
    "for bn,xlab,order,pairs,fitcol,qs in bnqs:\n",
    "    dftmp0 = dfc_multi_tsz.query(qs).groupby(['subject','env',fitcol])\n",
    "    dftmp0 = dftmp0.mean(numeric_only = True).reset_index()    \n",
    "    \n",
    "    print(bn)\n",
    "    ttrssig,ttrs = comparePairs(dftmp0, 'err_sens', 'env', alt=['greater','less'],\n",
    "                               paired=True)\n",
    "    display(ttrssig)\n",
    "    #dftmp0.query('env == \"stable\"')['err_sens'], dftmp0.query('env == \"random\"')['err_sens']\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50177d63",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "print(getAddInfo())\n",
    "corrs = []\n",
    "for bn,xlab,order,pairs,fitcol,qs in bnqs:\n",
    "    dftmp0 = dfc_multi_tsz.query(qs).groupby(['subject','env',fitcol])\n",
    "    dftmp0 = dftmp0.mean(numeric_only = True).reset_index()    \n",
    "    dftmp0[fitcol] = dftmp0[fitcol].astype(float) #now, not earlier!\n",
    "    \n",
    "    print(bn)\n",
    "    \n",
    "    def f(df_):\n",
    "    #print(df_['err_sens'],df_[fitcol])\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "            r = pg.corr(df_['err_sens'],df_[fitcol], method='pearson')\n",
    "        return r\n",
    "    r = dftmp0.groupby(['subject','env']).apply(f)\n",
    "\n",
    "    coors_me = r.reset_index().groupby(['subject','env']).mean(numeric_only=1)\n",
    "    coors_me['fitcol'] = fitcol\n",
    "    corrs += [coors_me.reset_index()]\n",
    "    for env in ['stable','random']:\n",
    "        print(env)\n",
    "        coors_me_ = coors_me.query('env == @env')\n",
    "        corrs_sig_nonz = compare0(coors_me_, 'r').query('pval < 0.05')\n",
    "        if len(corrs_sig_nonz):\n",
    "            display(corrs_sig_nonz)\n",
    "        else:\n",
    "            print('   NOOOO')\n",
    "    #dftmp0.query('env == \"stable\"')['err_sens'], dftmp0.query('env == \"random\"')['err_sens']\n",
    "    #break\n",
    "corrs = pd.concat(corrs, ignore_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fc181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d1233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(df_):\n",
    "    #x = df_.query('env == \"stable\"')['r']\n",
    "    #y = df_.query('env == \"random\"')['r']\n",
    "    ttsig,tt = comparePairs( df_, 'r', 'env', alt=['greater','less'],\n",
    "                               paired=True)\n",
    "    return tt\n",
    "dfr = corrs.groupby(['fitcol']).apply(f)\n",
    "\n",
    "print(getAddInfo())\n",
    "dfr.query('pval < 0.05')[['pval','pooled','ttstr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911cfd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2036432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coors_me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af81ad4",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a29f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7626345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f1b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d958a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b0b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258dcabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1e444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "input_files = outfiles\n",
    "\n",
    "output_file = os.path.join(path_fig, \"merged.pdf\")\n",
    "\n",
    "# Build the command to merge the PDF files using pdfunite\n",
    "# #command = [\"pdfunite\"] + input_files + [output_file]\n",
    "# command = [\"pdfjam\"] + input_files + ['--nup 2x2 --landscape --outfile'] + [output_file]\n",
    "\n",
    "# #command = ' '.join(command)\n",
    "# command = [command[0], ' '.join(command[1:])]\n",
    "\n",
    "# # Run the command using subprocess.run()\n",
    "# result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "\n",
    "# Build the command to arrange the PDF files using pdfjam\n",
    "command = f\"pdfjam {' '.join(input_files)} --nup 2x2 --suffix 4up\"\n",
    "\n",
    "# Split the command into a list of arguments using shlex.split()\n",
    "args = shlex.split(command)\n",
    "\n",
    "# Run the command using subprocess.run()\n",
    "result = subprocess.run(args, capture_output=True, text=True)\n",
    "\n",
    "# Check the return code and output of the command\n",
    "if result.returncode == 0:\n",
    "    print(f\"Successfully merged {len(input_files)} \")\n",
    "else:\n",
    "    print(f\"Failed to merge PDF files: {result.stderr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f933c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356d4fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e378336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "\n",
    "def create_stacked_pdf():\n",
    "  \"\"\"Creates a stacked PDF from the four input PDF files.\"\"\"\n",
    "  command = 'for env_type in random stable; do' \\\n",
    "            '  for bn in grid_line_violin_spatial grid_line_violin_temporal; do' \\\n",
    "            '    pdfunite nopool_${env_type}_${bn}.pdf nopool_${env_type}_${bn}.pdf >> stacked_pdf.pdf' \\\n",
    "            '  done' \\\n",
    "            'done'\n",
    "  subprocess.call(command, shell=True)\n",
    "\n",
    "create_stacked_pdf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merr2",
   "language": "python",
   "name": "merr2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
