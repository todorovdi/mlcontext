{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9952a90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "ipy = get_ipython()\n",
    "from os.path import join as pjoin\n",
    "import os,sys; sys.path.append(os.path.expandvars('$CODE_MEMORY_ERRORS'))\n",
    "import error_sensitivity\n",
    "import pandas as pd\n",
    "import seaborn as sns; print(sns.__version__)\n",
    "from datetime import datetime\n",
    "import pingouin as pg\n",
    "data_dir_general = os.path.expandvars('$DATA_QUENTIN')\n",
    "data_dir_input = os.path.expandvars('$DATA_MEMORY_ERRORS_STAB_AND_STOCH')\n",
    "scripts_dir = pjoin( os.path.expandvars('$CODE_MEMORY_ERRORS'))\n",
    "\n",
    "print(data_dir_input, scripts_dir)\n",
    "\n",
    "subjects = [f for f in os.listdir(data_dir_input) if f.startswith('sub') ]\n",
    "subjects = list(sorted(subjects))\n",
    "print(subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c38735",
   "metadata": {},
   "source": [
    "### prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290b5aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from config2 import path_data\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from behav_proc import *\n",
    "\n",
    "import numpy as np\n",
    "#from collections import OrderedDict as odict\n",
    "from config2 import envcode2env\n",
    "from pingouin import ttest\n",
    "\n",
    "from base2 import radius_cursor\n",
    "radius_cursor\n",
    "ps_2nice = dict( zip(['pre','pert','washout','rnd'], \n",
    "        ['No perturbation','Perturbation','Washout','Random']) )\n",
    "\n",
    "target_angs = (np.array([157.5, 112.5, 67.5, 22.5]) + 90) * (np.pi / 180)\n",
    "print(target_angs / np.pi * 180)\n",
    "\n",
    "import behav_proc\n",
    "from behav_proc import addBehavCols2, truncateNIHDfFromES, calcESthr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab37059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "// needed to access notebook path later\n",
    "var nb = IPython.notebook;\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var command = \"NOTEBOOK_FULL_PATH = '\" + nb.base_url + nb.notebook_path + \"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31801f4c",
   "metadata": {
    "run_control": {
     "marked": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def getAddInfo():\n",
    "    import datetime\n",
    "    # Get the current date and time in the format YYYY-MM-DD HH:MM:SS\n",
    "    now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    # Get the name of the current jupyter notebook\n",
    "    #notebook_name = os.path.basename(os.environ.get(\"NOTEBOOK_PATH\", \"\"))\n",
    "    notebook_name = NOTEBOOK_FULL_PATH\n",
    "    #print(notebook_name)\n",
    "    add_ttle = f\"{now}\\n{notebook_name}\"\n",
    "    return add_ttle\n",
    "\n",
    "def addTitleInfo(axs):\n",
    "    add_ttle = getAddInfo()\n",
    "    # Add a linebreak and the date, time, and notebook name to the ylabel of each axis\n",
    "    if axs is not None:\n",
    "        if isinstance(axs, (list, np.ndarray)): # If axs is a list or an array of axes\n",
    "            for ax in axs:\n",
    "                title = ax.get_title()\n",
    "                new_title = f\"{title}\\n{add_ttle}\"\n",
    "                ax.set_title(new_title)\n",
    "        else: # If axs is a single axis\n",
    "            title = axs.get_title()\n",
    "            new_title = f\"{title}\\n{add_ttle}\"\n",
    "            axs.set_title(new_title)\n",
    "    else:\n",
    "        title = plt.gcf()._suptitle.get_text()\n",
    "        new_title = f\"{title}\\n{add_ttle}\"\n",
    "        plt.suptitle(new_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af1617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"NOTEBOOK_FULL_PATH:\\n\", NOTEBOOK_FULL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6858d750",
   "metadata": {
    "run_control": {
     "marked": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fnf = pjoin(path_data,'df_all_multi_tsz_.pkl.zip')\n",
    "#fnf = '/home/demitau/ownCloud/Current/merr_data/df_all_multi_tsz.pkl.zip'\n",
    "print(fnf)\n",
    "print( str(datetime.fromtimestamp(os.stat(fnf).st_mtime)))\n",
    "df_all_multi_tsz = pd.read_pickle(fnf)\n",
    "#dfc_multi_tsz = pd.   read_pickle(pjoin(path_data,'df_all_multi_tsz_trunc_q=0.05.pkl.zip'))\n",
    "# df = df_all_multi_tsz.query('trial_shift_size == 1 and trial_group_col_calc == \"trialwe\" '\n",
    "#                             ' and retention_factor_s == \"1.000\"').copy()\n",
    "\n",
    "df = df_all_multi_tsz.query('trial_shift_size == 1 and trial_group_col_calc == \"trialwe\" '\n",
    "                            ' and retention_factor_s == \"0.924\"').copy()\n",
    "df_orig = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453da2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df,dfall,ES_thr,envv,pert = addBehavCols2(df);\n",
    "df_wthr = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c91feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set(font_scale=1.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874445a9",
   "metadata": {},
   "source": [
    "# Variability (compare with Tan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf79353",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfc = dfall_aug.query('thr == \"mestd*1.0\"')\n",
    "#dfc = dfall.query('thr == \"mestd*1.0\"')\n",
    "# here we need all trials, w/o holes\n",
    "dfc = df_wthr.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b985d646",
   "metadata": {},
   "source": [
    "## corr ES and variance (and other statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1dfc91",
   "metadata": {},
   "source": [
    "### fixed histlen across subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2c5adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from behav_proc import addWindowStatCols\n",
    "dfcs,dfcs_fixhistlen,dfcs_fixhistlen_untrunc,histlens  = addWindowStatCols(dfc, ES_thr, \n",
    "                                    varn0s = ['error','error_pscadj','error_pscadj_abs'])\n",
    "dfcs_fixhistlen, me_pct_excl = behav_proc.truncLargeStats(dfcs_fixhistlen_untrunc, histlens, 5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a693d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c26cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(me_pct_excl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a2d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "me_pct_excl.query('mean_excl >= 1')\n",
    "\n",
    "me_pct_excl['mean_excl'].describe([0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff8f1f4",
   "metadata": {},
   "source": [
    "#### stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bf984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from behav_proc import compare0\n",
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b0b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e4ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcs_fixhistlen['environment'] = dfcs_fixhistlen['environment'].astype(int)\n",
    "df_ = dfcs_fixhistlen[['environment','subject','trials','error_pscadj_abs_Tan29']]\n",
    "assert not df_.duplicated(['subject','trials']).any()\n",
    "#df_.to_csv('/home/demitau/dfcs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b621d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "histlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a12d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcs_fixhistlen.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1528e761",
   "metadata": {
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# test one\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import warnings\n",
    "\n",
    "#result.pvalues, result.params are pd.Series objects containing actual values (possibly nan)\n",
    "# z is something like std (in fact it is coef / std)\n",
    "\n",
    "d={}\n",
    "varn = 'error_pscadj_abs_Tan20'\n",
    "df_ = dfcs_fixhistlen.dropna(subset = varn)\n",
    "model = smf.mixedlm(f\"err_sens ~ C(environment) + {varn} + C(environment) * {varn}\", df_, \n",
    "                    groups=df_[\"subject\"], re_formula=\"~C(environment)\")\n",
    "d['inter_randomeff'] = model\n",
    "\n",
    "model = smf.mixedlm(f\"err_sens ~ C(environment) + {varn} + C(environment) * {varn}\", df_, \n",
    "                    groups=df_[\"subject\"], re_formula=\"1\")\n",
    "d['inter'] = model\n",
    "\n",
    "model = smf.mixedlm(f\"err_sens ~ C(environment) + {varn} + C(environment) * {varn}\", df_, \n",
    "                    groups=df_[\"subject\"], re_formula=\"~C(environment)\")\n",
    "d['nointer_randomeff'] = model\n",
    "\n",
    "model = smf.mixedlm(f\"err_sens ~ C(environment) + {varn}\", df_, \n",
    "                    groups=df_[\"subject\"])\n",
    "d['nointer'] = model\n",
    "del model\n",
    "\n",
    "# disp=True is not helpful for catching warnings\n",
    "res = {}\n",
    "for mn,model in d.items():\n",
    "    wmess = []\n",
    "    with warnings.catch_warnings(record = True) as w:\n",
    "        result = model.fit(full_output=True)\n",
    "        for warning in w:\n",
    "            wmess += [warning.message]\n",
    "            print(warning.message)\n",
    "    result.wmess = wmess\n",
    "\n",
    "    result.converged2 = result.converged and ( not (result.params.isna().any() \\\n",
    "                                                        | result.pvalues.isna().any()) )\n",
    "    res[mn] = result\n",
    "\n",
    "    \n",
    "for mn,result in res.items():\n",
    "#print('result.converged2 = ',result.converged2)\n",
    "    summ = result.summary()\n",
    "    summ.tables[0].loc[5,2] = 'Converged2:'\n",
    "    summ.tables[0].loc[5,3] = 'Yes' if result.converged2 else 'No'\n",
    "\n",
    "\n",
    "    print(mn)\n",
    "    display(summ)\n",
    "\n",
    "#from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "#with warnings.catch_warnings():\n",
    "    #warnings.filterwarnings('ignore',category=ConvergenceWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ce4e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535240e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfcs_fixhistlen.pre_break_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85094350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfcs_fixhistlen.loc[dfcs_fixhistlen.was_pre_break,\n",
    "#                    ['trial_index','pre_break_duration','err_sens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b017724c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb618753",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_suffixes = 'mav,std,invstd,mavsq,mav_d_std,mav_d_var,Tan,invmavsq,invmav,std_d_mav,invTan'.split(',')\n",
    "\n",
    "varn0 = 'error_pscadj'\n",
    "n = 3\n",
    "for suffix in all_suffixes:\n",
    "    s = f'{varn0}_{suffix}{n}'\n",
    "    if s not in dfcs_fixhistlen.columns:\n",
    "        print(s)\n",
    "    assert s in dfcs_fixhistlen.columns\n",
    "\n",
    "print( all_suffixes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8091877",
   "metadata": {},
   "outputs": [],
   "source": [
    "prl = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b1feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make prev error abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef3de02",
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# run long calc\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import product\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning    \n",
    "from numpy.linalg import LinAlgError\n",
    "import traceback\n",
    "import datetime\n",
    "gc.collect()\n",
    "n_jobs_inside = 1\n",
    "\n",
    "# Define the function to be executed in parallel\n",
    "def run_model(args, ret_res = False):\n",
    "    dfcs_fixhistlen, cocoln, std_mavsz_, varn0, varn_suffix = args\n",
    "    varn = f'{varn0}_{varn_suffix}{std_mavsz_}'\n",
    "    df_ = dfcs_fixhistlen.dropna(subset=[varn, 'err_sens'])\n",
    "    df_ = df_[~np.isinf(df_[varn])]\n",
    "\n",
    "    excfmt = None\n",
    "    nstarts = 1\n",
    "    result = None\n",
    "    if cocoln == 'None':\n",
    "        s,s2 = f\"err_sens ~ {varn}\",\"1\"\n",
    "        model = smf.mixedlm(s, df_, \n",
    "                    groups=df_[\"subject\"])\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings('ignore',category=ConvergenceWarning)\n",
    "            result = model.fit()\n",
    "        results = {(s,s2): result}\n",
    "    else:\n",
    "        flas = []\n",
    "        s,s2 = f\"err_sens ~ C({cocoln}) + {varn} + C({cocoln}) * {varn} + {varn} * prev_error_pscadj_abs\",\\\n",
    "            f\"~C({cocoln})\"; flas += [(s,s2)]\n",
    "        s,s2 = f\"err_sens ~ C({cocoln}) + {varn} + C({cocoln}) * {varn} + {varn} * prev_error_pscadj_abs\",\\\n",
    "            f\"1\"; flas += [(s,s2)]\n",
    "        s,s2 = f\"err_sens ~ C({cocoln}) + {varn} + C({cocoln}) * {varn}\", f\"~C({cocoln})\"; flas += [(s,s2)]\n",
    "        s,s2 = f\"err_sens ~ C({cocoln}) + {varn} + C({cocoln}) * {varn}\",\"1\";  flas += [(s,s2)]\n",
    "        \n",
    "        s,s2 = f\"err_sens ~ C({cocoln}) + {varn}\",f\"~C({cocoln})\"; flas += [(s,s2)]\n",
    "        s,s2 = f\"err_sens ~ C({cocoln}) + {varn}\",\"1\"; flas += [(s,s2)]        \n",
    "        \n",
    "     \n",
    "        results = {}\n",
    "        for s,s2 in flas:\n",
    "            try:                \n",
    "                model = smf.mixedlm(s, df_.copy(), \n",
    "                            groups=df_[\"subject\"], re_formula=s2)\n",
    "                with warnings.catch_warnings(record=True) as w:\n",
    "                    ###warnings.filterwarnings('ignore',category=ConvergenceWarning)     \n",
    "                    # n_jobs argument does not really work :(\n",
    "                    result = model.fit(n_jobs =n_jobs_inside)\n",
    "                    wmess = []\n",
    "                    for warning in w:\n",
    "                        wmess += [warning.message]\n",
    "                    result.converged2 = result.converged and \\\n",
    "                        ( not (result.params.isna().any() | result.pvalues.isna().any()) )\n",
    "                    result.wmess = wmess\n",
    "\n",
    "            except LinAlgError as le:\n",
    "                excfmt = traceback.format_exc()\n",
    "                result = None\n",
    "            results[(s,s2)] = result\n",
    "        \n",
    "    s2summary = {}\n",
    "    for stpl,result in results.items():        \n",
    "        if (result is not None) and result.converged:\n",
    "            #result.remove_data()\n",
    "            summary = result.summary()\n",
    "            summary.tables[0].loc[5,2] = 'Converged2:'\n",
    "            summary.tables[0].loc[5,3] = 'Yes' if result.converged2 else 'No'\n",
    "            summary.wmess = result.wmess\n",
    "            summary.params = result.params\n",
    "            summary.pvalues = result.pvalues\n",
    "        else:\n",
    "            summary = None\n",
    "        s2summary[stpl] = summary\n",
    "    print(args[1:])\n",
    "    r = {'cocoln': cocoln, 'histlen': std_mavsz_,\n",
    "            'varn': varn, 'varn0':varn0, 'varn_suffix':varn_suffix,             \n",
    "             'excfmt':excfmt,\n",
    "            's2summary': s2summary, 'retention_factor':df_.iloc[0]['retention_factor_s']}\n",
    "            #'res': result}\n",
    "            #'nstarts':nstarts,\n",
    "    if ret_res:\n",
    "        r['s2res'] = results\n",
    "    return r\n",
    "\n",
    "N = 25\n",
    "# Create args array using product\n",
    "cocols = ['None', 'env', 'ps2_']\n",
    "#cocols = [ 'env'] #, 'ps2_']\n",
    "#std_mavsz_range = range(2, 30)\n",
    "std_mavsz_range = list(range(3,N)) + list( range(N, 40, 3) )\n",
    "#std_mavsz_range = range(2, 20)\n",
    "#std_mavsz_range = range(2, 12)\n",
    "#std_mavsz_range = range(2, 3)\n",
    "varn0s = ['error_pscadj', 'error_pscadj_abs']\n",
    "#varn_suffixes = ['std', 'invstd', 'mavsq', 'mav_d_std', 'mav_d_var', 'Tan']\n",
    "varn_suffixes = all_suffixes\n",
    "\n",
    "# shorter\n",
    "cocols = [ 'env', 'ps2_']\n",
    "varn0s = ['error'] #, 'error_pscadj', 'error_pscadj_abs']\n",
    "#varn_suffixes = ['std', 'invstd', 'Tan']\n",
    "#N_ = 10\n",
    "#std_mavsz_range = list(range(3,N_)) + list( range(N_, 32, 3) )\n",
    "\n",
    "# #std_mavsz_range = range(2, 15)\n",
    "# std_mavsz_range = range(2, 30)\n",
    "# varn0s = ['error_pscadj_abs']\n",
    "# #varn0s = ['error_pscadj', 'error_pscadj_abs']\n",
    "# #cocols = [ 'env', 'ps2_']\n",
    "# #cocols = [ 'ps2_']\n",
    "# cocols = [ 'env']\n",
    "\n",
    "args = list(product(cocols, std_mavsz_range, varn0s, varn_suffixes))\n",
    "print(len(args))\n",
    "# Number of processes\n",
    "#n_jobs = 10  # Use all available CPUs even with one job\n",
    "#n_jobs = 5\n",
    "n_jobs = 1\n",
    "\n",
    "ind = 0\n",
    "if n_jobs > 1:\n",
    "    # Execute in parallel\n",
    "    backend = 'multiprocessing' # 'loky'\n",
    "    #backend = 'loky' \n",
    "    prl = Parallel(n_jobs=n_jobs, backend = backend)\\\n",
    "        (delayed(run_model)( (dfcs_fixhistlen,*arg) ) for arg in args)\n",
    "else:\n",
    "    for arg in args:\n",
    "        prl += [run_model((dfcs_fixhistlen,*arg))]\n",
    "#     for arg in args[69:69+1]:\n",
    "#         prl += [run_model((dfcs_fixhistlen,*arg),ret_res=True)]\n",
    "        \n",
    "        if len(prl) >= 100:            \n",
    "            s_ = str(datetime.datetime.now())[:-7].replace(' ','_')\n",
    "            np.savez( pjoin(path_data, f'prl_{ind}_{s_}'), prl )\n",
    "            ind += 1\n",
    "            del prl\n",
    "            gc.collect()\n",
    "            prl = []\n",
    "    # to save the last\n",
    "    s_ = str(datetime.datetime.now())[:-7].replace(' ','_')\n",
    "    np.savez( pjoin(path_data, f'prl_{ind+1}_{s_}'), prl )\n",
    "\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f97b71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a8deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2663ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dif = (dfcs_fixhistlen['error_pscadj_std2'] - dfcs_fixhistlen['error_pscadj_abs_std2'])#\n",
    "display(dif.describe())\n",
    "dif.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3ec01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfcs_fixhistlen['_dif'] = dif\n",
    "dfcs_fixhistlen[['error_pscadj','error_pscadj_abs', 'error_pscadj_std2','error_pscadj_abs_std2','_dif']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f07c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a189d727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2266f777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac72361",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = prl[0]['s2res'][('err_sens ~ C(env) + error_pscadj_abs_mav_d_std7 + C(env) * error_pscadj_abs_mav_d_std7',\n",
    "  '~C(env)')]\n",
    "print( res.params )\n",
    "print( res.pvalues )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d75145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f0acb6",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd958e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define parameters for the distributions\n",
    "poisson_lambda = 5  # Mean for Poisson distribution\n",
    "normal_mean = 5  # Mean for normal distribution\n",
    "normal_std = 2  # Standard deviation for normal distribution\n",
    "N = 5000\n",
    "\n",
    "# Generate Poisson random variable\n",
    "poisson_var = np.random.gamma(poisson_lambda,size=N)\n",
    "\n",
    "# Generate normal random variable\n",
    "normal_var = np.random.normal(normal_mean, normal_std,size=N)\n",
    "\n",
    "# Print the generated variables\n",
    "print(\"Poisson variable:\", poisson_var)\n",
    "print(\"Normal variable:\", normal_var)\n",
    "\n",
    "import pandas as pd\n",
    "a = np.array(list(zip(normal_var,poisson_var)))\n",
    "dft = pd.DataFrame( a, columns=['normal','poisson'])\n",
    "    \n",
    "\n",
    "corr = pg.corr(dft['normal'], dft['poisson'], method='spearman')\n",
    "display(corr)\n",
    "\n",
    "sns.relplot(data=dft, x='normal',y='poisson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946d8c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Shepherd pi uses a\n",
    "# bootstrapping of the Mahalanobis distance to identify outliers, while the\n",
    "# skipped correlation is based on the minimum covariance determinant\n",
    "# (which requires scikit-learn). Note that these two methods are\n",
    "# significantly slower than the previous ones.\n",
    "\n",
    "# The `biweight midcorrelation\n",
    "# <https://en.wikipedia.org/wiki/Biweight_midcorrelation>`_ and\n",
    "# percentage bend correlation [1]_ are both robust methods that\n",
    "# protects against *univariate* outliers by down-weighting observations that\n",
    "# deviate too much from the median\n",
    "\n",
    "corr = pg.corr(dft['normal'], dft['poisson'], method='shepherd')\n",
    "display(corr.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f9b516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merr3_mamba",
   "language": "python",
   "name": "merr3_mamba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
