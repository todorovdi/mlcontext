{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdac4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%precision 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65e2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a373504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os,sys; sys.path.append(os.path.expandvars('$CODE_MEMORY_ERRORS'))\n",
    "from models import Shadmehr_model\n",
    "\n",
    "# Shadmehr params\n",
    "\n",
    "# simulate simple markov chain\n",
    "#change_prob = 0.9  # z in Shadmehr\n",
    "change_prob = 0.1  # z in Shadmehr\n",
    "#np.random.seed(5)\n",
    "\n",
    "def simulate(change_prob = 0.9, seed = None, verbose=1, ntrials = 100):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    switches = np.random.binomial(1, change_prob, ntrials-1)\n",
    "    start_state = 0\n",
    "    feedback_recorded = -np.ones( ntrials ) \n",
    "    feedback_recorded[0] = start_state\n",
    "    for i,notsv in enumerate(switches):\n",
    "        if notsv:\n",
    "            feedback_recorded[i+1] = feedback_recorded[i]\n",
    "        else:\n",
    "            feedback_recorded[i+1] = 1 - feedback_recorded[i]\n",
    "    #feedback_recorded\n",
    "    # weights_def not se in Shadmehr, needed manual tuning\n",
    "    # beta in Shadmehr is 0.05, but it is clearly too large\n",
    "    #weights_def=0.05\n",
    "    smodel = Shadmehr_model(ntrials, min_err=-5,max_err=5, weights_def=None,\n",
    "                           sigma =1., err_sens_def=0.001, beta=0.001,\n",
    "                           decay=1)\n",
    "    #smodel = Shadmehr_model(ntrials)\n",
    "    # processing\n",
    "    smodel.print_basic()\n",
    "    for ti in range(ntrials):\n",
    "        # TODO: update movement somehow\n",
    "        smodel.update(feedback_recorded[ti])\n",
    "        if verbose:\n",
    "            smodel.print_basic()\n",
    "    \n",
    "    return smodel, feedback_recorded\n",
    "    \n",
    "\n",
    "def plot(feedback_recorded, smodel, ttladd = ''):\n",
    "    pert_ests = smodel.pert_est[:smodel.prev_trial_ind + 1]\n",
    "    import matplotlib.pyplot as plt\n",
    "    nc,nr = 5,1;  ww,hh=10,2\n",
    "    fig,axs = plt.subplots(nc,nr, figsize=(nr*ww,nc*hh))\n",
    "    ax = axs[0]\n",
    "    ax.plot(np.arange(len(pert_ests) ), pert_ests, label='$\\hat{x}$')\n",
    "    ax.plot(np.arange(len(pert_ests) ), feedback_recorded, alpha=0.6, label='$x$')\n",
    "    ax.set_ylim(-0.1,1.1)\n",
    "    ax.set_title('Pert estimation vs perturation' + ttladd)\n",
    "    ax.legend()\n",
    "\n",
    "    ax = axs[1]\n",
    "    errors = smodel.errors[:smodel.prev_trial_ind + 1]\n",
    "    ax.plot(np.arange(len(errors) ), errors, label='errors')\n",
    "    wms = np.max( smodel.weights[:smodel.prev_trial_ind + 1], axis=1)\n",
    "    ax.plot(np.arange(len(errors) ), wms, label='max weights')\n",
    "    ax.set_title('Errors')\n",
    "    ax.legend()\n",
    "\n",
    "    ax = axs[2]\n",
    "    for wi in range(len(smodel.basis_err)):\n",
    "        ws = smodel.weights[:smodel.prev_trial_ind + 1,wi]\n",
    "        ax.plot(ws, label=f'{smodel.basis_err[wi]:.2f}')\n",
    "    ax.legend(loc=(1,0))\n",
    "    ax.set_title('All weights')\n",
    "\n",
    "    ax = axs[3]\n",
    "    es = smodel.err_sens[:smodel.prev_trial_ind + 1]\n",
    "    ax.plot(es, label=f'es')\n",
    "    ax.legend()\n",
    "    ax.set_title('Err sens')\n",
    "\n",
    "    ax = axs[4]\n",
    "    #es = smodel.err_sens[:smodel.prev_trial_ind + 1]\n",
    "    ws_all = smodel.weights[:smodel.prev_trial_ind + 1]\n",
    "    for wi in range(len(smodel.basis_err)):\n",
    "        es = []\n",
    "        for ti in range(ws_all.shape[0]):\n",
    "            es_cur = smodel.err2err_sens(ws_all[ti], smodel.basis_err[wi]) \n",
    "            es += [es_cur]\n",
    "        ax.plot(np.arange(ntrials),es, label=f'{smodel.basis_err[wi]:.2f}')\n",
    "    ax.legend(loc=(1,0))\n",
    "    ax.set_title('Err sens per basis el')\n",
    "    \n",
    "    \n",
    "def plotMeanES(smodels, ttladd = '', ax=None):\n",
    "    #pert_ests = smodel.pert_est[:smodel.prev_trial_ind + 1]\n",
    "    import matplotlib.pyplot as plt\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "#     nc,nr = 2,1;  ww,hh=4,2\n",
    "#     fig,axs = plt.subplots(nc,nr, figsize=(nr*ww,nc*hh))\n",
    "    #ax = axs[0]\n",
    "    ess = []\n",
    "    for smodel in smodels:\n",
    "        es = smodel.err_sens[:smodel.prev_trial_ind + 1]\n",
    "        ess += [es]\n",
    "    ess = np.vstack(ess)\n",
    "    es = ess.mean(0)\n",
    "    ess_errbar = scipy.stats.sem(ess,0)\n",
    "    #ess_errbar = ess.std(0)\n",
    "    print(ess.shape)\n",
    "    ax.errorbar(np.arange(len(es) ) , es, yerr=ess_errbar, label=f'es')\n",
    "    ax.legend()\n",
    "    ax.set_title(f'Err sens mean {ttladd}')\n",
    "    \n",
    "    ax.axhline(y=0, ls=':', c='r')\n",
    "\n",
    "    # TODO: for some reason too abrupt drop of err sens after a wrong thing\n",
    "    # the more certain we get the larger the weights and \n",
    "    # then the more abrupt would be the change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4edd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a9023",
   "metadata": {},
   "outputs": [],
   "source": [
    "smodel, feedback_recorded = simulate(change_prob = 0.9, verbose=0)\n",
    "plot(feedback_recorded, smodel, ttladd = '')\n",
    "\n",
    "smodel, feedback_recorded = simulate(change_prob = 0.1, verbose=0)\n",
    "plot(feedback_recorded, smodel, ttladd = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ba039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_probs = [0.9, 0.1]\n",
    "#change_prob = 0.1\n",
    "\n",
    "np.random.seed(2)\n",
    "N =16\n",
    "\n",
    "nc,nr = 2,1;  ww,hh=5,3\n",
    "fig,axs = plt.subplots(nc,nr, figsize=(nr*ww,nc*hh))\n",
    "\n",
    "for axi,change_prob  in enumerate(change_probs):\n",
    "    smodels = []\n",
    "    for nt in range(N):\n",
    "        smodel, feedback_recorded = simulate(change_prob = change_prob, verbose=0)\n",
    "        smodels += [smodel]\n",
    "\n",
    "    plotMeanES(smodels, ttladd = f' zeta={change_prob:.1f}', ax=axs[axi])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731c9bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a953052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime  as dt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5417b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re; help(re.match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcfaa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_recorded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b804ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pymc as pm\n",
    "\n",
    "# # Assume 10 trials and 5 successes out of those trials\n",
    "# # Change these numbers to see how the posterior plot changes\n",
    "# trials = 10; successes = 5\n",
    "\n",
    "# # Set up model context\n",
    "# with pm.Model() as coin_flip_model:\n",
    "#     # Probability p of success we want to estimate\n",
    "#     # and assign Beta prior\n",
    "#     p = pm.Beta(\"p\", alpha=1, beta=1)\n",
    "    \n",
    "#     # Define likelihood\n",
    "#     obs = pm.Binomial(\"obs\", p=p, n=trials,\n",
    "#         observed=successes,\n",
    "#     )\n",
    "\n",
    "#     # Hit Inference Button\n",
    "#     idata = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cd9913",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrials = 10\n",
    "#feedback_recorded = np.random.uniform(size=ntrials)\n",
    "feedback_recorded = np.ones(ntrials) * 10\n",
    "dif = max(np.abs(np.max(feedback_recorded)), np.abs( np.min(feedback_recorded) ) )\n",
    "mn = -dif #np.min(feedback_recorded)\n",
    "mx = dif  #np.max(feedback_recorded) \n",
    "mn -= np.abs(mn) * 0.1\n",
    "mx += np.abs(mx) * 0.1\n",
    "smodel = Shadmehr_model(ntrials, min_err=mn,max_err=mx)\n",
    "#smodel = Shadmehr_model(ntrials)\n",
    "\n",
    "    \n",
    "# processing\n",
    "smodel.print_basic()\n",
    "for ti in range(ntrials):\n",
    "    # TODO: update movement somehow\n",
    "    smodel.update(feedback_recorded[ti])\n",
    "    smodel.print_basic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60714c6a",
   "metadata": {},
   "source": [
    "### Q: what shall we simulate?\n",
    "### Q: how did Shadmehr supply _pertrubations_ to his model (instead of just feedback)\n",
    "### Q: correct initial conditions = ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
